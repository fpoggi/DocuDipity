<?xml version="1.0" encoding="UTF-8" standalone="no"?><classedDocument><article xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" class="po-hcontainer e0 e0" version="5.0-subset Balisage-1.2"><title class="po-block e1 e1"><textual class="po-textual">Sustainability of Linguistic Resources Revisited</textual></title><info class="po-record e2 e2"><confgroup class="po-record e3 e3"><conftitle class="po-field e4 e4"><textual class="po-textual">International Symposium on XML for the Long Haul:  Issues in the Long-term Preservation of XML</textual></conftitle><confdates class="po-field e5 e5"><textual class="po-textual">August 2, 2010</textual></confdates></confgroup><abstract class="po-container e6 e6"><para class="po-block e7 e7"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></para></abstract><author class="po-record e8 e8"><personname class="po-record e9 e9"><firstname class="po-field e10 e10"><textual class="po-textual">Georg</textual></firstname><surname class="po-field e11 e11"><textual class="po-textual">Rehm</textual></surname></personname><personblurb class="po-container e12 e12"><para class="po-block e13 e13"><textual class="po-textual"> Georg Rehm works at DFKI, the German Research Center for Artificial
                    Intelligence, where he coordinates </textual><link class="po-inline e14 e14" xlink:actuate="onRequest" xlink:href="http://www.meta-net.eu" xlink:show="new" xlink:type="simple"><textual class="po-textual">META-NET</textual></link><textual class="po-textual">, a strategic pan-European research project on 
                    Machine Translation and multilingualism. He holds a PhD
                    in Computational Linguistics and has been working with SGML and
                    related technologies in the context of Natural Language Processing since 1995.
                </textual></para></personblurb><affiliation class="po-record e15 e15"><orgname class="po-block e16 e16"><textual class="po-textual">DFKI</textual></orgname></affiliation><email class="po-field e17 e17"><textual class="po-textual">georg.rehm@dfki.de</textual></email><link class="po-inline e18 e18" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://georg-re.hm</textual></link></author><author class="po-record e19 e19"><personname class="po-record e20 e20"><firstname class="po-field e21 e21"><textual class="po-textual">Oliver</textual></firstname><surname class="po-field e22 e22"><textual class="po-textual">Schonefeld</textual></surname></personname><personblurb class="po-container e23 e23"><para class="po-block e24 e24"><textual class="po-textual"> Oliver Schonefeld works at the Institut für Deutsche Sprache (Institute for
                    the German Language) in Mannheim and is involved in the projects </textual><link class="po-inline e25 e25" xlink:actuate="onRequest" xlink:href="http://www.textgrid.de/en/" xlink:show="new" xlink:type="simple"><textual class="po-textual">TextGrid</textual></link><textual class="po-textual"> and </textual><link class="po-inline e26 e26" xlink:actuate="onRequest" xlink:href="http://www.clarin.eu" xlink:show="new" xlink:type="simple"><textual class="po-textual">Clarin</textual></link><textual class="po-textual">.</textual></para><para class="po-block e27 e27"><textual class="po-textual"> He studied computer science with specialization in text technology at
                    Bielefeld University until 2005. After graduating he worked as a researcher at
                    Bielefeld University and later at Tübingen University's collaborative research
                    center Linguistic Data Structures.</textual></para><para class="po-block e28 e28"><textual class="po-textual"> His major research interests are the limitations of markup languages
                    (especially overlapping markup) and the use of markup languages in linguistic
                    description of language data.</textual></para></personblurb><affiliation class="po-record e29 e29"><orgname class="po-block e30 e30"><textual class="po-textual">Institute for the German Language (IDS), Mannheim</textual></orgname></affiliation><email class="po-field e31 e31"><textual class="po-textual">schonefeld@ids-mannheim.de</textual></email></author><author class="po-record e32 e32"><personname class="po-record e33 e33"><firstname class="po-field e34 e34"><textual class="po-textual">Thorsten</textual></firstname><surname class="po-field e35 e35"><textual class="po-textual">Trippel</textual></surname></personname><personblurb class="po-container e36 e36"><para class="po-block e37 e37"><textual class="po-textual"> Thorsten Trippel works at Tübingen University in a project on sustainability
                    of language resources called </textual><link class="po-inline e38 e38" xlink:actuate="onRequest" xlink:href="http://www.sfs.uni-tuebingen.de/nalida" xlink:show="new" xlink:type="simple"><textual class="po-textual">NaLiDa</textual></link><textual class="po-textual">. This
                    national project aims at providing a platform for linguists to locate resources
                    they need and to enable them to produce long time usable data by introducing
                    them to relevant metadata descriptions and standards. He is part of national and
                    international standardization groups on language resources. </textual></para><para class="po-block e39 e39"><textual class="po-textual"> His major research interests are directed towards language resources in
                    general and specifically in terminology and lexicography/lexicon theory (PhD
                    Thesis: The Lexicon Graph Model: A generic Model for multimodal lexicon
                    development) including other types of resources such as speech corpora and
                    involving other modalities. He has conducted research in speech technology and
                    textual corpus linguistics, has been working with (XML-)databases for
                    information retrieval over highly structured data and run research projects on
                    interface design for such data. </textual></para><para class="po-block e40 e40"><textual class="po-textual"> Work at his previous affiliation Bielefeld University involved research
                    projects in Brazil, transforming archives of handwritten texts into web-usable
                    multi purpose sources for computational linguists and historians. Additionally
                    he taught at Bielefeld University, and various institutions and summer schools,
                    for example in introducing text technological and computational linguistic
                    backgrounds to field linguists and language documentarists in West-Africa.
                </textual></para></personblurb><affiliation class="po-record e41 e41"><orgname class="po-block e42 e42"><textual class="po-textual">Tübingen University</textual></orgname></affiliation><email class="po-field e43 e43"><textual class="po-textual">thorsten.trippel@uni-tuebingen.de</textual></email><link class="po-inline e44 e44" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.sfs.uni-tuebingen.de/nalida/ttrippel.html</textual></link></author><author class="po-record e45 e45"><personname class="po-record e46 e46"><firstname class="po-field e47 e47"><textual class="po-textual">Andreas</textual></firstname><surname class="po-field e48 e48"><textual class="po-textual">Witt</textual></surname></personname><personblurb class="po-container e49 e49"><para class="po-block e50 e50"><textual class="po-textual"> Witt received his Ph.D. in Computational Linguistics and Text Technology from
                    the Bielefeld University in 2002 (dissertation title: “Multiple
                    Informationsstrukturierung mit Auszeichnungssprachen. XML-basierte Methoden und
                    deren Nutzen für die Sprachtechnologie”). </textual></para><para class="po-block e51 e51"><textual class="po-textual"> After graduating in 1996, he started as a researcher and instructor in
                    Computational Linguistics and Text Technology. He was heavily involved in the
                    establishment of the minor subject Text Technology in Bielefeld University's
                    Magister and B.A. program in 1999 and 2002 respectively. After his Ph.D. in 2002
                    he became an assistant lecturer, still at the Text Technology group in
                    Bielefeld. In 2006 he moved to Tübingen University, where he was involved in a
                    project on “Sustainability of Linguistic Resources” and in projects on the
                    interoperability of language data. Since 2009 he is senior researcher at
                    Institut für Deutsche Sprache (Institute for the German Language) in Mannheim. </textual></para><para class="po-block e52 e52"><textual class="po-textual"> Witt is and was a member of several research organizations, amongst them the
                    TEI Special Interest Group on overlapping markup, for which he was involved in
                    the writing of the latest version of the chapter “Multiple Hierarchies”, which
                    is included in TEI-Guidelines P5. </textual></para><para class="po-block e53 e53"><textual class="po-textual"> Witt's major research interests deal with questions on the use and
                    limitations of markup languages for the linguistic description of language data.
                </textual></para></personblurb><affiliation class="po-record e54 e54"><orgname class="po-block e55 e55"><textual class="po-textual">Institute for the German Language (IDS), Mannheim</textual></orgname></affiliation><email class="po-field e56 e56"><textual class="po-textual">witt@ids-mannheim.de</textual></email><link class="po-inline e57 e57" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.ids-mannheim.de/direktion/personal/witt.html</textual></link></author><legalnotice class="po-container e58 e58"><para class="po-block e59 e59"><textual class="po-textual">Copyright © 2010 by the authors.  Used with
permission.</textual></para></legalnotice></info><section class="po-hcontainer e60 e60"><title class="po-block e61 e61"><textual class="po-textual">Introduction</textual></title><para class="po-block e62 e62"><textual class="po-textual"> This paper discusses work on the sustainability of linguistic resources as it was
            conducted in various projects, including the work of a three year project
                </textual><emphasis class="po-inline e63 e63"><textual class="po-textual">Sustainability of Linguistic Resources</textual></emphasis><textual class="po-textual"> which finished in
            December 2008, a follow-up project, </textual><emphasis class="po-inline e64 e64"><textual class="po-textual">Sustainable linguistic data</textual></emphasis><textual class="po-textual">,
            and initiatives related to the work of the International Organization of Standardization
            (ISO) on developing standards for linguistic resources. The individual projects have
            been conducted at German collaborative research centres at the Universities of Potsdam, 
            Hamburg and Tübingen, where the sustainability work was coordinated. </textual></para><para class="po-block e65 e65"><textual class="po-textual"> Today, most language resources are represented in XML. The representation of data in
            XML is an important prerequisite for long-term preservation but a reasonable
            representation format such as XML alone is not sufficient. Though XML is being said to
            be human-readable it is obvious that legibility is a rather problematic notion in terms
            of photos encoded in SVG, complex structures generated from data dumps of databases and
            other applications or even formats such as Office Open XML. In the linguistic data
            community, various flavours of stand-off annotation also demonstrate the complexity 
            of the problem. </textual></para><para class="po-block e66 e66"><textual class="po-textual"> Usually these data formats are not meant to be read by humans, though the advantages
            mentioned in XML-introductions still hold, namely, that data modelled according to the
            standardized and continuously maintained XML formalism can be read and analysed by 
            human users to re-engineer tools using simple parsers for validation and mental effort.
            </textual></para></section><section class="po-hcontainer e67 e67"><title class="po-block e68 e68"><textual class="po-textual">Case Study: The Project “Sustainability of Linguistic Resources”</textual></title><para class="po-block e69 e69"><textual class="po-textual"> This section briefly presents SPLICR, the Web-based Sustainability Platform for
            Linguistic Corpora and Resources aimed at researchers who work in Linguistics or
            Computational Linguistics: a comprehensive database of metadata records can be explored
            and searched in order to find language resources that could be appropriate for one’s
            specific research needs. SPLICR also provides a graphical interface that enables users
            to query and to visualise corpora. </textual></para><para class="po-block e70 e70"><textual class="po-textual"> The project in which SPLICR was developed aimed at sustainably archiving the language
            resources that were constructed in three collaborative research centres. The groups in
            Tübingen (SFB 441: “Linguistic Data Structures”), Hamburg (SFB 538: “Multilingualism”),
            and Potsdam/Berlin (SFB 632: “Information Structure”) built a total of 56 resources
            – corpora and treebanks mostly. According to our estimates it took more than one
            hundred person years to collect and to annotate these datasets. The project had two main
            goals: (a) To process and to sustainably archive the resources so that they are still
            available to the research community and other interested parties in five, ten, or even
            20 years time. (b) To enable researchers to query the resources both on the level of
            their metadata as well as on the level of linguistic annotations. In more general terms,
            the main goal was to enable solutions that leverage the interoperability, reusability,
            and sustainability of a large collection of heterogeneous language resources. </textual></para><para class="po-block e71 e71"><textual class="po-textual"> One of the obstacles we were confronted with was providing homogeneous means of
            accessing a large collection of diverse and complex linguistic resources. For this
            purpose we developed several custom tools in order to normalise the corpora and their
            metadata records. </textual></para><section class="po-hcontainer e72 e72"><title class="po-block e73 e73"><textual class="po-textual">Normalization of Linguistic Resources</textual></title><para class="po-block e74 e74"><textual class="po-textual"> Language resources are nowadays usually built using XML-based representations and
                contain several concurrent annotation layers that correspond to multiple levels of
                linguistic description (e.g., part-of-speech, syntax, coreference). Our approach
                included the normalization of XML-annotated resources, e.g., for cases in which
                corpora use PCDATA content to capture both primary data (i.e., the original text or
                transcription) as well as annotation information (e.g., POS tags). We used a set of
                tools to ensure that only primary data is encoded in PCDATA content and that all
                annotations proper are encoded using XML elements and attributes. </textual></para><para class="po-block e75 e75"><textual class="po-textual"> A second reason for the normalization procedure was that both hierarchical and
                timeline-based corpora needed to be transformed into a common annotation approach,
                because we wanted our users to be able to query both types of resources at the same
                time and in a uniform way. The approach can be compared to the NITE Object Model
                    (</textual><xref class="po-milestone e76 e76" linkend="Carletta2003"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">): we developed tools that semiautomatically
                split hierarchically annotated corpora that typically consist of a single XML
                document instance into individual files, so that each file represented the
                information related to a single annotation layer; this approach also guaranteed that
                overlapping structures can be represented straightforwardly. Timeline-based corpora
                were also processed in order to separate graph annotations. This approach enabled us
                to represent arbitrary types of XML-annotated corpora as individual files, i.e.,
                individual XML element trees. These were encoded as regular XML document instances,
                but, as a single corpus comprises multiple files, there was a need to go beyond the
                functionality offered by typical XML tools to enable us to process multiple files,
                as regular tools work with single files only. The normalization process is
                described in more detail in </textual><xref class="po-milestone e77 e77" linkend="Witt2007"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">. </textual></para><figure class="po-container e78 e78" xml:id="staging"><title class="po-block e79 e79"><textual class="po-textual">Resource normalization and SPLICR's staging area.</textual></title><mediaobject class="po-container e80 e80"><imageobject class="po-container e81 e81"><imagedata class="po-meta e82 e82" fileref="../../../vol6/graphics/Witt01/Witt01-001.png" format="png"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure></section><section class="po-hcontainer e83 e83"><title class="po-block e84 e84"><textual class="po-textual">Normalization of Metadata Records</textual></title><para class="po-block e85 e85"><textual class="po-textual"> The separation of the individual annotation layers contained in a corpus has
                serious consequences with regard to legal issues: due to copyright and personal
                rights specifics that usually apply to a corpus’s primary data we provided a
                fine-grained access control layer to regulate access by means of user accounts and
                access roles. We had to be able to explicitly specify that a certain user only has
                access to the set of, say, six annotation layers (in this example they might be
                available free of charge for research purposes) but not to the primary data, because
                they might be copyright-protected. </textual></para><para class="po-block e86 e86"><textual class="po-textual"> The generic metadata schema used for SPLICR, named </textual><emphasis class="po-inline e87 e87"><textual class="po-textual">eTEI</textual></emphasis><textual class="po-textual">, was
                based on the TEI P4 header and extended by a set of additional requirements. We
                decided to store both eTEI records and also the corpora in an XML database. The
                underlying assumption was that XML-annotated datasets are more sustainable than, for
                example, data stored in a proprietary relational DBMS. The main difference between
                eTEI and other approaches is that the generic eTEI metadata schema, formalized as a
                document type definition (DTD), can be applied to five different levels of
                description. One eTEI file contains information on one of the following levels: (1)
                setting (recordings or transcripts of spoken language, describes the situation in
                which the speech or dialogue took place); (2) raw data (e.g., a book, a piece of
                paper, an audio or video recording of a conversation etc.); (3) primary data
                (transcribed speech, digital texts etc.); (4) annotations; (5) a corpus (consists of
                primary data with one or more annotation levels). We devised a workflow that helps
                users to edit eTEI records. The workflow’s primary components were the eTEI DTD and
                the Oxygen XML editor. Based on structured annotations contained in the DTD we
                automatically generate an empty XML document with embedded documentation and a
                Schematron schema. The Schematron specification is used to check whether all
                elements and attributes instantiated in an eTEI document conform to the current
                level of metadata description. </textual></para></section><section class="po-hcontainer e88 e88"><title class="po-block e89 e89"><textual class="po-textual">Architecture</textual></title><para class="po-block e90 e90"><textual class="po-textual"> The sustainability platform SPLICR consists of a front-end and a back-end. The
                front-end is the part visible to the user and is realized using JSP (Java Server Pages) and
                Ajax technology. It runs in the user’s browser and provides functions for searching
                and exploring metadata records and corpus data. The back-end hosts the JSP files and
                related data. It accesses two different databases, the corpus database and the
                system database, as well as a set of ontologies and additional components. The
                corpus database is an XML database, extended by AnnoLab, an XML/XQuery-based
                corpus query and management framework that was specifically designed to deal with
                multiple possibly concurrent annotation layers, in which all resources and metadata
                are stored. The system database is a relational database that contains all data
                about user accounts, resources (i.e., annotation layers), resource groups (i.e.,
                corpora) and access rights. A specific user can only access a specific resource if
                the permissions for this user/resource tuple allow it. </textual></para></section><section class="po-hcontainer e91 e91"><title class="po-block e92 e92"><textual class="po-textual">SPLICR: Concluding Remarks</textual></title><para class="po-block e93 e93"><textual class="po-textual"> The corpus normalization and preprocessing phase in this project started in early
                2007 and was finished in May 2008, the process of transforming the existing metadata
                records into the eTEI format was completed in June 2008. Work on the querying engine
                and integration of the XML database, metadata exploration and on the graphical
                visualization and querying front-end as well as on the back-end was carried out in
                the summer of 2008; a first prototype of the platform was finished in October 2008.
                    </textual><xref class="po-milestone e94 e94" linkend="Rehm2009"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual"> gives a more detailed description of the project.
            </textual></para></section></section><section class="po-hcontainer e95 e95"><title class="po-block e96 e96"><textual class="po-textual">XML and Sustainability: Problems and Solutions</textual></title><section class="po-hcontainer e97 e97"><title class="po-block e98 e98"><textual class="po-textual">Problem: Stand-off Annotation</textual></title><para class="po-block e99 e99"><textual class="po-textual"> Stand-off markup refers to the physical separation of annotations and 
                text. Piotr Bański described this technique thoroughly at Balisage 2010 (</textual><xref class="po-milestone e100 e100" linkend="Banski2010"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">). Stand-off annotation allows for marking up text
                without altering it by the inclusion of markup. It is the opposite approach to 
                inline or embedded markup that was one of the principle ideas behind SGML and its
                successor XML. The term </textual><emphasis class="po-inline e101 e101"><textual class="po-textual">stand-off annotation</textual></emphasis><textual class="po-textual"> was introduced
                by Henry Thompson and
                David McKelvie in 1997 (</textual><xref class="po-milestone e102 e102" linkend="thompsonetal97"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">), however the principles of
                this technique are even older, since, e.g., the linking mechanisms described in TEI P3
                already allowed to mark up texts by linking annotations to text regions. Within the
                last couple of years the use of stand-off markup became predominant, especially for
                complex linguistic annotations. </textual></para><para class="po-block e103 e103"><textual class="po-textual"> Linguistically annotated corpora use stand-off markup extensively. Stand-off is
                also predominant within the forthcoming ISO standard “Linguistic Annotation
                Framework” (LAF, </textual><xref class="po-milestone e104 e104" linkend="ide-romary2007"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">). </textual></para><figure class="po-container e105 e105" xml:id="standoff-example"><title class="po-block e106 e106"><textual class="po-textual">LAF based linguistic annotation</textual></title><programlisting class="po-block e107 e107" xml:space="preserve"><textual class="po-textual">&lt;!-- base segmantation --&gt; 
&lt;region id="r42" a="24 35"/&gt;

&lt;!-- annotation over the base segmentation --&gt;
&lt;node id="n16"&gt;
   &lt;f name="pos" value="NN"/&gt;
&lt;/node&gt;
&lt;edge from="n16" to="r42"/&gt;

&lt;!-- annotation over another annotation --&gt; 

&lt;node id="n23"&gt;
   &lt;f name="synLabel" value="NP"/&gt;
   &lt;f name="role" value="-SBJ"/&gt;
&lt;/node&gt;
&lt;edge from="n23" to="n16"/&gt;

&lt;!-- ... --&gt;</textual></programlisting><caption class="po-container e108 e108"><para class="po-block e109 e109"><textual class="po-textual">Example of linguistic stand-off annotation (see </textual><xref class="po-milestone e110 e110" linkend="Trippel2007"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">)</textual></para></caption></figure><para class="po-block e111 e111"><textual class="po-textual"> Stand-off annotation has witnessed an increase in use due to the advantages of
                this approach (see </textual><xref class="po-milestone e112 e112" linkend="Banski2010"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual"> and </textual><xref class="po-milestone e113 e113" linkend="Banski2009"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">),
                but considering the sustainability and interoperability point of view, there are 
                quite a few disadvantages (see </textual><xref class="po-milestone e114 e114" linkend="Witt2004"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">): </textual><itemizedlist class="po-table e115 e115"><listitem class="po-container e116 e116"><para class="po-block e117 e117"><textual class="po-textual">very difficult to read for humans</textual></para></listitem><listitem class="po-container e118 e118"><para class="po-block e119 e119"><textual class="po-textual">the information, although included, is difficult to access using
                            generic methods</textual></para></listitem><listitem class="po-container e120 e120"><para class="po-block e121 e121"><textual class="po-textual">limited software support as standard parsing or editing software
                            cannot be employed</textual></para></listitem><listitem class="po-container e122 e122"><para class="po-block e123 e123"><textual class="po-textual">standard document grammars can only be used for the level which
                            contains both markup and textual data</textual></para></listitem><listitem class="po-container e124 e124"><para class="po-block e125 e125"><textual class="po-textual">new layers require a separate interpretation</textual></para></listitem><listitem class="po-container e126 e126"><para class="po-block e127 e127"><textual class="po-textual">layers, although separate, often depend on each other</textual></para></listitem></itemizedlist><textual class="po-textual">
            </textual></para><para class="po-block e128 e128"><textual class="po-textual"> Our solution to overcome these problems is to process the standoff annotations
                and the annotated source text so that multiple annotations of the same text are created 
                that are archived together with the original stand-off
                resources. This approach achieves sustainability through redundancy. </textual></para></section><section class="po-hcontainer e129 e129"><title class="po-block e130 e130"><textual class="po-textual">Problem: Machine-Generated XML</textual></title><para class="po-block e131 e131"><textual class="po-textual"> Today, a lot of XML data is generated by machines. Many of those XML documents
                are used for machine-to-machine communication, e.g., as SOAP-messages in web
                services. However, these messages are rather short-lived and will not be considered
                in this paper. </textual></para><para class="po-block e132 e132"><textual class="po-textual"> A growing number of applications use XML to store documents.
                These XML documents differ greatly from handcrafted XML and are rather complicated,
                especially with respect to the semantics of their tag sets, structure and code layout
                and therefore are difficult to comprehend by humans. Since users usually do not work
                with these documents directly this issue is not of a big concern. From a sustainability
                point of view these documents present a challenge though. </textual></para><figure class="po-container e133 e133" xml:id="word-screenshot"><title class="po-block e134 e134"><textual class="po-textual">Screenshot of Microsoft Word 2007</textual></title><mediaobject class="po-container e135 e135"><imageobject class="po-container e136 e136"><imagedata class="po-meta e137 e137" fileref="../../../vol6/graphics/Witt01/Witt01-002.png" format="png"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure><para class="po-block e138 e138"><textual class="po-textual"> As an example, the figure shows a conference paper created with Microsoft Word (see </textual><xref class="po-milestone e139 e139" linkend="word-screenshot"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">).
                Since the 2007 version of Microsoft Office documents are saved by default in Office Open
                XML format (OOXML) (see </textual><xref class="po-milestone e140 e140" linkend="OOXML"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">) and are – as the name
                suggests – encoded in XML. With regard to sustainability this is, in
                principle, a step in the right direction, but OOXML itself is not sufficient. </textual><footnote class="po-popup e141 e141"><para class="po-block e142 e142"><textual class="po-textual"> In this aspect we are not arguing in favour or against the OOXML standard.
                        Whether OOXML is a good or bad standard or whether it is well designed or
                        lies not in the scope of this paper and is to be discussed elsewhere. We were
                        only interested in the generated XML code and inspected it against the
                        background of sustainability. Similar results hold for OpenDocument format
                        (ODF) documents generated by OpenOffice. </textual></para></footnote><textual class="po-textual"> Without the corresponding application the generated XML document is very hard to
                understand or to use. </textual><xref class="po-milestone e143 e143" linkend="word-xml-excerpt"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual"> shows an excerpt of the
                resulting OOXML document for the first heading and paragraph. The document is mostly
                structured by sections and paragraphs, but the OOXML structure does not show
                this structure in a transparent way. The following can be noted: </textual><itemizedlist class="po-table e144 e144"><listitem class="po-container e145 e145"><para class="po-block e146 e146"><textual class="po-textual">There is no difference in markup used for headings and paragraph. Both
                            are encoded by </textual><code class="po-atom e147 e147"><textual class="po-textual">w:p</textual></code><textual class="po-textual"> elements. A heading made different from a
                            paragraph by adding further information through the
                                </textual><code class="po-atom e148 e148"><textual class="po-textual">w:pStyle</textual></code><textual class="po-textual"> element. It's </textual><code class="po-atom e149 e149"><textual class="po-textual">w:val</textual></code><textual class="po-textual"> attribute
                            denotes whether the construct is a heading (“Heading1”) or a regular
                            paragraph (“Textkorper”). More style information is encoded
                            in additional XML files, but this still does not yield enough
                            properties to resolving their role in structuring the text. </textual></para></listitem><listitem class="po-container e150 e150"><para class="po-block e151 e151"><textual class="po-textual">The running text in the paragraph is heavily fragmented. For example
                            the words “Referenzkorpus” or “established” are – for no apparent
                            reason – both fragmented into 3 parts with a middle part which
                            only contains a single character. The fragmentation could be the result of
                            editing the document in MS Word's Track Changes mode.</textual></para></listitem><listitem class="po-container e152 e152"><para class="po-block e153 e153"><textual class="po-textual">The markup contains rather complex constructs, e.g., the handling of
                            italics. The words “Mannheimer Korpus 1” are set in italics. The
                            formatting is applied to a text-run (</textual><code class="po-atom e154 e154"><textual class="po-textual">w:r</textual></code><textual class="po-textual"> element) which has
                            formatting information applied to it by means of a </textual><code class="po-atom e155 e155"><textual class="po-textual">w:rPr</textual></code><textual class="po-textual">
                            element.</textual></para></listitem></itemizedlist><textual class="po-textual">
            </textual></para><figure class="po-container e156 e156" xml:id="word-xml-excerpt"><title class="po-block e157 e157"><textual class="po-textual">OOXML excerpt</textual></title><programlisting class="po-block e158 e158" xml:space="preserve"><textual class="po-textual">&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;
&lt;w:document xmlns:ve="http://schemas.openxmlformats.org/markup-compatibility/2006"
    xmlns:o="urn:schemas-microsoft-com:office:office"
    xmlns:r="http://schemas.openxmlformats.org/officeDocument/2006/relationships"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    xmlns:v="urn:schemas-microsoft-com:vml" xmlns:w10="urn:schemas-microsoft-com:office:word"
    xmlns:wp="http://schemas.openxmlformats.org/drawingml/2006/wordprocessingDrawing"
    xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main"
    xmlns:wne="http://schemas.microsoft.com/office/word/2006/wordml"&gt;
    &lt;!-- ... --&gt;
    &lt;w:p w:rsidR="00A77FB8" w:rsidRDefault="00A77FB8"&gt;
        &lt;w:pPr&gt;
            &lt;w:pStyle w:val="Heading1"/&gt;
            &lt;w:numPr&gt;
                &lt;w:ilvl w:val="0"/&gt;
                &lt;w:numId w:val="5"/&gt;
            &lt;/w:numPr&gt;
        &lt;/w:pPr&gt;
        &lt;w:r&gt;
            &lt;w:lastRenderedPageBreak/&gt;
            &lt;w:t&gt;Introduction&lt;/w:t&gt;
        &lt;/w:r&gt;
    &lt;/w:p&gt;
    &lt;w:p w:rsidR="00A77FB8" w:rsidRDefault="00A77FB8" w:rsidP="007357D1"&gt;
        &lt;w:pPr&gt;
            &lt;w:pStyle w:val="Textkorper"/&gt;
        &lt;/w:pPr&gt;
        &lt;w:r&gt;
            &lt;w:t&gt;The Institute for the German Language (IDS) has a long tradition in building 
            corpora. DeReKo (Deutsches Refe&lt;/w:t&gt;
        &lt;/w:r&gt;
        &lt;w:r&gt;
            &lt;w:t&gt;r&lt;/w:t&gt;
        &lt;/w:r&gt;
        &lt;w:r&gt;
            &lt;w:t xml:space="preserve"&gt;enzkorpus), the Archive of General Reference Corpora of 
            Contemporary Written German, has been set &lt;/w:t&gt;
        &lt;/w:r&gt;
        &lt;w:r w:rsidR="003A1540"&gt;
            &lt;w:t&gt;off&lt;/w:t&gt;
        &lt;/w:r&gt;
        &lt;w:r&gt;
            &lt;w:t xml:space="preserve"&gt; as the &lt;/w:t&gt;
        &lt;/w:r&gt;
        &lt;w:r&gt;
            &lt;w:rPr&gt;
                &lt;w:i/&gt;
            &lt;/w:rPr&gt;
            &lt;w:t&gt;Mannheimer Korpus 1&lt;/w:t&gt;
        &lt;/w:r&gt;
        &lt;w:r&gt;
            &lt;w:t xml:space="preserve"&gt; project in 1964. Paul Grebe and Ulrich Engel succeeded in 
            compiling a corpus of about 2.2 million running words of Written German by 1967. Since 
            then, further corpus acquisition projects esta&lt;/w:t&gt;
        &lt;/w:r&gt;
        &lt;w:r&gt;
            &lt;w:t&gt;b&lt;/w:t&gt;
        &lt;/w:r&gt;
        &lt;w:r&gt;
            &lt;w:t&gt;lished a ceaseless stream of electronic text documents and let the corpus to grow 
            steadily (Kupietz &amp;amp; Keibel, 2009).&lt;/w:t&gt;
        &lt;/w:r&gt;
    &lt;/w:p&gt;
    &lt;!-- ... --&gt;
&lt;/w:document&gt;</textual></programlisting><caption class="po-container e159 e159"><para class="po-block e160 e160"><textual class="po-textual"> An excerpt of an OOXML document produced by MS Word 2007 (the
                        document was reformatted for readability). </textual></para></caption></figure><para class="po-block e161 e161"><textual class="po-textual"> Just having data encoded in XML does not automatically make the data sustainable.
                Especially very complex tag sets such as OOXML are of very limited use if one does
                not have an application which understands these formats. For almost any given application, obtaining and using such
                a piece of software will most probably pose a big problem a few years later.
                Sustainability of software is a whole different topic by itself and is not within the scope of this paper. </textual></para><para class="po-block e162 e162"><textual class="po-textual"> As a possible solution for this problem we propose to provide the
                machine-generated XML data in multiple formats. For example, the OOXML document
                can be stored in its native format, in plain text or in Portable
                Document format (PDF). Furthermore, filters can be used to remove those XML elements and
                attributes from the machine-generated code that are not necessary. It would be even
                better to transform the machine-generated XML data to established formats such as TEI
                    (</textual><xref class="po-milestone e163 e163" linkend="TEI-P5"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">). </textual></para><para class="po-block e164 e164"><textual class="po-textual"> Other than that, one should provide various descriptions and a thorough
                documentation of the data format, not only providing the schema but also tutorials,
                conceptual descriptions or similar documents for human reimplementation of tools
                operating on the machine-generated XML code. </textual></para></section><section class="po-hcontainer e165 e165"><title class="po-block e166 e166"><textual class="po-textual">Problem: Proprietary Tag Sets</textual></title><para class="po-block e167 e167"><textual class="po-textual"> In the document lifecycle, especially when taking long-term maintenance and
                archiving into account, it is a common problem that XML tag sets and document
                grammars are being used that are not well established outside the 
                group defining the tagset. The use of XML tags following the insights and beliefs of
                the individual who wrote the schema as such does not pose the problem, but the
                interpretation of the schema by somebody reviewing the material later may cause
                problems, because no one else knows and understands the implicit logical constraints
                of tag and attribute names as well as data structures. </textual></para><para class="po-block e168 e168"><textual class="po-textual"> The usual answer to the use of proprietary tag sets would be not to use them at
                all and to replace them by standard annotation schemas and tagsets wherever
                possible. For example TEI (</textual><xref class="po-milestone e169 e169" linkend="TEI-P5"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">), tagsets developed in the
                context of the standardization processes of ISO TC 37 SC 4 (“Language Resources”) or
                DocBook for technical articles and texts (see </textual><xref class="po-milestone e170 e170" linkend="Walsh1999"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">) come to
                mind. However, these tagsets do not always fit the given problem very well and using
                them often results in the well-known problem of tag abuse: tags are used in
                unintended ways or – even worse – users confuse the semantics of tags
                with their intended use. In these cases the results are bound to be more confusing
                than starting from an idiosyncratic tagset. Therefore, if users decide to use one of
                the established tagsets they should thoughtfully select the most appropriate one for a
                given problem. </textual></para><para class="po-block e171 e171"><textual class="po-textual"> More critical are those cases in which for various reasons no established tagset
                is used. Reasons for not selecting established tagsets range from not knowing about
                tagsets, not understanding tagsets, via policy reasons to the unavailability of
                appropriate tagsets. For example commercial terminological applications may use a
                data model that is consistent with established standards (such as </textual><xref class="po-milestone e172 e172" linkend="ISO_16642"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual"> in combination with </textual><xref class="po-milestone e173 e173" linkend="ISO_30042"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">) but use a
                native XML format that is very similar but utilises different generic identifiers (for
                example SDL Trados MultiTerm 2009 shows this behaviour). The reason for this does not lie
                in the technology, but in management decisions. In each of these cases it is not
                sufficient to include the document grammar only to achieve valid XML, but further
                documentation is required. The basic idea is to document everything. </textual></para><para class="po-block e174 e174"><textual class="po-textual"> One way of approaching this problem is by providing a reference in the element
                description to an ontology or some other form of knowledge representation to define
                the data types with possible values. Data types here refer both to XML elements and
                attributes, similar to data types used in XML schema. The reference to the external
                definition of the elements allows for a human user to evaluate the correctness of
                the semantic interpretation, possibly also to automatically evaluate the content
                using a parser. With external definitions the data types are unambiguously
                described according to available means. </textual></para><para class="po-block e175 e175"><textual class="po-textual"> The definition by reference is only one part of the definition, for human use it
                is advisable to use a documentation with the tag set that uses multiple examples. This
                    </textual><emphasis class="po-inline e176 e176"><textual class="po-textual">prototype semantics</textual></emphasis><textual class="po-textual"> of a tagset is intended to explain the
                meaning of tags and attributes as applied in a given domain or application. For
                human use it is also recommended to use names that bear a certain meaning, i.e., which
                are easily interpretable by a person reading them. Interpreting and understanding
                element and attribute names and values depends on a common background of the creator
                and user. For example, it is harder if both do not use the same script or language,
                because mutual intelligibility is important. </textual></para><para class="po-block e177 e177"><textual class="po-textual"> In the field of language resources this method has been implemented with </textual><link class="po-inline e178 e178" xlink:actuate="onRequest" xlink:href="http://www.isocat.org" xlink:show="new" xlink:type="simple"><textual class="po-textual">ISOcat</textual></link><textual class="po-textual"> (</textual><xref class="po-milestone e179 e179" linkend="ISO_12620"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">).
                ISOcat is a registry for data categories used in describing terminological databases
                and language resources. All data categories needed in these fields are allowed to be
                registered with a unique identifier, definition and name in various languages. Several
                data categories have been defined, but the list is open, hence it is possible to
                insert data categories that are needed but not available in the registry yet. The
                registry consists of two parts, a private and a public section. Every data
                category that is defined or used by a project or tagset is first defined in a
                private workspace that is nevertheless part of the registry and can be reused and
                referenced. Data categories that are important for various contexts can then be
                moved from private workspaces to the public area by domain experts. This
                promotion includes a quality assessment of the definitions as well as a check for
                possible redundancy in the registry. By this means consistency and documentation of
                data categories is fostered, together with persistent identifiers of the data
                categories, even in the case of the renaming of elements. </textual></para><para class="po-block e180 e180"><textual class="po-textual"> Based on the idea of persistent category definitions, the </textual><link class="po-inline e181 e181" xlink:actuate="onRequest" xlink:href="http://www.clarin.eu/cmdi" xlink:show="new" xlink:type="simple"><textual class="po-textual">Component Metadata Infrastructure</textual></link><textual class="po-textual">
                (CMDI, see </textual><xref class="po-milestone e182 e182" linkend="Broeder2010"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">) was designed. CMDI is intended for
                describing language resources. These resources are of various types and require
                different metadata schemas to appropriately describe the contents in a form that
                allows a human user to understand what kind of resources they have to expect. Most
                of these schemas are far more detailed than traditional metadata schemas from
                archivist containing bibliographical data, but also contain keywords, abstracts,
                subject fields, participants, annotation schemas, etc. For reusability reasons the
                data categories are clustered into </textual><emphasis class="po-inline e183 e183"><textual class="po-textual">components</textual></emphasis><textual class="po-textual">, and components
                are combined to other components or to a </textual><emphasis class="po-inline e184 e184"><textual class="po-textual">profile</textual></emphasis><textual class="po-textual">, which is more
                or less a metadata schema for a specific type of resource, the components also
                allowing the definition of a value schema for each data category. The data
                categories which are used in the components do not provide their own description,
                but refer to the data category registry, for example ISOcat or Dublin Core, using 
                URIs. By this procedure, the concrete tag name becomes language, script and
                application independent, because the definition is given in a central repository.
                User interfaces are provided with the component registry web tool and the Arbil
                Metadata editor developed by the Max Planck Institute for Psycholinguistics (all
                available at the </textual><link class="po-inline e185 e185" xlink:actuate="onRequest" xlink:href="http://www.clarin.eu/cmdi" xlink:show="new" xlink:type="simple"><textual class="po-textual">CMDI site</textual></link><textual class="po-textual">).
            </textual></para></section><section class="po-hcontainer e186 e186"><title class="po-block e187 e187"><textual class="po-textual">Problem: Availability and Findability</textual></title><para class="po-block e188 e188"><textual class="po-textual"> Many researchers creating language resources are more than willing to share their
                resources with close colleagues upon request. However, for various reasons such as
                personal, privacy or property rights they tend to restrict public access to these
                resources. Furthermore, resources created in research contexts are usually designed for
                specific purposes such as the analysis of specific linguistic phenomena. The resource itself is
                mostly not visible, because research publications discuss the phenomena and their
                analysis, but usually do not describe the resource in great detail. However, these
                publications are often the only documentation for the existence of the resource and describe the rationale behind their creation.
                Hence, accessibility to language resources is a major problem to be dealt with. </textual></para><para class="po-block e189 e189"><textual class="po-textual"> Especially in fields with a large economic interest in linguistic resources, such
                as statistical language processing and machine learning, data centres or distribution
                agencies were created to address the problem of accessibility. These data centres provide
                material in large quantities and they use rather flat structures for their data.
                In contrast, resources created by individual research projects and researchers
                are often deeply structured and tend to be much more detailed and complex.
                Data centres have standard procedures for intellectual property rights handling and
                cataloguing resources using bibliographical procedures. Language resources from
                commercially less interesting areas or resources that are deeply structured, can
                hardly be found in these data centres. Even if such resources are accessible
                elsewhere, they cannot be reliably located by general search engines. Most often
                they will only be part of the statistical noise of general search engine results.
                There are some specialized search engines, such as ODIN (see
                    </textual><link class="po-inline e190 e190" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.csufresno.edu/odin</textual></link><textual class="po-textual">) for interlinear glossed text, but
                they usually do not provide users with knowledge about the text type and what kind
                of structures and content to expect in the resource. </textual></para><para class="po-block e191 e191"><textual class="po-textual"> The solution is well-known from the initial ideas around the semantic web: metadata descriptions of resources should be used that are based on standards,
                quasi-standards, best practice and which are used for specialized catalogues of
                resources. Providing exhaustive metadata records enables a possible user to
                understanding the structures and content of a resource, not necessarily the document
                grammar, but at least they would give a fair idea on the theory behind it. </textual></para><para class="po-block e192 e192"><textual class="po-textual"> Providing metadata refers to issues of proprietary tagsets and controlled
                vocabulary again. The keywords used to describe a resource ideally refer to a
                conceptual space, in which all concepts are well defined and classified according to
                superordinate and subordinate terms. The reference to the concept system or to an
                ontology requires standardized values. Standardized values means that a central,
                accessible structure needs to provide them, i.e., a kind of a registry such as ISOcat.
            </textual></para><para class="po-block e193 e193"><textual class="po-textual"> In the process of metadata creation different perspectives can be taken: the
                perspective of the author of the resource, the software engineer, the publisher and
                the person looking for a resource later, to name just a few.
                These different roles in relation to a resource are not mutually exclusive in terms
                of metadata categories, but in the creation process different areas are emphasized. For 
                example the publisher will usually be more interested in
                making sure that the copyright is explicitly defined than the user searching for a
                specific resource to be employed for a specific use case. Software engineers will be
                interested in technical features, while archivist require bibliographical data. </textual></para><para class="po-block e194 e194"><textual class="po-textual"> For the creation of metadata it is essential to use the perspective of
                prospective users. Though it can be argued that not all possible users and their
                requirements can possibly be anticipated, the perspective of users, especially with
                other backgrounds, helps to include not only technically relevant metadata but also
                descriptive metadata relevant for human users. Technical metadata here means those
                bits of information required by someone implementing tools for processing the data,
                while descriptive metadata refers to those classifications that help a possible user
                to understand the content of a resource before actually seeing it. </textual></para><para class="po-block e195 e195"><textual class="po-textual"> Taking various user groups into account when selecting the descriptive detail of
                metadata also allows the design of structured search engines. Structured search
                engines here refer to search engines not only interpreting the textual content of
                pages but that take into account the structure of the metadata. The intention behind
                using the structure of metadata is to provide search results with a higher
                precision while providing a high recall at the same time, which is not necessarily
                achieved by full text based search engines. </textual></para><para class="po-block e196 e196"><textual class="po-textual"> Additionally it is recommended to make these datasets available through as many
                national and international catalogues and initiatives in the respective field or sub-field as
                possible (see </textual><xref class="po-milestone e197 e197" linkend="sec-conclusion"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">) and also to enable harvesting of metadata sets using OAI-PMH. With the help of these catalogues
                it is possible to announce the availability of the dataset to the scientific
                community using websites, blogs, etc.
            </textual></para></section><section class="po-hcontainer e198 e198"><title class="po-block e199 e199"><textual class="po-textual">Problem: Selection and Qualification for Long-Term Archiving</textual></title><para class="po-block e200 e200"><textual class="po-textual"> In the past, resources were either available or not, a lot of data was lost due
                to conversion problems, technical failure, etc. For each of these there are
                technical solutions, but a major problem remains in the question: what is worth
                archiving? Resources undergo a life cycle and in general it is agreed that not every
                step in the life cycle is worth being archived. In contrast to that, some resources
                are supposed to be archived, even if they did not reach the archival phase of the
                intended life cycle. Finding formal criteria for deciding upon archiving or not is a major
                problem that still remains unsolved, one that might be unsolvable as such. </textual></para><para class="po-block e201 e201"><textual class="po-textual"> Criteria for deciding which resource should be archived fall into different
                categories: status, technical quality, organizational and institutional
                requirements, extent of use, quality evaluation and longevity. Some of these
                criteria depend on each other, but can be evaluated independently and therefore be
                used to measure the need for archiving a resource. </textual></para><para class="po-block e202 e202"><textual class="po-textual"> The status of a resource defines the formal editing status, starting from first
                draft versions to released or published versions, etc. Projects that work with a
                life cycle model in resource creation need to archive those documents that are in
                the archiving phase. Naming conventions and value schemas for the different phases 
                vary greatly. However, the archive status cannot be the sole criterion,
                because in some projects resources get stuck in an earlier state and do not reach the
                publication phase, but considering other criteria, they nevertheless may qualify for
                or even require long-term archiving. </textual></para><para class="po-block e203 e203"><textual class="po-textual"> Especially for technological applications the technical quality can be of prime
                importance. For some testing environments it is sufficient to have a resource that
                is technically adequate and has the correct size, so it can serve as a reference point
                or for testing procedures, algorithms and technologies, even if the content and
                status as such are incomplete and still pending improvement. Consequently, the
                technical quality can be a decisive factor for long-term archiving. </textual></para><para class="po-block e204 e204"><textual class="po-textual"> Institutionalized requirements may force data providers to submit material, for
                example close to the end of a project life, while others are hesitant in providing
                data for various reasons, even if the quality is much higher. These requirements are
                usually negotiated with archivists and partners, but often result in
                archiving the resource regardless of other criteria. </textual></para><para class="po-block e205 e205"><textual class="po-textual"> A resource that is widely used by various groups needs to be archived regardless
                of other factors, because it is used as a reference Ὰ ignoring other criteria
                such as quality and status. One reason could be that it is the only resource
                available or has unique properties. Though the use of a resource by a variety of
                users is complex to evaluate, this criterion seems to be obvious. </textual></para><para class="po-block e206 e206"><textual class="po-textual"> Quality is another factor in an evaluation matrix. In contrast to an approach
                which might be termed a take-whatever-you-can-get approach in archiving, archiving
                material without prior evaluation is not desired, as the information flood becomes
                unmanageable, if not for saving, then for retrieval and search. The assessment can
                be both formal by algorithmic processes that can also provide information on the
                technical quality mentioned before, or by a peer reviewing process. In the latter,
                experts decide on the quality of a resource and based on this judgment a resource is
                archived or disregarded. </textual></para><para class="po-block e207 e207"><textual class="po-textual"> Even more problematic but essential is the question of longevity of a resource. A
                resource that is most likely to be usable for a long period of time is supposed to
                be archived. The usability over a long period depends on the application of a
                resource. If the resource answers to demands that are continuously present, then the
                resource needs to be available, hence archived, even if the number of users might be
                small. </textual></para><para class="po-block e208 e208"><textual class="po-textual"> When measuring all of these criteria separately it is comparatively easy to
                define a threshold of criteria that need to be fulfilled in order for a resource to
                be archived. The threshold is selected in a way that each criteria can serve as an
                overriding criterion, that is, if one of these criteria mandates archiving, then the
                resource will be archived. But if there is no criteria with this requirement, the
                values can accumulate. If the threshold is not set too low, the resource will then be
                archived. </textual></para><para class="po-block e209 e209"><textual class="po-textual"> The ultimate goal for working with resources is of course to achieve a high
                quality resource, that is highly regarded by experts, used and usable for many
                years, and reaches a maturity level that is technically well established, etc.
                However, for most resources there are limitations that are not supposed to interfere
                as knock-out criteria for long-term archiving. </textual></para></section><section class="po-hcontainer e210 e210"><title class="po-block e211 e211"><textual class="po-textual">Additional Pitfalls</textual></title><para class="po-block e212 e212"><textual class="po-textual"> Technical sustainability is one aspect of sustainability. Other major aspects are
                organizational sustainability and legal issues – two issues not to be
                underestimated. While the technical sustainability is an engineering task which
                seems to be solved in most cases with semi-automatic migration procedures for
                digital devices, this is not true for organizational and legal aspects.</textual></para><para class="po-block e213 e213"><textual class="po-textual">
                </textual><xref class="po-milestone e214 e214" linkend="Eide2008"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual"> claim that organizational sustainability may even be more
                important than technical sustainability, because valuable resources can easily be
                lost when an organization is shut down. They list several examples from cultural
                heritage management, where shutting down museums almost lead to the loss of
                resources, e.g., the Newham case where data was only saved because the staff acted
                quickly and dumped it to floppy disks. Sometimes, the resources also exist on paper and
                could be digitized again, but as there is a movement away from paper, this option
                will cease to exist soon. </textual></para><para class="po-block e215 e215"><textual class="po-textual">Organizational sustainability is a rather fragile process because it correlates
                with funding and institutional commitment, which are rather soft and fragile factors. 
                Due to the structure of funding organizations it is hardly
                possible to receive a statement of commitment for a very long period of time. For
                example, the duration of German collaborative research centres is limited to 12
                years. Other long time programs exist, but it is virtually impossible to find a
                commitment for more than 20 years. Therefore, ventures in sustainability also need
                to consider the organizational aspect with a proper strategy how to guarantee taking care
                of resources in the years to come – either by securing continuity of
                the organization itself or by preparing and implementing a proper migration plan for
                resources to a different organization. Preparing for both cases would be even
                better. </textual></para><para class="po-block e216 e216"><textual class="po-textual"> Another issue are legal aspects. Especially in the field of linguistics,
                intellectual property rights create their own set of problems which have to be dealt
                with when thinking about sustainability (see </textual><xref class="po-milestone e217 e217" linkend="Lehmberg2008"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual"> and
                    </textual><xref class="po-milestone e218 e218" linkend="Zimmermann2007"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">). These issues are investigated in the context
                of international projects such as CLARIN and META-NET; the current direction is
                to work out licensing models (see </textual><xref class="po-milestone e219 e219" linkend="Linden2010"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual"> and </textual><xref class="po-milestone e220 e220" linkend="Weitzmann2010"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">). These intellectual property rights issues are
                especially tricky as linguistic resources often cross political and cultural
                borders, hence not only legal issues but also ethical implications are involved. </textual></para></section></section><section class="po-hcontainer e221 e221" xml:id="sec-conclusion"><title class="po-block e222 e222"><textual class="po-textual">Conclusions</textual></title><para class="po-block e223 e223"><textual class="po-textual"> Sustainability of language resources is an aspect wanted and needed by data
            providers, users and funders alike. To be able to speak of sustainable resources it is
            necessary to make resources available according to defined processes, platforms or
            archives in a reproducible and reliable way. To this end, XML is an essential part of a
            complex approach which, additionally, also encompasses other standards on multiple
            levels. These are requirements, but tools and systems, accessible in a reliable manner
            and operating based on standards, are important as well. </textual></para><para class="po-block e224 e224"><textual class="po-textual"> With SPLICR there is a proof-of-concept implementation of large parts of the
            functionality required for sustainability platforms. A platform alone is a node in the
            sustainable web of trusted resource repositories, each repository providing
            organizational support, technical infrastructure with archiving technology, and being
            entrusted to use specified procedures to respect privacy and rights of data providers
            while providing non-discriminatory access to the resources according to stated
            procedures and rights holders restrictions. Part of this network is also the cooperation
            of various national and international initiatives. In cases of sustainability a certain
            amount of overlap between these projects is desirable to further foster interoperation
            and reliability of tools, data centres and increase redundant archives, avoiding major
            problems in disaster scenarios. </textual></para><para class="po-block e225 e225"><textual class="po-textual"> All in all it can be said that with a number of international projects such as CLARIN
            and META-NET along with its META-SHARE open resource exchange facility, together with
            the initial implementations of various tools, the development of standards in the ISO
            Technical Committee 37, Subcommittee 4 “Language Resources” (see </textual><link class="po-inline e226 e226" xlink:actuate="onRequest" xlink:href="http://www.tc37sc4.org/" xlink:show="new" xlink:type="simple"><textual class="po-textual">TC 37 SC 4</textual></link><textual class="po-textual">) and establishment of
            de-facto procedures, the sustainability of language resources is no longer something
            that needs to be argued for. Instead, the situation has changed dramatically, as the
            very real problem of providing sustainable data sets is, by now, firmly anchored in
            academic as well as commercially oriented research centres. With raised awareness in
            the community, the continuation of language resource distribution projects and
            institutional support by academic libraries and institutions, chances are more than
            promising for providing sustainable resources, using XML technology and state of the art
            processes. </textual></para></section><bibliography class="po-hcontainer e227 e227"><title class="po-block e228 e228"><textual class="po-textual">References</textual></title><bibliomixed class="po-block e229 e229" xml:id="Banski2009" xreflabel="Bański &amp; Przepiórkowski 2009"><textual class="po-textual"> Bański, P.
            and Przepiórkowski, A. “Stand-off TEI annotation: the case of the National Corpus of
            Polish”. In: </textual><emphasis class="po-inline e230 e230" role="ital"><textual class="po-textual">Proceedings of the Third Linguistic Annotation
                Workshop (LAW III)</textual></emphasis><textual class="po-textual"> at ACL-IJCNLP 2009, Singapore, 2009, pages
            64–67. </textual></bibliomixed><bibliomixed class="po-block e231 e231" xml:id="Banski2010" xreflabel="Bański 2010"><textual class="po-textual"> Bański, P. “Why TEI stand-off
            annotation doesn't quite work and why you might want to use it nevertheless”. In:
                </textual><emphasis class="po-inline e232 e232" role="ital"><textual class="po-textual">Proceedings of Balisage 2010. Series on Markup
                Technologies</textual></emphasis><textual class="po-textual">, vol. 6, 2010. doi: </textual><biblioid class="po-atom e233 doi e233"><textual class="po-textual">10.4242/BalisageVol5.Banski01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e234 e234" xml:id="Broeder2010" xreflabel="Broeder et al. 2010"><textual class="po-textual"> Broeder, D.,
            Kemps-Snijders, M., Van Uytvanck, D., Windhouwer, M., Withers, P., Wittenburg, P. and
            Zinn, C. “A Data Category Registry- and Component-based Metadata Framework”. In:
                </textual><emphasis class="po-inline e235 e235" role="ital"><textual class="po-textual">Proceedings of LREC 2010</textual></emphasis><textual class="po-textual">, Malta, 2010,
            pp. 43–47 </textual></bibliomixed><bibliomixed class="po-block e236 e236" xml:id="Carletta2003" xreflabel="Carletta et al. 2003"><textual class="po-textual"> Carletta, J., Kilgour,
            J., O'Donnell, T., Evert, S., Voormann, H. “The NITE Object Model Library for Handling
            Structured Linguistic Annotation on Multimodal Data Sets”. In: </textual><emphasis class="po-inline e237 e237" role="ital"><textual class="po-textual">Proceedings of the EACL Workshop on Language Technology and the Semantic Web (3rd
                Workshop on NLP and XML)</textual></emphasis><textual class="po-textual">. </textual></bibliomixed><bibliomixed class="po-block e238 e238" xml:id="Eide2008" xreflabel="Eide et al. 2008"><textual class="po-textual"> Eide, Ø., Ore, C.-E. and
            Holmen, J. “Sustainability in Cultural Heritage Management”. In: </textual><emphasis class="po-inline e239 e239" role="ital"><textual class="po-textual">Proceedings of Digital Humanities 2008</textual></emphasis><textual class="po-textual">, Oulu, Finnland,
            pp. 22–23. </textual></bibliomixed><bibliomixed class="po-block e240 e240" xml:id="ide-romary2007" xreflabel="Ide &amp; Romary 2007"><textual class="po-textual"> Ide, N. and Romary,
            L. “Towards International Standards for Language Resources”. In: Dybkjær, L., Hemsen,
            H., Minker, W. (eds.), </textual><emphasis class="po-inline e241 e241" role="ital"><textual class="po-textual">Evaluation of Text and Speech Systems,
                Springer</textual></emphasis><textual class="po-textual">, pages 263–284. </textual></bibliomixed><bibliomixed class="po-block e242 e242" xml:id="ISO_12620" xreflabel="ISO 12620:2009"><textual class="po-textual"> ISO 12620:2009. “Terminology and
            other language and content resources – Specification of data categories and
            management of a Data Category Registry for language resources”. </textual></bibliomixed><bibliomixed class="po-block e243 e243" xml:id="ISO_16642" xreflabel="ISO 16642:2003"><textual class="po-textual"> ISO 16642:2003. “Computer
            applications in terminology – Terminological markup framework”. </textual></bibliomixed><bibliomixed class="po-block e244 e244" xml:id="ISO_30042" xreflabel="ISO 30042:2008"><textual class="po-textual"> ISO 30042:2008. “Systems to
            manage terminology, knowledge and content – TermBase eXchange (TBX)”. </textual></bibliomixed><bibliomixed class="po-block e245 e245" xml:id="OOXML" xreflabel="ISO/IEC 29500:2008"><textual class="po-textual"> ISO/IEC 29500:2008. “Information
            technology – Office Open XML formats”. </textual></bibliomixed><bibliomixed class="po-block e246 e246" xml:id="Lehmberg2008" xreflabel="Lehmberg et al. 2008"><textual class="po-textual"> Lehmberg, T., Rehm, G.,
            Witt, A. and Zimmermann, F. “Digital Text Collections, Linguistic Research Data, and
            Mashups: Notes on the Legal Situation”. In: </textual><emphasis class="po-inline e247 e247" role="ital"><textual class="po-textual">Library
                Trends</textual></emphasis><textual class="po-textual">, 57/1, pp. 52–71. doi: </textual><biblioid class="po-atom e248 doi e248"><textual class="po-textual">10.1353/lib.0.0023</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e249 e249" xml:id="Linden2010" xreflabel="Lindén et al. 2010"><textual class="po-textual"> Lindén, K., Oksanen, V. and
            Bruun, S. (eds) “CLARIN Classification Guide for Deposition Licenses – First
            comprehensive summary about licensing problems”. To appear. </textual></bibliomixed><bibliomixed class="po-block e250 e250" xml:id="Rehm2009" xreflabel="Rehm et al. 2009"><textual class="po-textual"> Rehm, G., Schonefeld, O., Witt,
            A., Hinrichs, E. and Reis, M. Sustainability of annotated resources in linguistics: “A
            web-platform for exploring, querying, and distributing linguistic corpora and other
            resources”. In: </textual><emphasis class="po-inline e251 e251" role="ital"><textual class="po-textual">Literary &amp; Linguistic Computing (LLC) –
                Journal of the Association for Literary and Linguistic Computing</textual></emphasis><textual class="po-textual">, 24
            (2009) 2, pp. 193–210. doi: </textual><biblioid class="po-atom e252 doi e252"><textual class="po-textual">10.1093/llc/fqp003</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e253 e253" xml:id="TEI-P5" xreflabel="TEI P5"><textual class="po-textual"> The TEI Consortium (ed.) “Guidelines for
            Electronic Text Encoding and Interchange (TEI P5)”. The TEI Consortium, 2007.
                </textual><link class="po-inline e254 e254" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.tei-c.org/Guidelines/P5/</textual></link><textual class="po-textual">. </textual></bibliomixed><bibliomixed class="po-block e255 e255" xml:id="thompsonetal97" xreflabel="Thompson &amp; McKelvie 1997"><textual class="po-textual"> Thompson, H.
            and McKelvie, D. “Hyperlink semantics for standoff markup of read-only documents”. In:
                </textual><emphasis class="po-inline e256 e256" role="ital"><textual class="po-textual">Proceedings of SGML Europe</textual></emphasis><textual class="po-textual">, 1987.
                </textual><link class="po-inline e257 e257" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.ltg.ed.ac.uk/~ht/sgmleu97.html</textual></link><textual class="po-textual">. </textual></bibliomixed><bibliomixed class="po-block e258 e258" xml:id="Trippel2007" xreflabel="Trippel et al. 2007"><textual class="po-textual"> Trippel, T., Declerck, T.
            and Ide, N. “Interoperable Language Resources”. In: SDV Sprache und
            Datenverarbeitung/International Journal for Language Data Processing, Volume
            31.1–2, pp. 101–113 </textual></bibliomixed><bibliomixed class="po-block e259 e259" xml:id="Walsh1999" xreflabel="Walsh &amp; Muellner 1999"><textual class="po-textual"> Walsh, N. and
            Muellner, L. “DocBook: The Definitive Guide”, Sebastopol, O'Reilly Media, 1999. </textual></bibliomixed><bibliomixed class="po-block e260 e260" xml:id="Weitzmann2010" xreflabel="Weitzmann et al. 2010"><textual class="po-textual"> Weitzmann, J. H.,
            Rehm, G and Uszkoreit, H. “Licensing and Sharing Language Resources: An Approach
            Inspired by Creative Commons and Open Science Data Movements”. In: </textual><emphasis class="po-inline e261 e261" role="ital"><textual class="po-textual">LREC 2010 Workshop Legal Issues for Sharing Language Resources: Constraints and
                Best Practices</textual></emphasis><textual class="po-textual">, May 17, Malta, 2010. </textual></bibliomixed><bibliomixed class="po-block e262 e262" xml:id="Witt2004" xreflabel="Witt 2004"><textual class="po-textual"> Witt, A. “Multiple Hierarchies: New
            Aspects of an Old Solution.”. In: </textual><emphasis class="po-inline e263 e263" role="ital"><textual class="po-textual">Proceedings of Extreme Markup
                Languages 2004</textual></emphasis><textual class="po-textual">, Montréal, Canada, 2004 </textual></bibliomixed><bibliomixed class="po-block e264 e264" xml:id="Witt2007" xreflabel="Witt et al. 2007"><textual class="po-textual"> Witt, A., Schonefeld, O., Rehm,
            G., Khoo, J. and Evang, K. “On the Lossless Transformation of Single-File, Multi-Layer
            Annotations into Multi-Rooted Trees”. In: </textual><emphasis class="po-inline e265 e265" role="ital"><textual class="po-textual">Proceedings of Extreme
                Markup Languages 2007</textual></emphasis><textual class="po-textual">, Montréal, Canada, 2007. </textual></bibliomixed><bibliomixed class="po-block e266 e266" xml:id="Zimmermann2007" xreflabel="Zimmermann et al. 2007"><textual class="po-textual"> Zimmermann, F. and
            Lehmberg, T. “Language Corpora – Copyright – Data Protection: The Legal Point of View”.
            In: </textual><emphasis class="po-inline e267 e267" role="ital"><textual class="po-textual">Proceedings of Digital Humanities 2008</textual></emphasis><textual class="po-textual">,
            Urbana-Champaign, United Stated, pp. 162–164. </textual></bibliomixed></bibliography></article></classedDocument>