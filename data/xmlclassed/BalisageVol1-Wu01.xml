<?xml version="1.0" encoding="UTF-8" standalone="no"?><classedDocument><article xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" class="po-hcontainer e0 e0" version="5.0-subset Balisage-1.2" xml:id="HR-23632987-8973"><title class="po-block e1 e1"><textual class="po-textual">A Hybrid Parallel Processing for XML Parsing and Schema Validation</textual></title><info class="po-record e2 e2"><confgroup class="po-record e3 e3"><conftitle class="po-field e4 e4"><textual class="po-textual">Balisage: The Markup Conference 2008</textual></conftitle><confdates class="po-field e5 e5"><textual class="po-textual">August 12 - 15, 2008</textual></confdates></confgroup><abstract class="po-container e6 e6"><para class="po-block e7 e7"><textual class="po-textual">XML is playing crucial roles in web services, databases, and document representing and processing. However, the processing of XML document has been regarded as the main performance bottleneck especially for the processing of very large XML data. On the other hand, multi-core processing gains increasingly popularity both on the desktop computers and server computing machines. To take full advantage of multi-cores, we present a novel hybrid parallel XML processing model, which combines data-parallel and pipeline processing. It first partitions the XML by chunks to perform data parallel processing for both XML parsing and schema validation, then organize and execute them as a two stage pipeline to exploit more parallelism. The hybrid parallel XML processing model has shown great overall performance advantage on multi-core platform as indicated by the experiment performance results.</textual></para></abstract><author class="po-record e8 e8"><personname class="po-record e9 e9"><firstname class="po-field e10 e10"><textual class="po-textual">Yu</textual></firstname><surname class="po-field e11 e11"><textual class="po-textual">Wu</textual></surname></personname><personblurb class="po-container e12 e12"><para class="po-block e13 e13"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></para></personblurb><affiliation class="po-record e14 e14"><orgname class="po-block e15 e15"><textual class="po-textual">Intel Corporation</textual></orgname></affiliation><email class="po-field e16 e16"><textual class="po-textual">yu.y.wu@intel.com</textual></email></author><author class="po-record e17 e17"><personname class="po-record e18 e18"><firstname class="po-field e19 e19"><textual class="po-textual">Qi</textual></firstname><surname class="po-field e20 e20"><textual class="po-textual">Zhang</textual></surname></personname><personblurb class="po-container e21 e21"><para class="po-block e22 e22"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></para></personblurb><affiliation class="po-record e23 e23"><orgname class="po-block e24 e24"><textual class="po-textual">Intel Corporation</textual></orgname></affiliation><email class="po-field e25 e25"><textual class="po-textual">qi.zhang@intel.com</textual></email></author><author class="po-record e26 e26"><personname class="po-record e27 e27"><firstname class="po-field e28 e28"><textual class="po-textual">Zhiqiang</textual></firstname><surname class="po-field e29 e29"><textual class="po-textual">Yu</textual></surname></personname><personblurb class="po-container e30 e30"><para class="po-block e31 e31"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></para></personblurb><affiliation class="po-record e32 e32"><orgname class="po-block e33 e33"><textual class="po-textual">Intel Corporation</textual></orgname></affiliation><email class="po-field e34 e34"><textual class="po-textual">zhiqiang.yu@intel.com</textual></email></author><author class="po-record e35 e35"><personname class="po-record e36 e36"><firstname class="po-field e37 e37"><textual class="po-textual">Jianhui</textual></firstname><surname class="po-field e38 e38"><textual class="po-textual">Li</textual></surname></personname><personblurb class="po-container e39 e39"><para class="po-block e40 e40"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></para></personblurb><affiliation class="po-record e41 e41"><orgname class="po-block e42 e42"><textual class="po-textual">Intel Corporation</textual></orgname></affiliation><email class="po-field e43 e43"><textual class="po-textual">jian.hui.li@intel.com</textual></email></author><legalnotice class="po-container e44 e44"><para class="po-block e45 e45"><textual class="po-textual">Copyright Â© 2008 Intel Corporation. Used by permission.</textual></para></legalnotice></info><section class="po-hcontainer e46 e46"><title class="po-block e47 e47"><textual class="po-textual">Introduction</textual></title><section class="po-hcontainer e48 e48"><title class="po-block e49 e49"><textual class="po-textual">The challenge of XML Parsing and Schema Validation</textual></title><para class="po-block e50 e50"><textual class="po-textual">Extensible Markup Language (XML) has been playing crucial roles in web services, databases and document processing fields. However, it has been commonly perceived that the verbosity of XML incurs heavy processing overhead. Several academic and industry efforts have been made to accelerate the XML processing, trying to mitigate the performance pain point. [6-10]</textual></para><para class="po-block e51 e51"><textual class="po-textual">XML parsing and schema validation are two major XML processing loads in most XML based applications. XML parsing provides the infoset and XML Schema validation determines type information for every node of the document. Beside use on the application perimeter to validate input XML messages [1][2], the schema-aware processing gains are significance inside application, using XML processing languages like XPath2.0/XSLT2.0, accessing XML database, or mapping to Java objects.</textual></para><para class="po-block e52 e52"><textual class="po-textual">The schema validation adds extra significant overhead into XML parsing [5]. For example, the eBay Web services specification has a few thousand elements and hundreds of complex type definitions. Communicating with eBay via the SOAP protocol requires processing of large XML documents [2]. Benchmark analysis [3][4] shows that most implementations of Web services do not scale well as the size of XML document increases.</textual></para></section><section class="po-hcontainer e53 e53"><title class="po-block e54 e54"><textual class="po-textual">Parallel XML Processing and Multi-cores</textual></title><para class="po-block e55 e55"><textual class="po-textual">On the hardware front, a recent trend in computer architecture is the rapid adoption of chip multiprocessors (CMPs), commonly referred as multi-core processors. Intel, as an example, has shipped several of multi-core processors from 2 cores to 8 cores and is even leading the trend from multi-core to many-core with their future-oriented 80-core chip research project[12]. It's no doubt that tomorrow's computers will have more cores rather than exponentially faster clock speeds. As more and more web services based applications are deploying on multi-core processors, the heavy XML processing in web services will need to take full advantage of multi-core processing.</textual></para><para class="po-block e56 e56"><textual class="po-textual">In this paper, we present a hybrid parallel processing model for XML parsing and schema validation, which combines data-parallel and pipeline parallelization model to achieve high performance and good scalability. The parsing and schema validation are two major pipeline stages in this model and are both based on a novel chunk-based speculative parallel XML processing algorithm. The parallel algorithm first partitions the XML document by chunks and then apply data-parallel model to process each chunk in parallel.</textual></para><para class="po-block e57 e57"><textual class="po-textual">Several efforts have been made in this field to parallelize XML parsing. Wei Lu first presented a pre-scanning based parallel parsing model, which consisted of an initial pre-scanning phase to determine the structure of the XML document, followed by a full, parallel parser [6]. The results of pre-scanning phase are used to help partition the XML document for data parallel processing. The research continued with an attempt to parallelize the pre-scanning stage to exploit more parallelism [8]. Michael R.Head also explored new techniques for parallelizing parsers for very large XML documents [7]. They did not focus on developing parallel XML parsing algorithm, but exposing the parallelism by dividing XML parsing process into several phases, such as XML data loading, XML parsing and result generation, and then scheduling working threads to execute each parsing phase in a pipeline model. The paper discussed a bunch of performance issues such as load imbalance and communication and synchronization overhead. Parabix uses parallel bitstream technology [10], in its XML parsing by exploiting the SSE vector instructions in the Intel architecture [9].</textual></para><para class="po-block e58 e58"><textual class="po-textual">Compared to other approaches, our approach tries to avoid the pre-scanning overhead [6], as we discovered the pre-scanning overhead is considerable especially after we improved the parsing performance [9]. Our the algorithm is chunk-based and each parallel sub-task is to process a chunk, it helps processing a large document without loading it into the memory. The vectorization approach [10] can be used in the each parallel sub-task and therefore complementary to our approach. Moreover, our paper is the first one describing the parallel schema validation and the hybrid parallel model. The performance evaluation results show the performance benefits by this model and parallel XML parsing and schema validation.</textual></para><para class="po-block e59 e59"><textual class="po-textual">The rest of the paper is organized as follows. Section 2 introduces hybrid parallel XML processing model. Sections 3 and 4 focus on parallel XML parsing and parallel schema validation algorithms. The last section gives the performance evaluation results and makes a performance comparison with an existed parallel XML parser model.</textual></para></section></section><section class="po-hcontainer e60 e60"><title class="po-block e61 e61"><textual class="po-textual">Hybrid Parallel XML Processing Model</textual></title><para class="po-block e62 e62"><textual class="po-textual">The hybrid parallel XML processing model showing in figure 1 combines pipeline and data-parallel model to expose more parallelism and achieve better scalability.</textual></para><section class="po-hcontainer e63 e63"><title class="po-block e64 e64"><textual class="po-textual">Pipeline Execution in XML Processing</textual></title><para class="po-block e65 e65"><textual class="po-textual">XML processing can be executed as pipeline. Figure 1 shows two pipeline stages, parsing and validation. The two stages can execute as a pipeline based on chunks, which means, the parsing stages inputs the XML document by chunks and outputs parsed chunks while validation stage inputs the parsed chunk from previous stage and do validation against each parsed chunk if it's necessary. After that, it either associates PSVI information with each node in the chunk or produce a simple Boolean to indicate whether the document is valid.</textual></para><para class="po-block e66 e66"><textual class="po-textual">However, the common challenge for a pipeline model is how to maintain load balance among pipeline stages. As the speed of producing the parsed chunk can be different than the consumption speed of the validator and the difference may vary for different chunks.  The parsed chunk pool acts as a cushion to absorb these differences. The more detailed discussion about how to assure load balance in pipeline model is out of the scope of this paper.</textual></para></section><section class="po-hcontainer e67 e67"><title class="po-block e68 e68"><textual class="po-textual">Apply Data-parallel Model</textual></title><para class="po-block e69 e69"><textual class="po-textual">Both the parsing and validation stages can apply chunk based data-parallel model respectively to exploit more parallelism.</textual></para><para class="po-block e70 e70"><textual class="po-textual">As shown in figure 1, parsing stage contains a number of XML parsers. At first, the input XML document is partitioned into chunks and put into a chunk pool. All of XML parsers can start speculative parsing once an input chunk in the chunk pool is available even though not receiving the whole input XML document. Any parser may perform chunk partition when the chunk number in the pool is less than a given threshold. After finishing parsing a chunk, the information for the chunk is not complete, the parallel parser must carry out post processing for the chunk after all preceding chunks are parsed. After that, the parsed chunks hold the complete infoset information for the corresponding input chunk and can be put into parsed chunk pool to be processed by next stage.</textual></para><para class="po-block e71 e71"><textual class="po-textual">Similarly, the validation stage contains multiple parallel validators, each of which can perform partial validation once a parsed chunk is available. The parallel validator reads the parsed chunk from the pool directly. After validating one chunk, the post processing should be executed for all of preceding chunks to produce final validation result.</textual></para><figure class="po-container e72 e72" floatstyle="1" xml:id="hybrid" xreflabel="hybrid"><mediaobject class="po-container e73 e73"><imageobject class="po-container e74 e74"><imagedata class="po-meta e75 e75" fileref="../../../vol1/graphics/Wu01/Wu01-001.jpg" format="jpg" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e76 e76"><para class="po-block e77 e77"><textual class="po-textual">Hybrid parallel XML processing model</textual></para></caption></mediaobject></figure></section></section><section class="po-hcontainer e78 e78"><title class="po-block e79 e79"><textual class="po-textual">Parallel XML Parsing</textual></title><para class="po-block e80 e80"><textual class="po-textual">Parallel XML parsing scans an XML document in parallel as well as checking the well-formedness and generates the parsing result. The XML document is divided into chunks so that each parser works on a chunk independently and generates its own partial result that is merged in document order during the post processing step to produce the final result.</textual></para><para class="po-block e81 e81"><textual class="po-textual">The key to the parallel XML parsing algorithm is how to parse a chunk as a part of an XML document without seeing the whole document. A chunk may start in the middle of some string whose context and grammatical role is unknown. For example, a chunk may start as a part of element name or attribute or text value. Without this information, the parser does not know how to parse a chunk.</textual></para><para class="po-block e82 e82"><textual class="po-textual">We present speculative XML parsing to address this issue. Speculative parsing can produce partial result for each chunk and delegate uncompleted work to post processing.</textual></para><para class="po-block e83 e83"><textual class="po-textual">To support the speculative processing, we use a simple DOM-like XML tree(S-TREE) as our internal representation and the final parsing result. The node in S-TREE only has parent and first children link and all of sibling nodes are organized as document order, which is very memory efficient. S-TREE can be partially generated in the initial parsing step with the rest of the information completed in the later post processing step. We use the term of partial S-TREE to refer a partially generated S-TREE by speculative parsing for one chunk and all of partial S-TREEs can be linked together to be a completed one after post processing.</textual></para><para class="po-block e84 e84"><textual class="po-textual">Figure 2 provides a detailed look at the parser. The speculative parsing based algorithm brings additional overhead: the chunk partition and the post processing. However, the overhead is much smaller than the pre-scanning overhead [6] and it can be amortized as the task can be done in parallel with speculative parsing. As shown in the figure, typically the chunk partition and the post processing are carried out only once although each parallel parser may perform the function. Comparably, the pre-scanning based algorithm [6] requires a pre-scanning over the whole document to get the skeleton of an XML document before parallel parsing can start.</textual></para><figure class="po-container e85 e85" floatstyle="1" xml:id="PXP" xreflabel="pxp"><mediaobject class="po-container e86 e86"><imageobject class="po-container e87 e87"><imagedata class="po-meta e88 e88" fileref="../../../vol1/graphics/Wu01/Wu01-002.jpg" format="jpg" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e89 e89"><para class="po-block e90 e90"><textual class="po-textual">Parallel XML Parsing Algorithm</textual></para></caption></mediaobject></figure><section class="po-hcontainer e91 e91"><title class="po-block e92 e92"><textual class="po-textual">Chunk Partition</textual></title><para class="po-block e93 e93"><textual class="po-textual">Chunk partition divides the whole or part of XML document into several of approximately equal-sized chunks and puts them into the chunk pool. The chunk size can be decided at run time to assure 1) each chunk should be big enough to minimize the number of chucks and reduce the post processing workload. 2) each parsing thread has one chunk to be processed at least, that is, the number of chunks should be larger than the number of working threads.</textual></para><para class="po-block e94 e94"><textual class="po-textual">An issue for chunk partition is that a chunk may start in the middle of some string as we have discussed before. To make use of speculative parsing, we force each chunk must start with left angle bracket "&lt;" by forward searching in XML during partition. By this way, each chunk can be regarded as a new XML document though it may not be well-formed.</textual></para></section><section class="po-hcontainer e95 e95"><title class="po-block e96 e96"><textual class="po-textual">Speculative Parsing</textual></title><para class="po-block e97 e97"><textual class="po-textual">This step parses each chunk and generates partial S-TREE.</textual></para><para class="po-block e98 e98"><textual class="po-textual">Because each chunk always begins with left angle bracket "&lt;", our parser works the same way as a single threaded or traditional parser does. However, a traditional parser may throw an exception if a chunk is not well-formed. For example, figure 3-a is a possible chunk partition for a sample XML document, we can find the chunk 3 is not well-formed for it starts with an end element. </textual></para><para class="po-block e99 e99"><textual class="po-textual">Speculative parsing deals with this issue by catching and classifying all of ill-formed exceptions. We have identified that there are three types of ill-formed exceptions. Each exception implies there is an unresolved element. All of unresolved elements can be further processed in post processing step.</textual></para><para class="po-block e100 e100"><textual class="po-textual">1) Unresolved Start Element; which means the start element has no corresponding end element in current chunk. The unresolved start elements include "catalog", "book", and "title" in the first chunk of figure 3-a.</textual></para><para class="po-block e101 e101"><textual class="po-textual">2) Unresolved End Element; which means the end element appeared when there is no matched start element in current chunk. Like the element "title" in the second chunk of figure 3-a.</textual></para><para class="po-block e102 e102"><textual class="po-textual">3) Unresolved Prefix; which means the prefix has no associated namespace definition in current chunk. Like the prefix "bw" in the second chunk of figure 3-a.</textual></para><figure class="po-container e103 e103" floatstyle="1" xml:id="Xsample" xreflabel="sample"><mediaobject class="po-container e104 e104"><imageobject class="po-container e105 e105"><imagedata class="po-meta e106 e106" fileref="../../../vol1/graphics/Wu01/Wu01-003.jpg" format="jpg" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e107 e107"><para class="po-block e108 e108"><textual class="po-textual">Figure3-a A sample XML includes three chunks</textual></para></caption></mediaobject><mediaobject class="po-container e109 e109"><imageobject class="po-container e110 e110"><imagedata class="po-meta e111 e111" fileref="../../../vol1/graphics/Wu01/Wu01-004.jpg" format="jpg" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e112 e112"><para class="po-block e113 e113"><textual class="po-textual">Figure3-b Speculative Parsing Result of sample XML</textual></para></caption></mediaobject></figure><para class="po-block e114 e114"><textual class="po-textual">The unresolved start and end elements of a chunk are added to UnresolvedEE queue and UnresolvedSE queue respectively. For each unresolved start element, it also records the context information like namespace definition. In addition, the Qname of the start element and end element are recorded to help the well-formedness check in the post processing. The unresolved prefixes are recorded and later on resolved in the post processing step. Figure 3-b gives the speculative parsing result for each chunk of figure 3-a, which contains generated partial S-TREEs and unresolved elements.</textual></para><para class="po-block e115 e115"><textual class="po-textual">Speculative parsing of a chunk may produce a number of partial S-TREEs. A new S-TREE is produced whenever the element has no parent in the current chunk. For example, the chunk 2 generates two partial S-TREEs as shown in figure 3-b. For each S-TREE, a relative depth is recorded to indicate his distance between the current tree and the tree with lowest level.</textual></para></section><section class="po-hcontainer e116 e116"><title class="po-block e117 e117"><textual class="po-textual">Post-Processing</textual></title><para class="po-block e118 e118"><textual class="po-textual">The post processing propagates the context information and performs residual processing including checking well-formedness across chunks, resolving unresolved prefix and linking partial S-TREEs. As post processing has to be sequentially executed in one parallel parser, the algorithm is designed to be highly efficient.</textual></para><section class="po-hcontainer e119 e119"><title class="po-block e120 e120"><textual class="po-textual">Context information</textual></title><para class="po-block e121 e121"><textual class="po-textual">The post processing propagates context information from the first chunk to the succeeding chunks. The context information is used in the residual processing to complete the parsing of a partial processed chunk. The context information has to include QName, namespace definition and node reference of each unresolved start element in the UnresolvedSE queue to support well-formedness checking, unresolved prefix resolving and partial S-TREEs linking. The context information has to be prepared beforehand at the partial processing as long as the UnresolvedSE queues are formed.</textual></para></section><section class="po-hcontainer e122 e122"><title class="po-block e123 e123"><textual class="po-textual">Well-formedness Checking</textual></title><para class="po-block e124 e124"><textual class="po-textual">Parallel XML parsing uses two steps to check the well-formedness against an XML document. First, speculative parsing checks the well-formedness inside a chunk and post processing checks unresolved start and end element with a simple and efficient algorithm illustrated in figure 4. In this algorithm, N indicates the number of parsed chunks. </textual></para><figure class="po-container e125 e125" floatstyle="1" xml:id="wellform" xreflabel="wellform"><mediaobject class="po-container e126 e126"><imageobject class="po-container e127 e127"><imagedata class="po-meta e128 e128" fileref="../../../vol1/graphics/Wu01/Wu01-005.jpg" format="jpg" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e129 e129"><para class="po-block e130 e130"><textual class="po-textual">Well-formedness checking algorithm</textual></para></caption></mediaobject></figure><para class="po-block e131 e131"><textual class="po-textual">This algorithm maintains the global context stack and matches its unresolved start element with the unresolved end elements in the UnresolvedEE queue for each chunk consecutively. After the last chunk has been processed, the global context stack and the UnresolvedEE queue of the chunk should be empty, which indicates all of start elements have matched all of end elements. Then the whole XML document is well-formed; otherwise it throws ill-formed exception.</textual></para></section><section class="po-hcontainer e132 e132"><title class="po-block e133 e133"><textual class="po-textual">Resolving Unresolved Prefix</textual></title><para class="po-block e134 e134"><textual class="po-textual">In a well-formed XML document, any prefix must bind to a determined namespace. Speculative parsing can't bind an unresolved prefix to any namespace because its namespace may be defined in a preceding chunk.</textual></para><para class="po-block e135 e135"><textual class="po-textual">To resolve unresolved prefixes, the post processing treats the namespace as context information and propagates the namespace information when maintaining the global context stack. It looks up all the ancestors of the element from its direct parent to the root element of XML document in global context stack to find the first matched namespace definition. If successful, all elements with the prefix associate the matched namespace; otherwise it throws unrecognized prefix exception.</textual></para><para class="po-block e136 e136"><textual class="po-textual">However, there is an exception for resolving default namespace. If there is no matched default namespace definition for a default prefix, it should not report any error. Because XML specification has specified a pre-defined default namespace, it's not necessary to define a new default namespace in an XML document.</textual></para></section><section class="po-hcontainer e137 e137"><title class="po-block e138 e138"><textual class="po-textual">Linking Partial S-TREEs</textual></title><para class="po-block e139 e139"><textual class="po-textual">This step links partial S-TREEs together to be a complete S-TREE representing the original XML document. The key to this step is finding the correct parent for the root node of each partial S-TREE. So element's depth is introduced to indicate the relevant depth for the element in its own chunk, which is equal to number of unresolved end element appearing before the element in current chunk. The figure 5 shows how a partial S-TREE is linked to the trunk tree. In this algorithm, N stands for the total number of chunks.</textual></para><figure class="po-container e140 e140" floatstyle="1" xml:id="DOMmerge" xreflabel="dommerge"><mediaobject class="po-container e141 e141"><imageobject class="po-container e142 e142"><imagedata class="po-meta e143 e143" fileref="../../../vol1/graphics/Wu01/Wu01-006.jpg" format="jpg" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e144 e144"><para class="po-block e145 e145"><textual class="po-textual">Partial S-TREE Linking algorithm</textual></para></caption></mediaobject></figure><para class="po-block e146 e146"><textual class="po-textual">After this step, a chunk of XML data can be represented by a number of partial S-TREEs whose information is complete enough that it can be processed by another application, for example, parallel schema validator can start validation based on partial S-TREEs to expose more data-parallel opportunity.</textual></para></section></section></section><section class="po-hcontainer e147 e147"><title class="po-block e148 e148"><textual class="po-textual">Parallel Schema Validation</textual></title><para class="po-block e149 e149"><textual class="po-textual">Like parallel XML parsing, the basic idea of parallel schema validation is dividing the whole validation task into a set of subtasks, where each subtask validates a chunk of the document. Schema validation can work on partial S-TREE directly rather than the raw XML data. The validation stage has two phases, partial validation and residual validation, corresponding to speculative parsing and post processing in section 3. The figure 6 provides a more detailed look at the parallel validation.</textual></para><figure class="po-container e150 e150" floatstyle="1" xml:id="PSV" xreflabel="psv"><mediaobject class="po-container e151 e151"><imageobject class="po-container e152 e152"><imagedata class="po-meta e153 e153" fileref="../../../vol1/graphics/Wu01/Wu01-007.jpg" format="jpg" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e154 e154"><para class="po-block e155 e155"><textual class="po-textual">Parallel Schema Validating</textual></para></caption></mediaobject></figure><section class="po-hcontainer e156 e156"><title class="po-block e157 e157"><textual class="po-textual">Partial Validation</textual></title><para class="po-block e158 e158"><textual class="po-textual">Partial validation starts with schema validation on the partial S-TREEs, which can be regarded as a subtask of the whole validation process starting from one of generated partial S-TREE so that partial validation can be executed in parallel based on having multiple partial S-TREEs. Usually, a finite state machine is used to describe the validation process. To validate a partial S-TREE, we must determine the schema type for the root element of a partial tree to initialize start of the start of the finite state machine.</textual></para><para class="po-block e159 e159"><textual class="po-textual">According to schema definition, we can look up all of ancestors for a specific element to determine its schema type. As described in last section, each partial S-TREE must be linked into the preceding parsed chunks before being validated. So the ancestor link for the root element of a partial S-TREE is available. As long as the schema type of the root element is determined, the whole partial S-TREE can be validated. After finishing validating all of partial S-TREEs in a chunk it generates schema context information for all of unresolved start elements in current chunk, and summaries the type information in validation summary, which can be used in residual processing. The algorithm detail is shown in figure 7.</textual></para><figure class="po-container e160 e160" floatstyle="1" xml:id="Partialval" xreflabel="pval"><mediaobject class="po-container e161 e161"><imageobject class="po-container e162 e162"><imagedata class="po-meta e163 e163" fileref="../../../vol1/graphics/Wu01/Wu01-008.jpg" format="jpg" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e164 e164"><para class="po-block e165 e165"><textual class="po-textual">Partial Validation Algorithm</textual></para></caption></mediaobject></figure></section><section class="po-hcontainer e166 e166"><title class="po-block e167 e167"><textual class="po-textual">Residual Validation</textual></title><para class="po-block e168 e168"><textual class="po-textual">Residual validation merges the partial validation result in document order. In fact, it just resumes to validate the unresolved start elements in a chunk which has been suspended due to its child nodes are not available in that chunk. The only difference of residual validation from traditional validation process is that it will use the information kept in validation summary to do the validation work other than retrieving from original XML document. Figure 8 describes the algorithm.</textual></para><figure class="po-container e169 e169" floatstyle="1" xml:id="Reval" xreflabel="reval"><mediaobject class="po-container e170 e170"><imageobject class="po-container e171 e171"><imagedata class="po-meta e172 e172" fileref="../../../vol1/graphics/Wu01/Wu01-009.jpg" format="jpg" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e173 e173"><para class="po-block e174 e174"><textual class="po-textual">Residual Validation Algorithm</textual></para></caption></mediaobject></figure></section></section><section class="po-hcontainer e175 e175"><title class="po-block e176 e176"><textual class="po-textual">Performance Evaluation</textual></title><para class="po-block e177 e177"><textual class="po-textual">This section gives the performance evaluation result. In our experiment, we use the high performance XML parser in the IntelÂ® XML Software Suite as the baseline, which offers 80M/sec throughput single-thread performance on the 2.66G Xeon test machine [9]. We first analyzed the performance breakdown for our hybrid parallel processing model for XML parsing and schema validation. Then we measured performance of our standalone parallel parser, which only parsing and try to analyze its speedup and overhead for documents with different size. Then we make a comparison between speculative parsing based XML parser and the pre-scanning based approach, using our prototype parallel parsers with the two approaches. At last, we show the performance improvement on schema validating parser which integrates parallel parsing and schema validation.</textual></para><para class="po-block e178 e178"><textual class="po-textual">These performance measurements were taken on a Dual Intel Xeon 5300 processor machine (2.66GHz, Quad Core, Shared 8M L2 cache) with 4G RAM. The underlying operating system for these tests was Redhat Linux EL4 (kernel 2.6.9).  The test cases are taken from Intel's XML Parsing Benchmark [11], whose cases are all from real customer and varied in XML size, number of elements and element nesting depth. For example, the size of test cases is in ranging from 5K to 20M and the element nesting depth is from zero to six.</textual></para><para class="po-block e179 e179"><textual class="po-textual">To minimize external system effects on our results, we had exclusive access to the machine during testing. Every test ran ten times, to get the average time the first time was discard, so as to measure performance with the XML document data already cached rather than being read from disk. </textual></para><section class="po-hcontainer e180 e180"><title class="po-block e181 e181"><textual class="po-textual">Performance Breakdown</textual></title><para class="po-block e182 e182"><textual class="po-textual">Our parallel XML processing model performs the pipeline stages as described, and thus we can measure the time of each stage. The sequential stages include chunk partition, post processing in XML parsing and residual validation in schema validation. The speculative parsing and partial validation can be done in parallel. Figure 9 shows the average time consuming percentage of each stage from two threads to eight threads.</textual></para><para class="po-block e183 e183"><textual class="po-textual">First, we find the percentage of effort related to chunk partition is nearly zero. The main reason is that speculative parsing algorithm can start parsing any part of XML as long as it starts with left angle bracket "&lt;", which simplifies the chunk partition algorithm.</textual></para><para class="po-block e184 e184"><textual class="po-textual">As thread number increases up to eight, we observe the percentage for another two sequential stages, post processing and residual validation grows from 10% to 35%. If excluding the overhead caused by lock contention, the time consumed by the two stages is in direct ratio to chunk number and average element depth of an XML document. For example, the worst situation is that the first chunk only has start element while the second one only contains end element, which hints the XML document has very high depth. We also measure the performance breakdown for such worst XML case.  The result shows the percentage taking by post processing and residual validation is less than 50% in 8 threads, which is acceptable because such worst XML case is rare exception.</textual></para><figure class="po-container e185 e185" floatstyle="1" xml:id="Pbreak" xreflabel="Pbreak"><mediaobject class="po-container e186 e186"><imageobject class="po-container e187 e187"><imagedata class="po-meta e188 e188" fileref="../../../vol1/graphics/Wu01/Wu01-010.jpg" format="jpg" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e189 e189"><para class="po-block e190 e190"><textual class="po-textual">Performance Breakdowns</textual></para></caption></mediaobject></figure></section><section class="po-hcontainer e191 e191"><title class="po-block e192 e192"><textual class="po-textual">Standalone Parallel Parser Performance</textual></title><para class="po-block e193 e193"><textual class="po-textual">Standalone parallel parser only parses the XML document in parallel and generate DOM-like tree. We use the term speedup to measure how well the parallel algorithm scales and evaluate the efficiency of parallel algorithms.  Speedup is calculated by dividing sequential time by the parallel execution time. We use the XML parser in IntelÂ® XML Software Suite as the baseline to get the sequential execution time. The parallel time is the time our parallel XML parser spends on build the same DOM-like tree. Figure 10 shows how the parallel algorithm scales with the number of threads when parsing the XML document with different document size.</textual></para><figure class="po-container e194 e194" floatstyle="1" xml:id="purePerf" xreflabel="pureperf"><mediaobject class="po-container e195 e195"><imageobject class="po-container e196 e196"><imagedata class="po-meta e197 e197" fileref="../../../vol1/graphics/Wu01/Wu01-011.jpg" format="jpg" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e198 e198"><para class="po-block e199 e199"><textual class="po-textual">Speedup of standalone parallel parser on XML document with different size</textual></para></caption></mediaobject></figure><para class="po-block e200 e200"><textual class="po-textual">From the figure 10, we can see that the bigger the XML document size, the higher speedup of parallel parser can achieve. Because bigger XML document can be split into more subtasks to be parsed in parallel and can maximize the utilization of multi-processors. This algorithm has very good speedup for large XML documents. It is even nearly three times faster than sequential parsing with four threads. The speedup for large documents is also nearly 4.5 with eight threads. But the overhead of thread communication and lock contention is becoming significant when the total sequential parsing time is very short for small XML documents. That's the reason why there is no performance gain for small XML documents less than 64K. But parallel parser can filter these cases at run time by setting a threshold of minimum XML document size. It still makes sense because parallel parser is designed for speeding up the parsing of large XML documents. </textual></para><para class="po-block e201 e201"><textual class="po-textual">Besides, we made a performance comparison analysis against an alternative parallel parser prototype presented in paper [6]. Before we use the speculative execution based approach, we have developed a prototype using the pre-scanning approach. Figure 11 gives the performance comparison result for the two parallel XML parsing algorithms on large XML document. The result shows the performance of our speculative parsing based parser has significantly higher speed-up. Also, the pre-scanning based parsing approach doesn't scale very well when we use 8 threads on 8-core machine. </textual></para><figure class="po-container e202 e202" floatstyle="1" xml:id="comPerf" xreflabel="comperf"><mediaobject class="po-container e203 e203"><imageobject class="po-container e204 e204"><imagedata class="po-meta e205 e205" fileref="../../../vol1/graphics/Wu01/Wu01-012.jpg" format="jpg" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e206 e206"><para class="po-block e207 e207"><textual class="po-textual">Performance Comparison for two Algorithms</textual></para></caption></mediaobject></figure><para class="po-block e208 e208"><textual class="po-textual">Speculative parsing based parser avoids the pre-scanning process and reduces the sequential execution time as much as possible. An initial evaluation result shows that the average overhead of pre-scanning is hundreds times slower than the overhead introduced by the sequential execution time of our parallel algorithm, which explains the reason that speculative execution based parallel parser performs better than the pre-scanning based parallel parser.</textual></para></section><section class="po-hcontainer e209 e209"><title class="po-block e210 e210"><textual class="po-textual">Parallel validated parser performance</textual></title><para class="po-block e211 e211"><textual class="po-textual">A validating parser performs validation during parsing. Our parallel validating parser is an integration of parallel parsing and parallel schema validation with a pipeline model. Schema validating parser has two usual usage models. The first, named parallel validator only validates the XML document and gives the validation result against a given schema. The other also outputs a DOM-like tree with type information at the same time, named parallel validating DOM parser.</textual></para><para class="po-block e212 e212"><textual class="po-textual">Figure 12 gives the speedup for pure parallel parsing, standalone parallel validation and parallel validated DOM parser respectively on large XML documents, using XML schema validator in IntelÂ® XML Software Suite as our baseline. The speedup of parallel validating DOM parser reaches above 5 on the 8-core test machine. The speedup of parallel validator is slightly slower as the baseline uses a faster mode which avoids generating the intermediate DOM-like tree. The better speedup of parallel validator than that of standalone parallel parser demonstrate the former exposes more parallelism by integrating parallel XML parsing and schema validation while has lower overhead of parallel validation by using the information summary in the residual processing</textual></para><figure class="po-container e213 e213" floatstyle="1" xml:id="threePerf" xreflabel="threeperf"><mediaobject class="po-container e214 e214"><imageobject class="po-container e215 e215"><imagedata class="po-meta e216 e216" fileref="../../../vol1/graphics/Wu01/Wu01-013.jpg" format="jpg" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e217 e217"><para class="po-block e218 e218"><textual class="po-textual">Speedup of Three Parallel Parsers</textual></para></caption></mediaobject></figure></section></section><section class="po-hcontainer e219 e219"><title class="po-block e220 e220"><textual class="po-textual">Conclusion</textual></title><para class="po-block e221 e221"><textual class="po-textual">In this parser, we describe a new parallel XML parsing algorithm with great performance and that scales well for up to eight cores by means of speculative based parsing. Then we develop a novel parallel schema validation algorithm which can validate partial DOM-like trees generated by parallel XML parsers. Based on the two parallel algorithms, a hybrid parallel processing model is presented. This model organizes XML parsing and schema validation as a two stages execution pipeline and then apply data-parallel for each stage to expose more parallelism.  Our results have shown this hybrid parallel XML processing model is effective and very efficient.</textual></para></section><section class="po-hcontainer e222 e222"><title class="po-block e223 e223"><textual class="po-textual">LEGAL INFORMATION</textual></title><para class="po-block e224 e224"><textual class="po-textual">This paper is for informational purposes only. THIS DOCUMENT IS PROVIDED "AS IS" WITH NO WARRANTIES WHATSOEVER, INCLUDING ANY WARRANTY OF MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR ANY PARTICULAR PURPOSE, OR ANY WARRANTY OTHERWISE ARISING OUT OF ANY PROPOSAL, SPECIFICATION OR SAMPLE. Intel disclaims all liability, including liability for infringement of any proprietary rights, relating to use of information in this specification. No license, express or implied, by estoppel or otherwise, to any intellectual property rights is granted herein.</textual></para><para class="po-block e225 e225"><textual class="po-textual">Intel, the Intel logo, Intel leap ahead, Intel leap ahead logo, Intel Core, are trademarks of Intel Corporation in the United States and other countries.</textual></para><para class="po-block e226 e226"><textual class="po-textual">*Other names and brands may be claimed as the property of others.</textual></para></section><bibliography class="po-hcontainer e227 e227"><title class="po-block e228 e228"><textual class="po-textual">Bibliography</textual></title><bibliomixed class="po-block e229 e229" xml:id="A1" xreflabel="Singh2003"><textual class="po-textual">G. Singh, S. Bharathi, A. Chervenak, E. Deelman, C. Kesselman, M.Manohar, S. Patil, and L. Pearlman. "A Metadata Catalog Service for Data Intensive Applications" In SC'03: Proceedings of the 2003 ACM/IEEE conference on Supercomputing, page 33</textual></bibliomixed><bibliomixed class="po-block e230 e230" xml:id="A2" xreflabel="eBay"><textual class="po-textual">eBay. eBay Developers Program </textual><link class="po-inline e231 e231" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://developer.ebay.com/developercenter/soap</textual></link></bibliomixed><bibliomixed class="po-block e232 e232" xml:id="A3" xreflabel="Head2005"><textual class="po-textual">M. R. Head, M. Govindaraju, A. Slominski, P. Liu, N. Abu-Ghazaleh, R. van Engelen, K. Chiu, and M. J. Lewis. "A Benchmark Suite for SOAP-based Communication in Grid Web Services." In SC'05: Proceedings of the 2005 ACM/IEEE conference on Supercomputing, page 19, Washington, DC, USA, 2005. IEEE Computer Society. doi: </textual><biblioid class="po-atom e233 doi e233"><textual class="po-textual">10.1109/SC.2005.2</textual></biblioid></bibliomixed><bibliomixed class="po-block e234 e234" xml:id="A4" xreflabel="Head2006"><textual class="po-textual">M. R. Head, M. Govindaraju, R. van Engelen, and W. Zhang. "Benchmarking XML Processors for Applications in Grid Web Services".  In SC'06: Proceedings of the 2006 ACM/IEEE conference on Supercomputing, page 121, New York, NY, USA, 2006. ACM Press. doi: </textual><biblioid class="po-atom e235 doi e235"><textual class="po-textual">10.1145/1188455.1188581</textual></biblioid></bibliomixed><bibliomixed class="po-block e236 e236" xml:id="A5" xreflabel="Nicola2003"><textual class="po-textual">Nicola, M. and John, J., "XML Parsing: a Threat to Database Performance" International Conference on Information and Knowledge Management, 2003, pp. 175-178. doi: </textual><biblioid class="po-atom e237 doi e237"><textual class="po-textual">10.1145/956863.956898</textual></biblioid></bibliomixed><bibliomixed class="po-block e238 e238" xml:id="A6" xreflabel="WeiLu2006"><textual class="po-textual">W. Lu, K. Chiu, and Y. Pan "A parallel approach to XML parsing". In The 7th IEEE/ACM International Conference on Grid Computing, Barcelona, September 2006. doi: </textual><biblioid class="po-atom e239 doi e239"><textual class="po-textual">10.1109/ICGRID.2006.311019</textual></biblioid></bibliomixed><bibliomixed class="po-block e240 e240" xml:id="A7" xreflabel="Michael"><textual class="po-textual">Michael R. Head and Madhusudhan Govindaraju. "Approaching a Parallelized XML Parser Optimizedfor Multi-Core Processor"</textual></bibliomixed><bibliomixed class="po-block e241 e241" xml:id="A8" xreflabel="Yinfei"><textual class="po-textual">Yinfei Pan, Ying Zhang, Kenneth Chiu, Wei Lu, "Parallel XML Parsing Using Meta-DFA", Proceedings of the Third IEEE International Conference on e-Science and Grid Computing</textual></bibliomixed><bibliomixed class="po-block e242 e242" xml:id="A9" xreflabel="Intel"><textual class="po-textual">Intel Â® XML Software Suite </textual><link class="po-inline e243 e243" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.intel.com/cd/software/products/asmo-na/eng/366637.htm</textual></link></bibliomixed><bibliomixed class="po-block e244 e244" xml:id="A10" xreflabel="parabix"><textual class="po-textual">parabix, </textual><link class="po-inline e245 e245" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://parabix.costar.sfu.ca</textual></link></bibliomixed><bibliomixed class="po-block e246 e246" xml:id="A11" xreflabel="Intel"><textual class="po-textual">Intel Â® XML Software Suite Performance Paper </textual><link class="po-inline e247 e247" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://softwarecommunity.intel.com/isn/downloads/softwareproducts/pdfs/XSSPerformancePaper.pdf</textual></link></bibliomixed><bibliomixed class="po-block e248 e248" xml:id="A12" xreflabel="Intel"><textual class="po-textual">Intel Multi-core Architecture Briefing.</textual><link class="po-inline e249 e249" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.intel.com/pressroom/archive/releases/20080317fact.html</textual></link></bibliomixed></bibliography></article></classedDocument>