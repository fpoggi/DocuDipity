<?xml version="1.0" encoding="UTF-8"?><article xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0-subset Balisage-1.3"><title>The MLCD Overlap Corpus (MOC)</title><subtitle>Project report</subtitle><info><confgroup><conftitle>Balisage: The Markup Conference 2012</conftitle><confdates>August 7 - 10, 2012</confdates></confgroup><abstract><para> The MLCD Overlap Corpus (MOC) is a collection of samples of texts and text fragments
        with overlapping structures. The main immediate goal of the MOC project is to build a corpus
        of well understood and well documented examples of overlap, discontinuity, alternate
        ordering, and related phenomena in various notations, for use in the investigation of
        methods of recording such phenomena. The samples should be of use in documenting the history
        of proposals for dealing with overlap and in evaluating existing and new proposals. </para></abstract><author><personname><firstname>Yves</firstname><surname>Marcoux</surname></personname><personblurb><para>Yves MARCOUX is a faculty member at EBSI, University of Montréal, since
          1991. He is mainly involved in teaching and research activities in the field of document
          informatics. Prior to his appointment at EBSI, he has worked for 10 years in systems
          maintenance and development, in Canada, the U.S., and Europe. He obtained his Ph.D. in
          theoretical computer science from University of Montréal in 1991. His main
          research interests are document semantics, structured document implementation
          methodologies, and information retrieval in structured documents. Through GRDS, his
          research group at EBSI, he has been principal architect for the Governmental Framework for
          Integrated Document Management, a project funded by the National Archives of
          Québec and by the Québec Treasury Board.</para></personblurb><affiliation><jobtitle>Associate Professor</jobtitle><orgname>Université de Montréal</orgname></affiliation><email>yves.marcoux@umontreal.ca</email></author><author><personname><firstname>Claus</firstname><surname>Huitfeldt</surname></personname><personblurb><para>Mag.art. Claus Huitfeldt (born 1957) is Associate Professor
          (førsteamanuensis) at the Department of Philosophy of the University of Bergen
          since 1994. </para><para> He was founding Director (1990-2000) of the Wittgenstein Archives at the University
          of Bergen, for which he developed the text encoding system MECS as well as the editorial
          methods for the publication of <emphasis>Wittgenstein's Nachlass — The Bergen
            Electronic Edition</emphasis> (Oxford University Press, 2000).</para><para> He was Research Director (2000-2002) of Aksis (Section for Culture, Language and
          Information Technology at the Bergen University Research Foundation). In 2003 he returned
          to his position at the Department of Philosophy, where he teaches modern philosophy and
          philosophy of language, and also gives frequent courses in text technology at the The
          Department of Humanistic Informatics. </para><para> He was active in the Text Encoding Initiative (TEI) since 1991, and was centrally
          involved in the foundation of the TEI Consortium in 2001. The consortium now counts more
          than 90 member institutions. </para><para> Huitfeldt's research interests are within philosophy of language, philosophy of
          technology, text theory, editorial philology and markup theory. He is currently leader of
          the project Markup Languages for Complex Documents (MLCD).</para></personblurb><affiliation><jobtitle>Associate Professor (førsteamanuensis)</jobtitle><orgname>Department of Philosophy, University of Bergen</orgname></affiliation></author><author><personname><firstname>C. M.</firstname><surname>Sperberg-McQueen</surname></personname><personblurb><para> C. M. Sperberg-McQueen is the founder of Black Mesa Technologies LLC, a consultancy
          specializing in the use of descriptive markup to help memory institutions preserve
          cultural heritage information for the long haul. He has served as co-editor of the XML 1.0
          specification, the Guidelines of the Text Encoding Initiative, and the XML Schema
          Definition Language (XSD) 1.1 specification. He holds a doctorate in comparative
          literature. </para></personblurb><affiliation><orgname>Black Mesa Technologies LLC</orgname></affiliation></author><legalnotice><para>Copyright © 2012 by the authors</para></legalnotice></info><!--<note>
    <para><emphasis role="bold">Note to reviewers:</emphasis> The project described here has been
      discussed informally at Balisage before, but it has never been formally presented
    there.</para>
  </note>--><para>For some time now, people interested in descriptive markup have been considering the problem
    of how best to handle overlapping structures in electronic representations of documents. There
    have been proposals for handling such overlap in SGML using <code>CONCUR</code>, for handling it
    in SGML or XML using application-level semantics (milestone elements, Trojan Horse markup,
    fragmentation and recombination using virtual elements of various kinds, standoff markup), for
    resurrecting <code>CONCUR</code> in the XML context, and for a variety of non-XML approaches
    (colored XML, LMNL, Just-in-Time trees, TexMecs, Goddag structures, EARMARK). The literature on
    the subject is still manageable, but it has grown to the point where it is hard to keep track
    even of the number of reviews of the literature.<footnote><para> For methods of handling overlap in SGML, see [<xref linkend="Barnard1988"/>] and [<xref linkend="Barnard1995"/>]; some of the techniques described there are also applicable in
        XML. For the <code>CONCUR</code> feature of SGML (not available in XML) and a proposal to
        extend XML by adding it back, see [<xref linkend="cdhms"/>], [<xref linkend="Hilbert_etal2005"/>], [<xref linkend="Schonefeld_2007"/>], and [<xref linkend="WLSG-2005"/>].</para><para> Generic and specific milestone elements, and several forms of fragmentation and
        recombination are described in [<xref linkend="p3"/>] and again in [<xref linkend="p5"/>];
        Trojan Horse markup is described in [<xref linkend="DeRose2004"/>]. </para><para> Standoff markup has been invented and described many times; [<xref linkend="Barnard1995"/>] describes the generic technique, and vocabulary-specific use of
        standoff markup is described by [<xref linkend="p3"/>], [<xref linkend="Carletta2005"/>],
          [<xref linkend="Chatti2007"/>], [<xref linkend="SDF"/>], [<xref linkend="Stuhrenberg_and_Jettka_2009"/>], and [<xref linkend="p5"/>], among many others. </para><para> Among the many non-XML approaches suggested are those described by [<xref linkend="Jagadish_et_al._2004"/>] (colored XML), [<xref linkend="LMNL2002"/>] (LMNL),
          [<xref linkend="Durusau_and_ODonnell_2002b"/>] (Just-in-Time trees), [<xref linkend="Huitfeldt_and_Sperberg-McQueen_2003"/>] (TexMecs), [<xref linkend="Sperberg-McQueen_and_Huitfeldt_2000"/>] (Goddag structures), and [<xref linkend="EARMARK_2009"/>] (Earmark). Some of these propose alternative syntaxes, others
        alternative data models, others are sketchy on both topics. </para><para> Some but not all papers begin with a survey of the history of the topic, or at least a
        nod in that direction, but most of these are cursory and incomplete. Among the better
        surveys are those of [<xref linkend="DeRose2004"/>] and [<xref linkend="witt2004"/>].
      </para></footnote>
  </para><para>The proliferation of proposals has led to some secondary phenomena which seem to be problems
    in their own right. Because there are so many proposals for dealing with overlap, it can be
    difficult to keep track of them all. Because so many of the papers describing them use only a
    few terse examples it can be challenging to understand just how the proposal works in practice,
    and unclear just how any given proposal resembles or differs from other proposals made
    elsewhere. Most important of all, it is currently difficult to compare different techniques for
    dealing with overlap with each other and reach well founded conclusions as to their relative
    convenience.</para><para>The MLCD Overlap Corpus (MOC) is a first step toward improving this situation. This paper
    describes the current state of MOC and future plans for the project.</para><section xml:id="aims"><title>Aims</title><para>The main immediate goal of the MOC project is to build a corpus of well understood and
      well documented examples of overlap, discontinuity, alternate ordering, and related phenomena
      in various notations, for use in the investigation of methods of recording such phenomena.</para><para>Where possible, we would like to allow, indeed to encourage, participation of and
      contributions from a wider community in building the corpus. When the corpus has reached a
      suitable size and degree of completeness, we would also like to make it available for research
      and to encourage its use.</para><para>To address the concerns which led to the project, the MOC corpus should satisfy a number
      of requirements. <itemizedlist><listitem><para>It should provide illustrative examples to make it easier to understand various
            overlap solutions. </para></listitem><listitem><para>It should provide readily available documentation of overlap proposals (with
            pointers to the original papers).</para></listitem><!--<listitem><para>It should thus serve as a guide to the history of
discussions of overlap, to help fight the tendency
toward amnesia that characterizes the field of markup
theory.</para></listitem>--><!-- Commented out the preceding point, CH. --><listitem><para>Its samples should cover as wide a range of problems as is feasible, in the
            interests of seeing whether different proposals for overlap work better on different
            kinds of problems.</para></listitem><listitem><para>The corpus may provide, or should at least support work toward, some kind of
            systematic categorization or typology of <quote>overlap problems</quote>.</para></listitem><listitem><para>The samples in the corpus should be able to serve as a kind of testbed for the
            development of tools, including editors, translators, query languages, and so on.</para></listitem><listitem><para>It should be able to serve as a testbed for head-to-head comparison of overlap
            solutions, by making it possible to build demonstration applications using the same
            documents in different encodings and compare the volume and complexity of the code
            needed to support the different encodings. </para></listitem></itemizedlist>
    </para><para>It is currently difficult to compare different techniques for dealing with overlap with
      each other and to apply concrete metrics to them. We believe that MOC may provide a testbed
      for application and tool development, and an empirical basis for answering questions such as: <itemizedlist><listitem><para>How successful is a given syntactic proposal in capturing relevant information about
            a given document with overlapping structures?</para></listitem><listitem><para>How verbose or succinct is the proposal's markup for the document?</para></listitem><listitem><para>How <emphasis>complex</emphasis> is each proposal's markup (assuming it is possible
            to specify some quantitative measure of markup complexity).</para></listitem><listitem><para>How complex is the task of parsing a given syntax and mapping it to a given data
            structure?</para></listitem><listitem><para>How successful is a given proposed data structure in capturing the relevant
            information about overlapping structures in a document?</para></listitem><listitem><para>Given a representation of a particular document in a given data structure, how
            complex is the task of operating on that data structure in support of a given
            application using the document? </para></listitem></itemizedlist>
    </para></section><section xml:id="content"><title>Content of the corpus</title><section xml:id="structure"><title>Structure</title><para>In its initial form, MOC will comprise three sets of samples: <itemizedlist><listitem><para><quote>toy</quote> samples, typically just a few lines in length.</para><para>Most toy samples are drawn from the literature on overlap. These samples usually
              reduce the problem of overlap to very minimal terms, which makes them helpful for
              highlighting the essential features of a particular overlap problem and the proposed
              solution. By the same token, they elide many of the details that must be handled in
              practical applications.</para></listitem><listitem><para><quote>short</quote> samples, each typically a few pages long.</para><para> These samples are designed to be large enough to illustrate the interaction of
              overlapping structures with other problems of text encoding, but short enough to make
              it feasible to encode them multiple times by hand.</para></listitem><listitem><para><quote>long</quote> samples, each typically a complete document (e.g. a play, long
              short story, or novel).</para><para> These samples are designed to be large enough to make it feasible to build simple
              text applications (e.g. interactive search and retrieval systems or text visualization
              systems) using the MOC samples as data, and to illuminate technical issues in the
              processing of overlapping structures. By current standards, however, none of the
              samples in this class are expected to be big in the sense of <quote>big
            data</quote>.</para></listitem></itemizedlist>
      </para></section><section xml:id="sample-metadata"><title>Information about the samples</title><para>Each sample is a concrete encoding of a particular text or text fragment, characterized
        along a number of axes: <itemizedlist><listitem><para><emphasis role="bold">sample group</emphasis>: the text or text fragment encoded,
              and the information to be captured.</para><para>For example, the sample group <emphasis>Peter, Paul, and the Hammer</emphasis>
                [<xref linkend="Hilbert_etal2005"/>] (whose instances are among the Toy samples of
              MOC) consists of the following text fragment, together with the constraint that the
              encoding should capture both the division into speeches or utterances by Peter and
              Paul and the division of the spoken text into sentences. <blockquote><para>
                  <emphasis role="bold">Peter</emphasis>
                </para><para>Hey, Paul! Would you pass me —</para><para>
                  <emphasis role="bold">Paul</emphasis>
                </para><para>
                  <emphasis role="ital">[Handing him the hammer]</emphasis>
                </para><para>— the hammer?</para></blockquote>
            </para></listitem><listitem><para><emphasis role="bold">notation</emphasis>: By <quote>notation</quote> we mean a
              particular markup syntax, such as SGML, XML, TexMecs, etc.</para></listitem><listitem><para><emphasis role="bold">vocabulary</emphasis>: the same textual material may be
              encoded in XML or another notation using different vocabularies, such as (for example)
              TEI, HTML, OSIS, or an ad hoc vocabulary invented for the example.</para><para>MOC is rather casual about the affiliation of vocabularies with notations. Most
              public vocabularies (TEI for instance) are defined using just one notation (typically
              XML), so it's stretching things a bit to say (as MOC does) that a vocabulary defined
              only for one notation can be used in samples encoded in another notation (say,
              TexMecs). For MOC purposes, that is, a vocabulary provides information about the
              meaning to be attached to particular identifiers used in an encoding, without being
              particular about the notation in which the identifiers occur. </para></listitem><listitem><para><emphasis role="bold">idiom</emphasis>: a given vocabulary may provide more than
              one way to encode overlapping structures; we refer to a particular way of using a
              vocabulary as an <emphasis>idiom</emphasis>. Some vocabularies are designed to reduce
              such variation as far as possible; others tolerate or even encourage it. In the TEI
              vocabulary, for example, overlapping elements can be encoded in several ways: <itemizedlist><listitem><para>using for-the-purpose milestone elements (such as <code>pb</code> and
                      <code>lb</code>),</para></listitem><listitem><para>using generic milestone elements (<code>milestone</code>), </para></listitem><listitem><para>using Trojan Horse markup [<xref linkend="DeRose2004"/>],</para></listitem><listitem><para>using virtual elements fragmented to fit into the imposed hierarchy and then
                    knit together in a variety of ways:<itemizedlist><listitem><para>using the <code>join</code> element,</para></listitem><listitem><para>using the attributes <code>next</code> and <code>prev</code>,</para></listitem><listitem><para>using the attribute <code>part</code> with the values <code>I</code>,
                            <code>M</code>, and <code>F</code>. </para></listitem></itemizedlist>
                  </para></listitem><listitem><para>using stand-off markup of various kinds</para></listitem></itemizedlist> In all of these cases, the encoder faces the choice of which logical
              elements of the document structure (if any) to encode in the conventional way (one
              logical element, one XML element) and which to encode in the alternative way using
              milestones, multiple XML elements, or elements in a stand-off annotation structure.
              (See further discussion of <quote>sacred</quote> and <quote>profane</quote> elements
              below.) The convenience of concrete operations on the document may vary widely
              depending on the choices made, so ideally MOC should provide a wide range of variation
              in choices here, to enable them to be compared empirically. </para><para>MOC reifies idioms by defining them and giving them names so they can be tracked
              and compared.</para><para>Each sample may instantiate any number of named idioms.</para></listitem><listitem><para><emphasis role="bold">source</emphasis>: a bibliographic reference to the source
              of the sample. Omitted for samples constructed by the MOC project. </para></listitem><listitem><para><emphasis role="bold">description</emphasis>: a prose description of the sample,
              commenting on any points of particular interest or importance. </para></listitem><listitem><para><emphasis role="bold">status, to-do list, and change history</emphasis>:
              provisions for work-flow management; see discussion below. </para></listitem></itemizedlist>
      </para><para>A formal model of (an early draft of) the MOC catalog has been created and is described
        in [<xref linkend="alloy_model_2010"/>].</para></section><section xml:id="ancillae"><title>Ancillary materials</title><para>Along with the samples, MOC records information about each sample group, notation,
        vocabulary, and idiom used in the corpus, together with bibliographic references. For
        notations like XML and vocabularies like TEI, documentation is readily available and MOC
        makes no attempt to compete with other sources as regards completeness of its lists of
        bibliographic references. But for less commonly known notations, it is hoped that MOC's
        collection of information may be helpful to those seeking to learn more. </para><para> Each notation, vocabulary, idiom, sample, and sample group in MOC has a distinct URI;
        users can dereference the URI to see the information MOC has about the item in question.
      </para></section><section xml:id="selectioncriteria"><title>Selection criteria</title><para>Since its purpose is to illuminate problems connected with overlap and with existing
        proposals for handling it, MOC does not attempt to make the selection of texts
        representative of any particular linguistic or textual population. (MOC is not a
          <emphasis>corpus</emphasis> in that sense.) For MOC, the relevant population is not a
        particular set of natural-language users, but the set of overlap-related problems
        encountered by people who work with natural-language texts for whatever purposes.</para><para>Accordingly, MOC takes a resolutely opportunistic approach to samples; we will take
        samples anywhere we can find them. This is particularly visible in the toy samples: the
        current version of MOC includes among the toy samples many short samples originally
        published in papers on overlap that have come to our attention. Opportunistic sampling is
        less fruitful when it comes to the short and long samples. </para><para>Since one of the purposes of MOC is to support investigations of different kinds of
        overlap as well as different ways of encoding overlap, the collections of short and long
        samples will, to the extent possible, reflect a variety of overlap phenomena and textual
        interests. In the absence of a well grounded categorization of different kinds of overlap,
        it's difficult to be certain how many really different kinds of overlap there are, and which
        kinds of overlap are structurally and conceptually isomorphic. In the absence of such a well
        grounded categorization, we hope to include examples at least of the following kinds of
        overlap: <itemizedlist><listitem><para>structural overlap and multiple hierarchies (as in verse drama, or physical and
              logical hierarchies [page vs paragraph], or in the analysis of the Peter / Paul
              example above into utterances and into syntactic units)</para></listitem><listitem><para>overlapping annotation targets (as in fine-grained commentary on specific
            texts)</para></listitem><listitem><para>change-history markup showing the revision of a text over time (of practical
              import for technical documentation, but also of interest for genetic editions) </para></listitem><listitem><para>overlapping sites of textual variation (as in text-critical editions) </para></listitem><listitem><para>discontinuous and disordered elements (as in cases where one text is quoted and
              commented on in another text, for which songs and plays-within-plays in drama provide
              examples; a well known example in the overlap literature is the attempt of Hughie,
              Louis, and Dewey to remember a haiku) </para></listitem></itemizedlist>
      </para><para>We also hope to provide examples that illustrate the occurrence of overlap in texts and
        applications of interest in different communities: <itemizedlist><listitem><para>literary study</para></listitem><listitem><para>lexicology</para></listitem><listitem><para>metrical study</para></listitem><listitem><para>language corpora (discourse analysis, syntax, prosody, ...)</para></listitem><listitem><para>textual criticism</para></listitem><listitem><para>document publishing</para></listitem><listitem><para>documentary, historical-critical, genetic, and other scholarly editions</para></listitem><listitem><para>analytical bibliography</para></listitem><listitem><para>historical annotation</para></listitem><listitem><para>legal documents</para></listitem></itemizedlist>
      </para></section><section xml:id="workflow"><title>Work flow</title><para>Each sample in the corpus goes through the following processes, leading to the
        corresponding status: <orderedlist><listitem><para><emphasis role="bold">candidate</emphasis>: The sample has been collected and may
              or may not be included in the corpus proper. (We expect this will apply just to toy
              samples, but it may also apply to others.) </para></listitem><listitem><para><emphasis role="bold">projected</emphasis>: We have agreed in principle and in
              theory that we want this sample.</para></listitem><listitem><para><emphasis role="bold">planned</emphasis>: We have agreed on the desired properties
              of the sample in sufficient detail to allow data capture to proceed: <itemizedlist><listitem><para>sample group (i.e., information about which sample group the sample belongs
                    to.)</para></listitem><listitem><para>source text <!--(which  sample group?)--></para></listitem><listitem><para>notation</para></listitem><listitem><para>vocabulary</para></listitem><listitem><para>idiom<!--(s)--></para><!-- Add a note concerning possible plural idioms in one sample. --></listitem></itemizedlist>
            </para></listitem><listitem><para><emphasis role="bold">incomplete</emphasis>: Data capture has begun but has not
              yet been completed. </para></listitem><listitem><para><emphasis role="bold">rough</emphasis>: Data capture has been completed, and the
              person who did the data capture has done an initial proofreading. </para></listitem><listitem><para><emphasis role="bold">validated</emphasis> (or <emphasis role="bold">wf-checked</emphasis>): The sample has been validated against all appropriate
              schemas, if there are any, or (if there is no schema) has been checked for
              well-formedness by some automatic tool. </para></listitem></orderedlist>
      </para><para>At this point the paths divide. Toy samples and small samples undergo repeated
        proofreadings (the initial plan is to do three proofreadings for each, but that plan has not
        yet been put to the test). Large samples are (we assume) too long for multiple proofreadings
        (or possibly even one). Instead, we perform a single proofreading and several spot checks.</para><para>Once it reaches the <code>validated</code> state, each large sample acquires a list of
        spot checks to be performed. One by one, not necessarily in any prescribed order, the
        prescribed checks are performed. Each check results, possibly, in corrections and
        re-validation, and possibly in the addition of new checks to the to-check list. Whenever we
        notice something odd or amiss in the document, especially if it could be a systematic
        problem, then a new task is added to the to-check list (assuming we can devise a way to
        check systematically for the error in question). </para><para>It is not yet clear exactly what spot-checks we need to do; we expect them to vary with
        the notation, the idioms, the sample, etc. But some examples may make the idea clearer: <itemizedlist><listitem><para>When feasible, a spell-checker is used to check the text for typographic
            errors.</para></listitem><listitem><para>A selected one-, ten-, or one-hundred-percent sample of markup constructs
              (typically occurrences of particular element types or attributes) is checked for
              semantic plausibility (their syntactic correctness having already been guaranteed by
              validation). For example, we might spot-check one percent, ten percent, or all of the
              markup used for page breaks, page numbers, the TEI <code>part</code> attribute, the
                <code>next</code> and <code>prev</code> attributes, the <code>join</code> element,
              instances of markup for discontinuous elements, instances of fragmented elements, or
              Trojan horses, to make sure they are semantically correct. The specific constructs
              that need checking will, of course, typically depend on the idiom used. </para></listitem></itemizedlist> Systematic errors found in spot checks are fixed in whatever way we can
        manage. </para></section></section><section xml:id="status"><title>Current status</title><para>The ultimate aim of MOC is to provide a fully populated matrix of materials: for each
      sample group, one sample in each relevant combination of notation, vocabulary, and idiom.</para><para>As a first step towards this larger goal we have built a prototype corpus of
      <quote>toy</quote> samples (MOC-POC), as a proof of concept. MOC-POC currently contains
      <!--comprises--> 52 samples distributed over 14 sample groups, 4 notations and 6 idioms.<footnote><para>Not all sample groups contain samples in all notations and idioms. When completed,
          this toy corpus of 14 sample groups will contain 126 samples.</para></footnote>
    </para><para>The text fragments comprising the samples of MOC-POC are taken from a selection of
      research publications on the overlap problem. This prototype does not claim any kind of
      completeness; it has, however, successfully identified a number of weak spots in our initial
      design. </para><para>Notations currently represented in MOC-POC are: <itemizedlist><listitem><para>XML</para></listitem><listitem><para>XConcur</para></listitem><listitem><para>LMNL <quote>saw-tooth</quote> notation</para></listitem><listitem><para>TexMecs</para></listitem></itemizedlist>
    </para><para>Most of the samples are encoded using a vocabulary taken from or based on some version of
      TEI, but ad hoc vocabularies are also represented. </para><para>Samples encoded in XML are encoded using six different TEI idioms<footnote><para>For other vocabularies, analogous attributes and elements are assumed or
        provided.</para></footnote> to resolve overlap problems: <itemizedlist><listitem><para>Fragmentation using the next and prev attributes defined as part of the TEI tags set
            for segmentation and alignment.</para></listitem><listitem><para>Fragmentation using the part attribute provided for certain elements in the TEI
            vocabulary. (If a TEI-encoded example requires fragmentation of an element for which TEI
            provides no part attribute, the attribute is added.)</para></listitem><listitem><para>Fragmentation using the part and id attributes and the join element defined as part
            of the TEI tags set for segmentation and alignment. </para></listitem><listitem><para>The "Trojan horse 1" idiom uses milestone tags to resolve overlap. Milestones are
            used only when necessary, normal XML elements are used in all other cases. It is left to
            the encoder's choice to decide which element to mark with milestones.</para></listitem><listitem><para>"Trojan horse 2", like "Trojan horse 1", uses milestone tags to resolve overlap.
            However, the Trojan horse 2 idiom represents every element in the overlap as a pair of
            milestones with intervening content.</para></listitem><listitem><para>The "XStandoff" idiom uses XML-conformant markup that points to the character data
            ("primary data"), which is kept in a separate location.<footnote><para>We express warm thanks to Maik Stührenberg (Bielefeld) for having
                prepared and allowed us to use XStandoff samples in all sample groups.</para></footnote></para></listitem></itemizedlist></para></section><section xml:id="results"><title>Preliminary results</title><para>A few preliminary results of our work on MOC can be mentioned.</para><para>Our attempts to explore the solution space of techniques like TEI-style fragmentation led
      very quickly to the realization that the TEI's techniques for handling overlapping structures
      (here we will use the <code>next</code> and <code>prev</code> attributes as an example, but
      the same observations apply to all the techniques described by the TEI) do not in themselves
      fully determine the encoding of a given sample, even when there is no uncertainty about which
      textual features are to be encoded. This is not surprising in itself; the TEI almost always
      leaves a great deal of leeway to the individual project and its encoding policies. But it does
      mean that a full description of how the TEI is used to encode a given sample must go beyond
      saying that the <code>next</code> and <code>prev</code> attributes are used. </para><para>When <code>next</code> and <code>prev</code> are used, an overlap of two logical elements
      is resolved by breaking one of the logical elements into smaller pieces
      (<quote>fragmentation</quote>) and using <code>next</code> and <code>prev</code> to signal
      that each XML element is just a fragment of the original logical element. For example, the
      Peter/Paul example given earlier might be encoded this way:
      <programlisting xml:space="preserve">
&lt;sp&gt;
  &lt;speaker&gt;Peter&lt;/speaker&gt;
  &lt;p&gt;
    &lt;s id="s1"&gt;Hey, Paul!&lt;/s&gt;
    &lt;s id="s2a" next="s2b"&gt;Would you pass me &lt;/s&gt;
    &amp;mdash;
  &lt;/p&gt;
&lt;/sp&gt;
&lt;sp&gt;
  &lt;speaker&gt;Paul&lt;/speaker&gt;
  &lt;stage&gt;Handing him the hammer&lt;/stage&gt;
  &lt;p&gt;&amp;mdash;
    &lt;s id="s2b" prev="s2a"&gt;the hammer?&lt;/s&gt;
  &lt;/p&gt;
&lt;/sp&gt;</programlisting>
    </para><para>Here sentences are tagged using the <code>s</code> (sentence-unit) element, and the second
      sentence is fragmented to fit within the hierarchy defined by the <code>speech</code>
      elements.</para><para>It would be logically possible, however, to break the <code>speech</code> elements as
      needed to fit within the <code>s</code>-unit hierarchy:
      <programlisting xml:space="preserve">&lt;p&gt;
  &lt;s id="s1"&gt;
    &lt;sp who="Peter" 
        id="sp1a" 
        next="sp1b"&gt;Hey, Paul!&lt;/sp&gt;
  &lt;/s&gt;
  &lt;s id="s2"&gt;
    &lt;sp id="sp1b" 
        pref="sp1a"&gt;Would you pass 
          me &amp;mdash;&lt;/sp&gt; 
    &lt;sp id="sp2" 
        who="Paul"&gt;&amp;mdash; 
          the hammer?&lt;/sp&gt;
  &lt;/s&gt;
  &lt;/p&gt;</programlisting>
    </para><para>In order to be usable, an encoding using <code>next</code> and <code>prev</code> to
      resolve overlap problems will need to be consistent in choosing which logical elements to
      fragment and which to leave intact. In some cases, it will suffice to say, for each element
      type in the vocabulary, whether or not it is to be fragmented in case of need. Those elements
      which are never to be fragmented or modified are referred to, jokingly, as
      <quote>sacred</quote>; the others in contrast as <quote>profane</quote>. But a binary
      classification of element types as either sacred or profane suffices only when every pair of
      overlapping elements has one sacred and one profane member: it does not provide adequate
      guidance when both elements in the pair are sacred, or both profane. In more complex cases,
      therefore, it <!--is necessary--> may be desirable to formulate a scale of values assigning
      each element type a degree of sacredness or profanity, and to ensure that no two element types
      which overlap each other have the same value. Then the rule can be formulated: for any pair of
      overlapping logical elements, represent the more sacred logical element as a single XML
      element, and fragment the less sacred element in order to make the XML elements nest. </para><para>The sacred / profane distinction has been picked up (and stretched into a slightly
      different shape) by [<xref linkend="Marinelli2008"/>].</para></section><section xml:id="future"><title>Conclusion and future work</title><para>The MOC project has been presented to markup-related communities on three occasions: a
      poster session at Digital Humanities 2010 in London, a nocturne at Balisage 2010, and a
      talk at the TEI 2010 Members Meeting in Zadar, Croatia. In all cases, the response of
      participants suggested that a corpus along the lines envisaged for MOC may meet a need of
      the community. The nocturne, in particular, led to the creation of <link xlink:href="http://listserv.brown.edu/archives/cgi-bin/wa?A0=MOC-L" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">a mailing list for
        project-related discussion</link> at Brown University (rather quiet so far, but still
      there). </para><para>As already mentioned, however, MOC is still work in progress. More lies ahead than behind. </para><para>Our first task is to make a first version of MOC which is reasonably complete and suitable
      for at least some of its intended uses. The steps we intend to take are:<itemizedlist><listitem><para>Concerning the technical infrastructure:<itemizedlist><listitem><para>Finalize and document decisions on the corpus repository structure and
            linking possibilities and mechanisms.</para></listitem><listitem><para>Adjust the structure of the current repository to conform to the above decisions.
          </para></listitem><listitem><para>Build, test, and deploy a multi-user and user-friendly interface to the
            repository.
	    <!--* <note><para>??? leave preceeding point there / modify ???</para></note> *-->
	  </para></listitem></itemizedlist>
        </para></listitem><listitem><para>
          Call for the contribution of any group or community interested in overlap to take part in
          the effort of populating the corpus.</para></listitem><listitem><para>
          Develop collaboration and work-organization strategies (including
          funding).</para></listitem><listitem><para>
          Populate the corpus up to a <quote>critical mass size</quote> (including full-size samples):
          <itemizedlist><listitem><para>systematic extension of the bibliography</para></listitem><listitem><para>selection of useful toy examples from the literature</para></listitem><listitem><para>identification of a small but illustrative set of idioms to be illustrated</para></listitem><listitem><para>selection and careful encoding of a small set of small examples</para></listitem><listitem><para>selection and careful encoding of a (very) small set of large examples</para></listitem><listitem><para>systematic encoding of all examples in all applicable notations, vocabularies, and
                idioms </para></listitem></itemizedlist>        
        </para></listitem></itemizedlist>
    </para><para>Once MOC has something like a critical mass of samples, it should be possible to use it to
      investigate and illustrate the relative merits of various encodings, building applications to
      operate on the data, for example by displaying it using visualizations like those developed by
      Wendell Piez for demonstrations of LMNL, or simple search and retrieval interfaces. </para><para>Such applications should make it possible to explore the suggestion by Fabio Vitali and
      his research team [<xref linkend="EARMARK_2009"/>] that SPARQL might be a more useful query
      language for overlapping structures than the various extensions to XPath described in the
      literature. </para><!--<note>
      <para><emphasis role="bold">Note to reviewers:</emphasis> Work on MOC continues, and some of
        what is described here may be completed before August. But we make no promises; MOC has been
        a very slow project thus far, and that is not likely to change soon. </para>
    </note>--></section><bibliography><title>References</title><bibliomixed xml:id="p3" xreflabel="ACH/ACL/ALLC 1994"> Association for Computers and the
      Humanities, Association for Computational Linguistics, and Association for Literary and
      Linguistic Computing. 1994. <emphasis>Guidelines for Electronic Text Encoding and Interchange
        (TEI P3)</emphasis>. Ed. C. M. Sperberg-McQueen and Lou Burnard. Chicago, Oxford: Text
      Encoding Initiative, 1994. </bibliomixed><bibliomixed xml:id="Barnard1988" xreflabel="Barnard et al. 1988"> Barnard, D., Hayter, R.,
      Karababa, M., Logan, G. and McFadden, J. 1988 <quote>SGML Markup for Literary Texts</quote>
      <emphasis>Computers and the Humanities</emphasis> 22 265-276 </bibliomixed><bibliomixed xml:id="Barnard1995" xreflabel="Barnard et al. 1995"> Barnard, D., Burnard, L.,
      Gaspart, J. P., Price, L. A., Sperberg-McQueen, C. M. and Varile, G. B. 1995
        <quote>Hierarchical encoding of text: Technical problems and SGML solutions</quote>
      <emphasis>Computers and the Humanities</emphasis> 29 211-231. doi:<biblioid class="doi">10.1007/BF01830617</biblioid> </bibliomixed><bibliomixed xml:id="Carletta2005" xreflabel="Carletta et al. 2005"> Carletta, J., Evert, S.,
      Heid, U. and Kilgour, J. 2005 <quote>The NITE XML Toolkit: data model and query</quote>
      <emphasis>Language Resources and Evaluation</emphasis> 39(4) 313-334. doi:<biblioid class="doi">10.1007/s10579-006-9001-9</biblioid>
        </bibliomixed><bibliomixed xml:id="Chatti2007" xreflabel="Chatti et al. 2007"> Chatti, N., Kaouk, S.,
      Calabretto, S. and Pinon, J. M. 2007 <quote>MultiX: an XML-based formalism to encode
        multi-structured documents</quote>
      <emphasis>Proceedings of Extreme Markup Languages 2007</emphasis> Montréal (Canada)
      Aug. 2007 <link xlink:href="http://conferences.idealliance.org/extreme/html/2007/Chatti01/EML2007Chatti01.html" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://conferences.idealliance.org/extreme/html/2007/Chatti01/EML2007Chatti01.html</link>
    </bibliomixed><bibliomixed xml:id="DeRose2004" xreflabel="DeRose 2004"> DeRose, Steven 2004 <quote>Markup
        overlap: A review and a horse</quote>
      <emphasis>Proceedings of Extreme Markup Languages 2004</emphasis> Montréal (Canada)
      Aug. 2004 <link xlink:href="http://conferences.idealliance.org/extreme/html/2004/DeRose01/EML2004DeRose01.html" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://conferences.idealliance.org/extreme/html/2004/DeRose01/EML2004DeRose01.html</link>
    </bibliomixed><bibliomixed xml:id="EARMARK_2009" xreflabel="Di Iorio et al. 2009"> Di Iorio, A.; Peroni, S.;
      and Vitali, F. <quote>Towards markup support for full GODDAGs and beyond: the EARMARK approach</quote>
      <emphasis>Proceedings of Balisage: The Markup Conference 2009</emphasis> Montréal
      (Canada), August 11-14, 2009. doi:<biblioid class="doi">10.4242/BalisageVol3.Peroni01</biblioid>.
    </bibliomixed><bibliomixed xml:id="Durusau_and_ODonnell_2002b" xreflabel="Durusau and O’Donnell       2002"> Durusau, Patrick and O’Donnell, Matthew Brook <quote>Coming down from the
        trees: Next step in the evolution of markup?</quote>
      <emphasis>Proceedings of Extreme Markup Languages®</emphasis> 2002 <link xlink:href="http://www.durusau.net/publications/Down_from_the_trees.pdf" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.durusau.net/publications/Down_from_the_trees.pdf</link>
    </bibliomixed><bibliomixed xml:id="Hilbert_etal2005" xreflabel="Hilbert et al. 2005"> Hilbert, Mirco;
      Schonefeld, Oliver; and Witt, Andreas <quote>Making CONCUR work</quote>
      <emphasis>Proceedings of Extreme Markup Languages®</emphasis> 2005 <link xlink:href="http://conferences.idealliance.org/extreme/html/2005/Witt01/EML2005Witt01.xml" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://conferences.idealliance.org/extreme/html/2005/Witt01/EML2005Witt01.xml</link>
    </bibliomixed><bibliomixed xml:id="zadar_2010" xreflabel="Huitfeldt and Marcoux 2010"> Huitfeldt, Claus and
      Marcoux, Yves <quote>The MLCD overlap corpus: A markup research infrastructure</quote>
      Presented at the <emphasis>TEI Members Meeting 2010</emphasis> Zadar (Croatia). </bibliomixed><bibliomixed xml:id="Huitfeldt_and_Sperberg-McQueen_2003" xreflabel="Huitfeldt and       Sperberg-McQueen 2003"> Huitfeldt, Claus and Sperberg-McQueen, C. M. <quote>TexMECS: An
        experimental markup meta-language for complex documents</quote> Working paper of the project
        <emphasis>Markup Languages for Complex Documents (MLCD)</emphasis> University of Bergen
      January 2001, rev. October 2003 <link xlink:href="http://mlcd.blackmesatech.com/mlcd/2003/Papers/texmecs.html" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://mlcd.blackmesatech.com/mlcd/2003/Papers/texmecs.html</link>
    </bibliomixed><bibliomixed xml:id="london_2010" xreflabel="Huitfeldt et al. 2010"> Huitfeldt, Claus;
      Sperberg-McQueen, C. M.; and Marcoux, Yves <quote>The MLCD Overlap Corpus (MOC)</quote> Poster
      presented at the <emphasis>Digital Humanities 2010 Conference</emphasis> King's College,
      London, 7-10 July 2010 <link xlink:href="http://dh2010.cch.kcl.ac.uk/academic-programme/abstracts/papers/html/ab-633.html" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://dh2010.cch.kcl.ac.uk/academic-programme/abstracts/papers/html/ab-633.html</link></bibliomixed><bibliomixed xml:id="Jagadish_et_al._2004" xreflabel="Jagadish et al. 2004"> Jagadish, H. V.;
      Lakshmanan, L. V. S.; Scannapieco, M.; Srivastava, D.; and Wiwatwattana, N. <quote>Colorful
        XML: one hierarchy isn't enough</quote>
      <emphasis>Proceedings of the 2004 ACM SIGMOD international conference on Management of
      data</emphasis> Paris, France: pp. 251-262, 2004 doi:<biblioid class="doi">10.1145/1007568.1007598</biblioid>
    </bibliomixed><bibliomixed xml:id="Marinelli2008" xreflabel="Marinelli / Vitali / Zacchiroli 2008"> Marinelli,
      Paolo; Vitali, Fabio; Zacchiroli, Stefano <quote>Towards the unification of formats for
        overlapping markup</quote>
      <emphasis>The New Review of Hypermedia and Multimedia</emphasis> 14 57-94. doi:<biblioid class="doi">10.1080/13614560802316145</biblioid>; see <link xlink:href="http://en.scientificcommons.org/38517317" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://en.scientificcommons.org/38517317</link>, <link xlink:href="http://www.tandfonline.com/doi/full/10.1080/13614560802316145" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.tandfonline.com/doi/full/10.1080/13614560802316145</link>, and <link xlink:href="http://hal.archives-ouvertes.fr/docs/00/34/05/78/PDF/nrhm-overlapping-conversions.pdf" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://hal.archives-ouvertes.fr/docs/00/34/05/78/PDF/nrhm-overlapping-conversions.pdf</link>
    </bibliomixed><bibliomixed xml:id="Schonefeld_2007" xreflabel="Schonefeld 2007"> Schonefeld, Oliver
        <quote>XCONCUR and XCONCUR-CL: A constraint-based approach for the validation of concurrent
        markup</quote> Georg Rehm, Andreas Witt, Lothar Lemnitzer <emphasis>Datenstrukturen
        für linguistische Ressourcen und ihre Anwendungen / Data structures for linguistic
        resources and applications: Proceedings of the Biennial GLDV Conference 2007</emphasis>
      Tübingen: Gunter Narr Verlag, pp. 347-356, 2007. See also <link xlink:href="http://www.xconcur.org/" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.xconcur.org/</link>. </bibliomixed><bibliomixed xml:id="alloy_model_2010" xreflabel="Sperberg-McQueen 2010"> Sperberg-McQueen, C.
      M. <quote>MOC catalog and maintenance plan</quote>
      <link xlink:href="http://mlcd.blackmesatech.com/mlcd/2010/A/moc-catalog-sketch.xml" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://mlcd.blackmesatech.com/mlcd/2010/A/moc-catalog-sketch.xml</link> (the
      formal model itself, in Alloy, is available at <link xlink:href="http://mlcd.blackmesatech.com/mlcd/2010/A/moc-catalog.als" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://mlcd.blackmesatech.com/mlcd/2010/A/moc-catalog.als</link>). </bibliomixed><bibliomixed xml:id="cdhms" xreflabel="Sperberg-McQueen / Huitfeldt 1998"> Sperberg-McQueen,
      C.M. and Huitfeldt, Claus 1998 <quote>Concurrent Document Hierarchies in MECS and SGML</quote>
      <emphasis>Literary and Linguistic Computing</emphasis> 14 29-42 </bibliomixed><bibliomixed xml:id="Sperberg-McQueen_and_Huitfeldt_2000" xreflabel="Sperberg-McQueen and       Huitfeldt 2000"> Sperberg-McQueen, C. M. and Huitfeldt, Claus <quote>GODDAG: A Data Structure
        for Overlapping Hierarchies</quote> Peter R. King and Ethan V. Munson <emphasis>Digital
        documents: systems and principles. Lecture Notes in Computer Science 2023</emphasis> Berlin:
      Springer, 2004, pp. 139-160. Paper given at Digital Documents: Systems and Principles. 8th
      International Conference on Digital Documents and Electronic Publishing, DDEP 2000, 5th
      International Workshop on the Principles of Digital Document Processing, PODDP 2000, Munich,
      Germany, September 13-15, 2000. 2004 <link xlink:href="http://www.springerlink.com/content/98j1vbu5nby73ul3/?p=4eefed0ac09e4ee381d09d3ac2afcb46&amp;pi=8" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.springerlink.com/content/98j1vbu5nby73ul3/?p=4eefed0ac09e4ee381d09d3ac2afcb46&amp;pi=8</link>
      <link xlink:href="http://cmsmcq.com/2000/poddp2000.html" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://cmsmcq.com/2000/poddp2000.html</link>
      <link xlink:href="http://www.w3.org/People/cmsmcq/2000/poddp2000.html" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.w3.org/People/cmsmcq/2000/poddp2000.html</link>
    </bibliomixed><bibliomixed xml:id="SDF" xreflabel="Stührenberg / Goecke 2008"> Stührenberg,
      M. and Goecke, D. 2008 <quote>SGF — An integrated model for multiple annotations and
        its application in a linguistic domain</quote>
      <emphasis>Proceedings of Balisage: The Markup Conference 2008</emphasis> Montréal
      (Canada) August 12-15, 2008 <link xlink:href="http://www.balisage.net/Proceedings/vol1/html/Stuehrenberg01/BalisageVol1-Stuehrenberg01.html" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.balisage.net/Proceedings/vol1/html/Stuehrenberg01/BalisageVol1-Stuehrenberg01.html</link>
      doi:<biblioid class="doi">10.4242/BalisageVol1.Stuehrenberg01</biblioid>.
    </bibliomixed><bibliomixed xml:id="Stuhrenberg_and_Jettka_2009" xreflabel="Stührenberg and Jettka       2009"> Stührenberg, M. and Jettka, D. <quote>A toolkit for multi-dimensional markup:
        The development of SGF to XStandoff</quote>
      <emphasis>Proceedings of Balisage: The Markup Conference 2009</emphasis> Montréal
      (Canada), August 11-14, 2009 doi:<biblioid class="doi">10.4242/BalisageVol3.Stuhrenberg01</biblioid>.
    </bibliomixed><bibliomixed xml:id="p5" xreflabel="TEI 2007"> TEI Consortium. 2007. <emphasis>TEI P5:
        Guidelines for Electronic Text Encoding and Interchange</emphasis>. Ed. Lou Burnard and Syd
      Bauman. Oxford, Providence, Charlottesville, Nancy: The TEI Consortium, 2007, rev. 2010. </bibliomixed><bibliomixed xml:id="LMNL2002" xreflabel="Tennison and Piez 2002"> Tennison, Jeni and Piez,
      Wendell <quote>The Layered Markup and Annotation Language (LMNL)</quote>
      <emphasis>Proceedings of Extreme Markup Languages®</emphasis> 2002 <link xlink:href="http://conferences.idealliance.org/extreme/html/2002/Tennison02/EML2002Tennison02.html" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://conferences.idealliance.org/extreme/html/2002/Tennison02/EML2002Tennison02.html</link> (abstract only). Some information on LMNL can be found at <link xlink:href="http://www.piez.org/wendell/LMNL/lmnl-page.html" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.piez.org/wendell/LMNL/lmnl-page.html</link>. </bibliomixed><bibliomixed xml:id="witt2004" xreflabel="Witt 2004"> Witt, Andreas. 2004. <quote>Multiple
        hierarchies: new aspects of an old solution</quote>. Paper given at Extreme Markup Languages
      2004, Montréal, sponsored by IDEAlliance. Available on the Web at <link xlink:href="http://www.mulberrytech.com/Extreme/Proceedings/html/2004/Witt01/EML2004Witt01.html" xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.mulberrytech.com/Extreme/Proceedings/html/2004/Witt01/EML2004Witt01.html</link>
    </bibliomixed><bibliomixed xml:id="WLSG-2005" xreflabel="Witt / Lüngen / Goecke 2005"> Witt, A.,
      Lüngen, H., Sasaki, F. and Goecke, D. 2005 <quote>Unification of XML Documents with
        Concurrent Markup</quote>
      <emphasis>Literary and Linguistic Computing</emphasis> 20(1) 103-116 </bibliomixed></bibliography></article>