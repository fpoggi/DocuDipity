<?xml version="1.0" encoding="UTF-8"?><article xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0-subset Balisage-1.3" xml:id="HR-23632987-8973"><title>An XML engine to model  and query multimodal concurrent linguistic annotations
  </title><subtitle>Application to the OTIM Project</subtitle><info><confgroup><conftitle>Balisage: The Markup Conference 2011</conftitle><confdates>August 2 - 5, 2011</confdates></confgroup><abstract><para>
	    This paper presents an XML engine defined to model and query multimodal concurrent annotated data. 
	    This work stands in the context of the OTIM (Tools for Multimodal Annotation) project which aims at developing conventions and tools 
	    for multimodal annotation of a large conversational French speech corpus; it groups together Social Science and Computer Science researchers. 
	    Within OTIM, our objective is to provide linguists with a unique framework 
	    to encode and manipulate numerous linguistic domains: morpho-syntax, prosody, phonetics, disfluencies, discourse,  gesture and posture. 
	    For that, it has to be possible to bring together and align all the different pieces of information (called annotations) associated to a corpus.
	  </para><para>
	    We propose a complete pipeline from the annotation step to the management of the data within an XML Information System. This pipeline first relies on 
		the formalisation of the linguistic knowledge and data within a OTIM specific XML format. A Java framework is proposed for interfacing with both linguists specific 
		annotation tools and XML Information System. Finally, the querying of multimodal annotations within the XML information system using XQuery is presented. 
		As annotations are time aligned, an extension of XQuery to Allen temporal relations is proposed.
	  </para><para>
	    The paper conclude on a discussion about the interest of a pure XML approach for linguistic annotations information system and the question of the 
		integration of the semantic within the pipeline. 
	  </para></abstract><author><personname><firstname>Julien</firstname><surname>Seinturier</surname></personname><personblurb><para>Julien Seinturier is a PhD in Computer Sciences at the 
		      University of Sud Toulon-Var (South of France) since 2007. He is 
			  post doctorate at the CNRS Laboratory of Information Science and systems(LSIS) 
			  within the computer science teaching department. 
			  His fields of research covers Knowledge Representation, Semantic Web, XML data management. 
			  His research activities have been supported 
			  by French National and European pluridisciplinary research projects. </para></personblurb><affiliation><jobtitle>Post-Doctorate</jobtitle><orgname>Laboratoire LSIS UMR CNRS 6168, Université du Sud Toulon et Var</orgname></affiliation><email>seinturier@univ-tln.fr</email></author><author><personname><firstname>Elisabeth</firstname><surname>Murisasco</surname></personname><personblurb><para>Elisabeth Murisasco is Professor in Computer Sciences at 
		      the University of Sud Toulon-Var (South of France) since 2007. 
			  She is researcher at the CNRS Laboratory of Information Science 
			  and systems  (LSIS) and she is member of the computer science 
			  teaching department .
              Her main research experience and scientific expertise covers databases, 
			  XML-based data, semantic web technologies. Her research activities 
			  have been supported by French National research projects. 
	    </para></personblurb><affiliation><jobtitle>Professor</jobtitle><orgname>Laboratoire LSIS UMR CNRS 6168, Université du Sud Toulon et Var</orgname></affiliation><email>murisasco@univ-tln.fr</email></author><author><personname><firstname>Emmanuel</firstname><surname>Bruno</surname></personname><personblurb><para>Emmanuel Bruno is Assistant Professor in Computer Sciences at the 
		      University of Sud Toulon-Var (South of France) since 2001. He is 
			  researcher at the CNRS Laboratory of Information Science and systems(LSIS) 
			  and he is member of the computer science teaching department. 
			  His main fields of research covers databases, XML data management, 
			  semantic web technologies. His research activities have been supported 
			  by French National research projects. 
	    </para></personblurb><affiliation><jobtitle>Lecturer</jobtitle><orgname>Laboratoire LSIS UMR CNRS 6168, Université du Sud Toulon et Var</orgname></affiliation><email>bruno@univ-tln.fr</email></author><legalnotice><para>Copyright © 2011 by the authors. Used with permission.</para></legalnotice><keywordset role="author"><keyword>Knowledge Engineering</keyword><keyword>XML Information System</keyword><keyword>Application</keyword></keywordset></info><!-- Introduction --><section><title>Introduction</title><para>
	  In this paper, our intention is to present an XML engine defined to model and query multimodal concurrent annotated data. 
	  This work stands in the context of the OTIM (Tools for Multimodal Annotation) project which aims at developing conventions and tools 
	  for multimodal annotation of a large conversational French speech corpus (<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://aune.lpl.univ-aix.fr/~otim/</link>) [<xref linkend="LAW2010"/>]. This interdisciplinary project 
	  is funded by the French ANR agency; it groups together Social Science and Computer Science researchers. Within OTIM, our objective is to provide linguists with a unique framework 
	  to encode and manipulate numerous linguistic domains: morpho-syntax, prosody, phonetics, disfluencies, discourse,  gesture and posture [<xref linkend="ICGL2010"/>]. For that, it has 
	  to be possible to bring together and align all the different pieces of information 
	  (called annotations) associated to a corpus. 
	</para><para>
	  Since some years, several works have studied concurrent markups/annotations associated to the same data, in particular in the context of XML documents. These 
	  documents are usually called multistructured. Indeed, XML documents are mainly hierarchical. The hierarchy, captured in a tree-like structure corresponds to 
	  one level of analysis of the data contained in the document. Concurrent markup opens a way for dynamically linking and aggregating documents with different 
	  structures associated to the same data. The CONCUR feature of SGML [<xref linkend="SGML"/>] first pointed out this need in the nineties in context of 
	  document-centric encoding where some applications needed to consider more than one hierarchy over the same text. 
	</para><para>
	  The main problem with concurrent structures is that merging every hierarchy in an unique XML document implies overlapping: structures 
	  cannot be merged in order to get a well-formed XML document without using a flat representation or hyperlinks that make the structure difficult to query with 
	  standards XML languages like XPath (<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.w3.org/TR/xpath/</link>), XQuery (<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.w3.org/TR/xquery/</link>) or XSLT (<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.w3.org/TR/xslt/</link>). 
	  See [<xref linkend="WITT2004"/>][<xref linkend="DEROSE2004"/>] for a review about the problem of overlapping and about multiple hierarchies. Another approach 
	  is to keep one document by hierarchy and to solve the problem of the concurrent querying. We stand our work in this last approach: we want to keep each structure 
	  safe to use available XML tools and languages for its manipulation.
	</para><para>
	  Main proposals are usually classified in three categories [<xref linkend="BRUNO2006"/>][<xref linkend="PORTIER2010"/>]. 
	</para><para>
	  Historical solutions which propose syntactic solutions for the representation of multiple hierarchies in the same text, like the CONCUR feature [<xref linkend="HILBERT2005"/>] 
	  of SGML or TEI specifications [<xref linkend="TEIP4"/>] (e.g. a flat representation  or a main (hierarchical) structure and the use references (ID/IDREF) for 
	  the description of the other structures).  These solutions make impossible querying by means of standards XML languages.
	</para><para>
	Proprietary graph based-model (and possible alternative syntax to XML) like LNML [<xref linkend="TENNINSON2002"/>], TexMecs[<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://decentius.aksis.uib.no/mlcd/2003/Papers/texmecs.html</link>], 
	XCONCUR [<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.xconcur.org/</link>], Annotation graphs [<xref linkend="BIRD2001"/>] (coming from the linguistic domain coupled to specific extension of XPath) or 
	MVDM [<xref linkend="DJEMAL2008"/>]. They allow the concurrent markup relying on a granule of data common to all the structures. Nevertheless, hierarchical structures 
	are easier to exploit compared to the graph structure which remain complex when a large number of structures exist. XML syntax for serialization or import/export XML syntax do 
	not make easy their querying by XML standard languages.   
	</para><para>
	Finally, the third category is XML compatible contributions; they generally propose extensions of XML data model (XDM) (<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.w3.org/XML/Datamodel.html</link>) to consider a set of XML trees 
	[<xref linkend="JLM2006"/>][<xref linkend="JAGADISH2004"/>] or several trees sharing their leaves [<xref linkend="DEKHTYAR2005"/>][<xref linkend="BRUNO2007"/>][<xref linkend="BRUNO2007B"/>]
	[<xref linkend="CHATTI2007"/>]. For querying, these proposals define extensions of XPath or XQuery in order to navigate between different structures either by extending the notion 
	of step in XPath [<xref linkend="JAGADISH2004"/>] or by adding new axis [<xref linkend="DEKHTYAR2005"/>]. Another solution is to extend the semantics of the XQuery filter [<xref linkend="BRUNO2006"/>] 
	to use as much as possible an unchanged  XQuery structure. Adding Allen’s relations [<xref linkend="ALLEN1991"/>] by means of function definitions enable to deal with overlapping [<xref linkend="BRUNO2006"/>][<xref linkend="CHATTI2007"/>].  
	</para><para>
	  Besides, some linguistic projects have a similar objective than OTIM, for instance NITE (<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://groups.inf.ed.ac.uk/nxt/</link>), 
	  AGTK (<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://weblex.ens-lsh.fr/projects/xitools/logiciels/AGTK/agtk.htm</link>), ATLAS [<xref linkend="BIRD2000"/>], 
	  PAULA (<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.sfb632.uni-potsdam.de/~d1/paula/doc/</link>), XStandoff [<xref linkend="SPERBERG2000"/>]. 
	  These projects rely on graph-based model. They generally propose toolkits for multi-level annotation by means of libraries of data and annotation management. The 
	  multiplication of annotation schemes and coding formats is a severe limitation for interoperability. One solution consists in developing higher level approaches (e.g. GrAF [<xref linkend="IDE2007"/>]) 
	  or annotation graphs based formats on top of which conversion routines between tools can be developed (see the Atlas Interchange Format [<xref linkend="STHRENBERG2009"/>]). 
	  However, these experiments still remain very programmatic. 
	</para><para>
	  Interoperability of linguistic annotated resources requires over all to be independent from the coding format. This means to specify and organize the information to be encoded 
	  independently from the constraints or restriction of the format (or the annotation tool), then to encode the information into an standard XML format, readable whatever the edition or 
	  annotation system. Moreover we have made the choice not to provide new anootation tools for linguists as they have a long experience and they are efficient with their own tools.
	</para><para>
	This paper is organised as follows: the context and motivations are presented, then we describe the project objectives and its functional architecture. A visual UML representation of 
	the linguistic knowledge is proposed before the OTIM XML representation and Java framework are explicited. The end of the work shows the methods for querying and managing linguistic annotations 
	within the XML engine and the implementation of the whole corpus construction and management before a conclusion.
	</para></section><!-- Contexte --><section><title>Context and motivations</title><para>The OTIM project can be summarized in two main steps.</para><para>The first step concerns the multimodal annotation of a conversational speech between two persons. It is under the responsibility of linguists; 
	      annotation is done according to different levels of linguistic analysis. Each expert has to annotate the same data flow according to its knowledge 
		  domain and the nature of the signal on which he annotates (signal transcription or signal). Experts generally use dedicated tools like PRAAT 
		  <link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.fon.hum.uva.nl/praat/</link>, ANVIL <link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.anvil-software.de/</link> or ELAN <link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.lat-mpi.eu/tools/elan/</link>. 
		  The qualifier multimodal is due to the nature of the studied corpus which is composed of text, sound, video.
	</para><para>
	 Within the project OTIM, linguists propose an encoding for annotating spoken language data, with the acoustic signal as well as its orthographic 
	 transcription. They have chosen to use Typed Feature Structures [<xref linkend="CARPENTER1992"/>][<xref linkend="COPESTAKE2003"/>] (TFS) to represent in an unified view the knowledge and the information 
	 they need for annotation. TFS representation is usual for linguists: it aims at normalizing, sharing and exchanging annotation schemas between experts. 
	 Linguistic annotation tools rely on native and not often open formats which are not directly interoperable. TFS provides an abstract description using a 
	 high level formalism independent from coding languages and tools.  
	</para><para>
	  The second step concerns the representation and manipulation of multimodal annotation. To analyze and find correlations between annotated linguistic 
	  domains, it is necessary to consider them grouped together: it implies the definition of a formal model for describing and manipulating them in a concurrent 
	  way.  The main difficulty in defining a data model comes from the heterogeneity and the distribution of the resources. Concurrent manipulation consists in 
	  querying annotations belonging to two or more modalities or in querying the relationships between modalities. For instance, we need to be able to express queries 
	  over gestures and intonation contours (what kind of intonation contour does the speaker use when he looks at the listener?) and to query temporal relationships 
	  (in terms of anticipation, synchronization or delay) between both gesture strokes and lexical affiliates. The results of queries could be useful to help in constructing 
	  new annotations or to extend existing ones.
	</para><para>
	  The paper focuses on the second step. It describes an XML engine based on an architecture dedicated to the construction and the exploitation of multimodal annotated 
	  linguistic corpus. Our theoretical standpoint being to share data and resources, we will use open standards from the XML universe (see <link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.w3.org</link>). 
	</para><para>
	  Linguistic knowledge is captured by means of three types of information:
      <itemizedlist><listitem><para>Properties: the set of characteristics of an object. An object is a type of information to be annotated in the corpus ,</para></listitem><listitem><para>Relations: the set of relations that an object has with other objects,</para></listitem><listitem><para>Constituents: complex objects are composed of other objects called constituents.</para></listitem></itemizedlist>
      Typed Feature Structures proposes a formal presentation of each object in terms of feature structures and type hierarchies: properties are encoded by features, 
	  constituency is implemented with complex features, and relations make use feature structure indexing; each linguistic domain is represented as a hierarchical model. 
	</para><para>
	  <figure xml:id="TFS-prosody"><title>TFS of the prosodic domain</title><mediaobject><imageobject><imagedata format="png" fileref="../../../vol7/graphics/Seinturier01/Seinturier01-001.png" width="40%"/><!--<imagedata format="png" fileref="Bal2011SMB102201.png" width="25%"/>--></imageobject></mediaobject><caption><para>TFS description of the prosodic domain within the OTIM project.</para></caption></figure>
      For example, <xref linkend="TFS-prosody"/> graphically describes TFS representation of the prosodic domain. Notice that every feature of the domain related to 
	  signal is a sub-feature of the <emphasis role="ital">OtimObject</emphasis> that is constituted of an <emphasis role="ital">INDEX</emphasis> feature in order to be referred 
	  and a <emphasis role="ital">LOCALISATION</emphasis> feature that represents an interval, 
	  which boundaries are defined by the features <emphasis role="ital">START</emphasis> and <emphasis role="ital">END</emphasis>, with temporal value (usually milliseconds). 
	  Prosodic phrases are of two different types: <emphasis role="ital">ap</emphasis> (accentual phrases) 
	  and <emphasis role="ital">ip</emphasis> (intonation phrases). Accentual phrases are constituted of two appropriate features: the <emphasis role="ital">LABEL</emphasis>, 
	  which value is simply the name of the corresponding type, and the list of <emphasis role="ital">CONSTITUENTS</emphasis>, in this case a list of syllables. The features of 
	  type <emphasis role="ital">ip</emphasis> contain the list of its <emphasis role="ital">CONSTITUENTS</emphasis> (a set of <emphasis role="ital">ap</emphasis>) as well as the 
	  description of its <emphasis role="ital">CONTOUR</emphasis> which is a prosodic event, situated at the end of the <emphasis role="ital">ip</emphasis> and is usually associated to 
	  an <emphasis role="ital">ap</emphasis>. The prosodic phrases are formally defined as set of syllables. A syllable (<emphasis role="ital">syl</emphasis>) is constituted of features: 
	  <emphasis role="ital">STRUCT</emphasis> that describes the syllable structure (for example <emphasis role="ital">CVC</emphasis>, <emphasis role="ital">CCVC</emphasis>, etc.), the 
	  position of the syllable in the word (<emphasis role="ital">POSITION</emphasis>), its possibility to be accented or prominent (resp. <emphasis role="ital">ACCENTUABLE</emphasis>, 
	  <emphasis role="ital">PROMINENCE</emphasis>). Features of type <emphasis role="ital">const_syl</emphasis>, contains two different features: a set of phonemes, denoted 
	  <emphasis role="ital">PHON</emphasis>, and the type of the constituent (<emphasis role="ital">onset</emphasis>, <emphasis role="ital">nucleus</emphasis> and 
	  <emphasis role="ital">coda</emphasis>), denoted <emphasis role="ital">CONST_TYPE</emphasis>. Note that each syllable constituent can contain a set of phonemes.
	</para></section><section><title>Objectives and functional architecture</title><para>
	TFS is well suited to take into account the heterogeneous characteristics of annotated data. TFS provides an abstract 
	description using a high level formalism independent from coding languages and tools. Nevertheless, due to its theoretical 
	nature, such a representation cannot be used within an applicative framework and has to be implemented into other formalisms.
	</para><para>
	In this context, our contributions are the following:
	<itemizedlist><listitem><para>The representation of the knowledge expressed by means of TFS in an XML formalism. We base our proposal on XDM (XML data model, <link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.w3.org/XML/Datamodel.html</link>),</para></listitem><listitem><para>
			    The automatic construction of XML annotated multimodal linguistic corpus. We define an operational multimodal data processing 
			    from TFS and (semi) automatic procedures to convert legacy data and annotations to the XML formalism,
              </para></listitem><listitem><para>
			    The concurrent querying of multilevel annotated linguistic data represented in the XML formalism. We use the XML 
			    Query Language XQuery that we have extended to multistructured XML documents [<xref linkend="BRUNO2006"/>], in particular in order to take 
				into account Allen’s temporal relations. 
			  </para></listitem></itemizedlist>
	</para><para>
	  In summary, from the organization of annotations in terms of TFS, we automatically generate a XML schema [<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.w3.org/XML/Schema</link>] for each linguistic domain. 
	  All the annotations are then encoded following this schema and data are represented in standard XML document. This representation provides a 
	  high level of modularity for applicative requirements and enables to modify only the structure / schema needed and it can be queried by our XQuery 
	  extension which supports Allen’s relations. Notice that the TEI consortium has proposed guidelines for implementing feature structures in XML  (<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.tei-c.org/Guidelines/P5/</link>) 
	  however, we have decided not to encode TFS this way because type hierarchies and inheritance are not easily and directly represented and no querying support 
	  has be defined. This engine, from TFS to XML data, based on formalisms independent from linguistic coding languages and tools is an element of answer to 
	  the question of interoperability.  
	</para><para>
	<figure xml:id="otim-framework"><title>The OTIM Framework</title><mediaobject><imageobject><imagedata format="png" fileref="../../../vol7/graphics/Seinturier01/Seinturier01-002.png" width="60%"/><!--<imagedata format="png" fileref="Bal2011SMB102202.png" width="50%"/>--></imageobject></mediaobject><caption><para>The OTIM project applicative framework.</para></caption></figure>
	  <xref linkend="otim-framework"/> shows the functional architecture of our XML engine. It is composed of three parts:
	  <itemizedlist><listitem><para>Linguistics tools and formalisms chosen by linguists in the OTIM project, </para></listitem><listitem><para>An XML information system dedicated to the representation and querying of XML annotated multimodal corpus, </para></listitem><listitem><para>
		    A Java API that interfaces with both XML information system and linguistic specific annotation tools.
          </para></listitem></itemizedlist>
	</para><para>
	  Our approach guarantees that no information is lost when translating one format into the target formalism. However, the Java / XML framework does not provide 
	  linguists with a visual representation equivalent to the graphical representation of TFS. Therefore, we have chosen to make a preliminary work within the representation process 
	  that leads to XML / Java. This work is the representations of TFS by means of UML diagrams. This representation has two advantages: first it is standard, secondly there is many 
	  friendly and ergonomic tools that enable to build UML diagrams like Omondo (<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.omondo.com/</link>) or Poseidon (<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.gentleware.com/</link>).
	</para></section><!-- --><section><title>UML Representation</title><para>As we have already said, TEI consortium proposes guidelines for implementing TFS in XML (<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.tei-c.org/Guidelines/P5/</link>). However, OTIM consortium has decided 
	      not to encode TFS this way for several reasons [<xref linkend="ICGL2010"/>]. First, 
	      there is a need of representation for type hierarchies and inheritance. Secondly, it is not realistic, or even possible, to encode all information by means of a TFS, 
		  that rapidly becomes huge and intractable. This last argument is important in the perspective of interoperability: annotation tools mainly focus on properties annotation (the 
		  encoding of object characteristics). Only some of them propose solution for constituency representation (e.g. in terms of primary/secondary tracks). None implement typing machinery. 
		  We think then preferable a decentralized representation in which objects are represented separately, their organization in hierarchy being encoded independently from their properties. 
		  Such an encoding offers the advantage to be close to the traditional way of encoding annotations without losing the richness of TFS representation.</para><para>OTIM UML representation relies on two different views. Static one describes the static structure in terms of objects, attributes, operations and relationships. This view 
	      includes class diagrams. Dynamic view emphasizes the dynamic behavior of a system. One of its advantages is that the language includes a set of graphical notation 
		  techniques to create and share intuitive visual models. We can represent a TFS description by a set of UML class diagrams by means of the following mapping:
          <itemizedlist><listitem><para>to each complex TFS corresponds a class,</para></listitem><listitem><para>to each TFS atomic attribute corresponds a class attribute,</para></listitem><listitem><para>the inheritance relationship defined on the TFS is represented by an inheritance relationship between classes,</para></listitem><listitem><para>the constituency relationships between TFS are represented by aggregation relationships between classes,</para></listitem></itemizedlist>
		  
          <figure xml:id="uml-phonetics"><title>The phonetics domain</title><mediaobject><imageobject><imagedata format="png" fileref="../../../vol7/graphics/Seinturier01/Seinturier01-003.png" width="125%"/><!--<imagedata format="png" fileref="Bal2011SMB102203.png" width="100%"/>--></imageobject></mediaobject><caption><para>UML representation of phonetics domain.</para></caption></figure>
          <xref linkend="uml-phonetics"/> shows the UML representation of phonetics and prosody domains. This graphical representation provides a global standard view of the two domains and a suitable way for experts to share 
		  their knowledge.
    </para></section><section><title>XML / Java representation</title><section><title>From TFS to XSchema</title><para>
      XML representation of the knowledge and data within the OTIM framework relies on XSchema. We generate an XSchema for each linguistic domain 
	  (for example phonetics and prosody). Data are then represented in different documents validated by the associated XSchemas. This method is motivated 
	  by two important points already said: 
	  <itemizedlist><listitem><para>this representation provides a high level of modularity for applicative requirements and enables to modify only the structure / schema needed</para></listitem><listitem><para>recents works on multistructured documents open a way for dynamically linking and aggregating various documents with different structure [<xref linkend="BRUNO2006"/>].</para></listitem></itemizedlist>
	  Within such a framework, it is possible to deal with a TFS-like XML representation and to process data as standard XML documents.
	</para><para>
      For the sake of simplicity, we call OTIM XML our set of XML schemas constructed from TFS. From a linguistic point of view, this set can be seen as the <quote>third component</quote> mentioned as a perspective 
	  in [<xref linkend="SCHMIDT2009"/>]. This component, besides a basic encoding of data exportable into linguistic standard AIF (Atlas Interchange Format)
	  <footnote><para><link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.itl.nist.gov/iaui/894.01/atlas/new/develop/aif.html</link></para></footnote>, encodes every information concerning the organization as well as the constraints 
	  on the structures. In the same way, as TFS are used as a tree description language in theories such as HPSG (Head-Driven Phrase Structure Grammar, <link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://hpsg.stanford.edu/</link>), the 
	  XML schema generated from our TFS representation also plays the same role with respect to the XML annotation data file. On the one hand, basic data can be encoded with AIF, on the other hand, the 
	  XML schema encodes all higher level information. Both components (basic data + structural constraints) guarantee against information lost that otherwise occurs when translating from one coding 
	  format to another (for example from Anvil to Praat).
    </para><para>
	  The creation of the XSchema from the linguistic knowledge is done from the TFS or the UML representation if it is available. The first step consists in representing 
	  all the information available within TFS. Each feature of a TFS appears in the associated XSchema:
	  <itemizedlist><listitem><para>feature types encoding atomic type are represented with a simple type (integer, string, ...),</para></listitem><listitem><para>composite feature types are represented with complex types.</para></listitem></itemizedlist>
	  From type definitions, a feature is represented by an XML element. The two relations of the TFS formalism (hierarchy and constituency) are represented respectively by type 
	  hierarchy and element aggregation. This representation guarantees that every information described within OTIM XML formalism can be represented by XML documents.
	  <xref linkend="app-prosody-xschema"/> shows the complete XSchema of the prosodic domain. It shows all required components for annotating the prosody of a 
	  dialog within the OTIM project.
	</para><para>
	  The choice of constructing one XSchema by linguistic domain is motivated by two reasons. The OTIM project crosses several domains but a significant part of the data processing is 
	  made within each domain. Independence between schemas implies that expert only has to work with XML documents containing the needed information. Moreover, as the knowledge 
	  on the domains evolves, a modular approach of the formal representation enables to be more reactive and efficient for updating or revising the XSchemas according to the 
	  TFS updating.
	</para></section><section><title>From raw annotations to XML documents</title><para>
	    XSchemas enable to represent the knowledge of the linguistic domains and to describe the complex structure of data but linguists work with specific tools (like PRAAT or ELAN) that provide 
	    data as raw text files or specific XML documents that are not valid with our schemas. Generating valid OTIM XML documents relies on a transformation from the outputs of linguistic tools to 
		the OTIM XML representation.
      </para><para>
	    Documents generation relies on the expression of the link between the data present within the annotation tool outputs and the value of the elements of the OTIM XML documents. 
		This link is called <quote>Annotation Scheme</quote> and describes what kind of information is contained within raw annotation files and what element is attached to within the 
		OTIM XML document. The annotation scheme also describes good practices to experts for a consistent and repeatable annotation. The construction of a set of valid XML documents is made by processing 
        the raw annotation files with the annotation scheme. 		
	  </para></section><section><title>A Java framework for managing linguistic data</title><para>
	    The OTIM project aims to fully annotate an 8 hours long corpus of recorded dialog. The raw annotation outputs from linguists' specific tools have to be processed in an efficient way 
		with respect to the OTIM XML description proposed. As linguists are very familiar with their annotation tools (PRAAT, ANVIL, ...), it was not an option to provide new tools from scratch 
		to directly make annotations within OTIM XML representation. Moreover, the diversity of the tools would make difficult to provide and maintain extensions for them in order to conform with 
		the OTIM XML. A solution for providing data processing capability that can deal with both raw annotation files and OTIM XML document is an applicative framework composed of specific modules.
	  </para><para>
	    We made the choice of developing a Java framework for OTIM that is composed of two main parts (see <xref linkend="otim-framework"/>):
		<itemizedlist><listitem><para>an implementation of the OTIM XSchemas within Object paradigm,</para></listitem><listitem><para>a set of modules that can interface with both raw annotation files and XML documents.</para></listitem></itemizedlist>
	  </para><para>
	    The first part of the framework is distributed as <quote>OTIM API</quote> and enables to deal with linguistic annotations with respect to OTIM XSchemas 
	   (and also TFS). The link between XML schemas and Java implementation is guaranteed by using the <emphasis role="ital">Java Architecture For XML Binding</emphasis> (JAXB)
	   <footnote><para>http://www.oracle.com/technetwork/articles/javase/index-140168.html</para></footnote>. This technology provides method for automatically generating Java classes from a set of XSchemas. 
	   Using JAXB makes implicit and always consistent the link between XSchemas and their Java representation. When a schema is modified, the associated Java classes are automatically regenerated.
	   In most case, a minor change within XSchemas only involves an automatic update of the Java classes (changing an element name, changing a value, ...). When the changes are important: 
	   the structure of an XSchema or the annotation scheme are modified, the update of the Java classes need to be manually performed as implementation can be heavily modified. This can be seen as a limit but this 
	   kind of changes are rare in a standardidation context.
	  </para><para>
	    The second part of the framework is a set of I/O modules that provide data exchange capabilities between OTIM XML documents and raw annotations files. The most important work of these 
		modules is to generate OTIM XML documents from raw annotations. This work is done by parsing annotations and interpreting them against the annotation scheme. Another important need is to reinsert 
		annotations that are expressed within OTIM XML format into a specific annotation tool. The I/O modules enable to export from XML documents to PRAAT or ANVIL tools and so, linguists can see 
		annotations performed by other teams on other domains within their own tools. This capability can be seen as a partial response to interoperability between different annotation tools and enable to 
		make a full pipeline from the annotation step to information system. 
	  </para></section></section><section><title>Querying and managing annotations in XML</title><para>
	  The OTIM project aims to provide a fully annotated corpus represented in XML which can be queried by the standard XQuery language. Annotations can be used in various ways: simple viewing, domain crossing or reinsertion within standard tools. 
	  Every need of access to annotations relies on a query on the corpus. We first present general queries on the corpus and then the OTIM specific queries related to time and temporal relations between 
	  annotations. These last queries need an extention of XQuery with temporal capabilities.
	</para><section><title>General queries</title><para>
	Queries are classified into two groups: those involving only a single domain and those taking into account several domains. In addition, for each group we distinguish between filtering queries and queries 
	requiring the construction of new XML documents.
	</para><para>
	Filtering queries enables to extract a subset of data in the corpus. Filtering on a single domain produces a subset of the involved OTIM XML documents. 
	For example, the following query filters the phonemes from the phonetic annotations (described within the document phonetics.xml) by getting only those 
	that are tagged with the label "A":
	<programlisting xml:space="preserve">for $phoneme in fn:doc("phonetics.xml")/SyntacticPhrase/words/word/phonemes/phoneme[@label="A"]
return $phoneme</programlisting>
    Such a quite simple query is very important for linguists as it enables to target only annotations with specific characteristics. One another example of query is the filtering of phonemes according to their 
	temporal anchoring. The following query extracts each phoneme that verifies a condition on its temporal bounds:
	<programlisting xml:space="preserve">for $phoneme in fn:doc("phonetics.xml")/SyntacticPhrase/words/word/phonemes/phoneme
where ($phoneme/TimeInterval/start/@time &gt; 250) and ($phoneme/TimeInterval/end/@time &lt; 500) 
return $phoneme
</programlisting>
   Filtered fragments can be reorganised in the <emphasis role="ital">return</emphasis> clause specifying  the structure of the result to match linguistic specific needs. For example, the following query builds an empty element 
   A (searched label) for each filtered phoneme computing its duration:  
   <programlisting xml:space="preserve">for $phoneme in fn:doc("phonetics.xml")/SyntacticPhrase/words/word/phonemes/phoneme
where ($phoneme/TimeInterval/start/@time &gt; 250) and ($phoneme/TimeInterval/end/@time &lt; 500) 
return &lt;A duration='{$phoneme/TimeInterval/end/@time - $phoneme/TimeInterval/start/@time}'/&gt;
   </programlisting>
   Finally, the following query shows an example of concurent querying based on phonetics and prosody domains. For each accentual phrase (<emphasis role="ital">ap</emphasis>) with at least 6 syllables the query builds an 
   element phoneme which is the first phoneme of the phrase as their share same start time (see inner where clause).
   <programlisting xml:space="preserve">for $ap in fn:doc("prosody-IP_AP.xml")/TurnConversationalUnit/phrases/ip/constituents/ap
where count($ap/syllables/syllable) &gt; 6
return 
  &lt;phoneme id='{$ap/@id}'&gt;{$ap/label}
  {for $phoneme in fn:doc("phonemes.xml")/phonemes/phoneme
   where $phoneme/TimeInterval/start/@time = $ap/TimeInterval/start/@time return $phoneme}
&lt;/phoneme&gt;
   </programlisting>
	</para></section><section><title>Time related queries</title><para>
	Among the queries shown above, some take into account the notion of time. For a corpus of annotations aligned with a signal such as video, time is indeed the dimension with which 
	the studied objects are related. However, even if the time can be taken in account in an absolute way without extending XQuery, the use of temporal relation (such as relations described 
	within Allen algebra) cannot be expressed. A relative expression of time position (before, after, during, ...) is a critical need when linguists process the corpus for determining some 
    complex object (<emphasis role="ital">before</emphasis>, 
  <emphasis role="ital">meets</emphasis>, <emphasis role="ital">overlaps</emphasis>, <emphasis role="ital">starts</emphasis>, <emphasis role="ital">during</emphasis>, 
  <emphasis role="ital">finishes</emphasis> and <emphasis role="ital">equal</emphasis> and symetrics). 	
	</para><para>
	We have extended XQuery by adding functions that implement Allen's relations within the OTIM XML representation. By inheritance, every object description contains the following structure that enables 
	temporal anchoring:
	<programlisting xml:space="preserve">&lt;xs:complexType name="timeInterval"&gt;
  &lt;xs:sequence&gt;
    &lt;xs:element name="start" type="timePoint" minOccurs="0"/&gt;
    &lt;xs:element name="end" type="timePoint" minOccurs="0"/&gt;
  &lt;/xs:sequence&gt;
&lt;/xs:complexType&gt;

&lt;xs:complexType name="timePoint"&gt;
  &lt;xs:sequence/&gt;
    &lt;xs:attribute name="time" type="xs:double" use="required"/&gt;
&lt;/xs:complexType&gt;
	
&lt;xs:complexType name="Object"&gt;
  &lt;xs:sequence&gt;
    &lt;xs:element name="index" type="xs:integer"/&gt;
    &lt;xs:choice minOccurs="0"&gt;
      &lt;xs:element ref="TimeInterval"/&gt;
      &lt;xs:element ref="TimePoint"/&gt;
    &lt;/xs:choice&gt;
  &lt;/xs:sequence&gt;
&lt;/xs:complexType&gt;</programlisting>
	</para><para>
	Allen's function are binaries boolean functions that take in parameter a <emphasis role="ital">TimeInterval</emphasis> or a 
  <emphasis role="ital">TimePoint</emphasis> XML fragment and that return <emphasis role="ital">true</emphasis> if the given relation is verified or <emphasis role="ital">false</emphasis> otherwise. 
	</para><para>Extending XQuery with specific time functions for OTIM XML representation is a solution that satisfies linguists need for expressiveness. However, due to TFS initial representation, OTIM XML 
	representation is not optimized for processing queries that are significantly based on time. Their use cannot be made ​​on an entire corpus. Among the possible solutions 
	to solve this problem, an explicit representation of time relationships in separate XML documents or an ontological approach (OWL) can be considered.</para></section></section><section><title>Implementation</title><para>The OTIM framework is implemented within a Java / XML framework. The JAXB technology provides a strong and consistent link between XML Schema and Java representations. The XML management and querying is 
	hosted within one eXist (<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://exist.sourceforge.net/</link>) server for web application or within an embedded eXist module for a standalone utilization. At this time, 15 minutes of the corpus 
	have been annotated for 4 domains (phonetics, prosody, syntax, disfluency). The size of an XML document representing the 15 minutes can vary from 150 up to 500 Mo.</para></section><section><title>Conclusion</title><para>
	  In this paper, our intention was to describe an XML engine dedicated to the representation and the concurrent querying of multimodal linguistic 
	  annotations implying to analyze and to find correlations between annotated linguistic domains.
	</para><para>
	  From the signal and the signal transcription of a conversational speech between two persons, experts annotate data according to different linguistics domains 
	  like prosody, phonetics, morpho-syntax, discourse or gesture/posture. From the TFS provided by linguists that describe the knowledge of the studied domains, 
	  from legacy data and annotations, we automatically build an XML corpus which can be queried by means of an extension of XQuery, in a concurrent way. A java framework has been provided
	  and enables to interface with both linguistic tools and OTIM XML information system. With this framework, the problem of the interoperability 
	  is solved for all the involved tools (PRAAT, ANVIL, ELAN) and domains within the OTIM project. Moreover, our proposal is based on XML standards.
	</para><para>
	  Nevertheless, we can notice that our XML solution cannot capture the semantics of linguistic knowledge. Moreover, TFS expressivity is limited, for example for temporal relations.  Object anchoring 
	  is absolute: interval boundaries are represented by the features <emphasis role="ital">start</emphasis> and <emphasis role="ital">end</emphasis>, with temporal value (an object can also be situated 
	  by means of a point). It would be useful to have a relative anchoring. Another limit is due to the underlying model of TFS which is a Directed Acyclic Graph (DAG). When linguists need to annotate 
	  co-references or disfluencies  which are organized around objects, it would be useful to have an object anchoring which is conflicting with the acyclic graph.      
	</para><para>
	We currently work to propose a knowledge representation formalism which be an alternative to TFS: an ontological approach based on Description Logics [<xref linkend="DLHANDBOOK2003"/>] (DL) 
	and on semantic web technologies for the development of a linguistic Knowledge-based Information System. We have already defined a linguistic ontology from the TFS provided 
	by linguists for prosody, phonetics, lexical and disfluency domains. An applicative framework is under development, it is based on semantic web proposals such as OWL DL 
	(Ontology Web Language5) for the representation of this ontology and SPARQL [<xref linkend="SPARQL2007"/>] the querying language of semantic web for its manipulation. 
	</para></section><appendix xml:id="app-prosody-xschema"><title>XSchema of the Prosodic domain</title><para>
	<programlisting xml:space="preserve">
&lt;xs:schema version="1.0" xmlns:xs="http://www.w3.org/2001/XMLSchema"&gt;

  &lt;xs:element name="Syllable" type="syllable"/&gt;

  &lt;xs:element name="TimeCompound" type="timeCompound"/&gt;

  &lt;xs:element name="TimeInterval" type="timeInterval"/&gt;

  &lt;xs:element name="TimePoint" type="timePoint"/&gt;

  &lt;xs:element name="TurnConversationalUnit" type="turnConversationalUnit"/&gt;

  &lt;xs:complexType name="turnConversationalUnit"&gt;
    &lt;xs:complexContent&gt;
      &lt;xs:extension base="Object"&gt;
        &lt;xs:sequence&gt;
          &lt;xs:element name="phrases" minOccurs="0"&gt;
            &lt;xs:complexType&gt;
              &lt;xs:sequence&gt;
                &lt;xs:choice minOccurs="0" maxOccurs="unbounded"&gt;
                  &lt;xs:element name="ip" type="IntonationalPhrase"/&gt;
                  &lt;xs:element name="ap" type="AccentualPhrase"/&gt;
                  &lt;xs:element name="pp" type="ProsodicPhrase"/&gt;
                &lt;/xs:choice&gt;
              &lt;/xs:sequence&gt;
            &lt;/xs:complexType&gt;
          &lt;/xs:element&gt;
        &lt;/xs:sequence&gt;
      &lt;/xs:extension&gt;
    &lt;/xs:complexContent&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="Object"&gt;
    &lt;xs:sequence&gt;
      &lt;xs:element name="index" type="xs:int"/&gt;
      &lt;xs:choice minOccurs="0"&gt;
        &lt;xs:element ref="TimeInterval"/&gt;
        &lt;xs:element ref="TimePoint"/&gt;
        &lt;xs:element ref="TimeCompound"/&gt;
      &lt;/xs:choice&gt;
    &lt;/xs:sequence&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="IntonationalPhrase"&gt;
    &lt;xs:complexContent&gt;
      &lt;xs:extension base="ProsodicPhrase"&gt;
        &lt;xs:sequence&gt;
          &lt;xs:element name="constituents" minOccurs="0"&gt;
            &lt;xs:complexType&gt;
              &lt;xs:sequence&gt;
                &lt;xs:element name="accentual_phrase" type="AccentualPhrase" minOccurs="0" maxOccurs="unbounded"/&gt;
              &lt;/xs:sequence&gt;
            &lt;/xs:complexType&gt;
          &lt;/xs:element&gt;
          &lt;xs:element name="contour" type="Contour" minOccurs="0"/&gt;
        &lt;/xs:sequence&gt;
      &lt;/xs:extension&gt;
    &lt;/xs:complexContent&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="ProsodicPhrase" abstract="true"&gt;
    &lt;xs:complexContent&gt;
      &lt;xs:extension base="Object"&gt;
        &lt;xs:sequence/&gt;
      &lt;/xs:extension&gt;
    &lt;/xs:complexContent&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="AccentualPhrase"&gt;
    &lt;xs:complexContent&gt;
      &lt;xs:extension base="ProsodicPhrase"&gt;
        &lt;xs:sequence&gt;
          &lt;xs:element name="label" type="xs:string" minOccurs="0"/&gt;
        &lt;/xs:sequence&gt;
      &lt;/xs:extension&gt;
    &lt;/xs:complexContent&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="timeInterval"&gt;
    &lt;xs:sequence&gt;
      &lt;xs:element name="end" type="timePoint" minOccurs="0"/&gt;
      &lt;xs:element name="start" type="timePoint" minOccurs="0"/&gt;
    &lt;/xs:sequence&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="timePoint"&gt;
    &lt;xs:sequence/&gt;
    &lt;xs:attribute name="time" type="xs:double" use="required"/&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="timeCompound"&gt;
    &lt;xs:sequence&gt;
      &lt;xs:element name="TimeLocations" minOccurs="0"&gt;
        &lt;xs:complexType&gt;
          &lt;xs:sequence&gt;
            &lt;xs:choice minOccurs="0" maxOccurs="unbounded"&gt;
              &lt;xs:element name="Interval" type="timeInterval"/&gt;
              &lt;xs:element name="Point" type="timePoint"/&gt;
            &lt;/xs:choice&gt;
          &lt;/xs:sequence&gt;
        &lt;/xs:complexType&gt;
      &lt;/xs:element&gt;
    &lt;/xs:sequence&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="Contour"&gt;
    &lt;xs:sequence&gt;
      &lt;xs:element name="direction" type="ContourDirection" minOccurs="0"/&gt;
      &lt;xs:element name="function" type="ContourFunction" minOccurs="0"/&gt;
      &lt;xs:element name="position" type="ContourPosition" minOccurs="0"/&gt;
    &lt;/xs:sequence&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="syllable"&gt;
    &lt;xs:complexContent&gt;
      &lt;xs:extension base="Object"&gt;
        &lt;xs:sequence&gt;
          &lt;xs:element name="accentuable" type="xs:boolean"/&gt;
          &lt;xs:element name="constituents" type="SyllableConstituent" nillable="true" minOccurs="0" maxOccurs="unbounded"/&gt;
          &lt;xs:element name="position" type="SyllablePosition" minOccurs="0"/&gt;
          &lt;xs:element name="prominence" type="xs:boolean"/&gt;
          &lt;xs:element name="struct" type="SyllableStruct" minOccurs="0"/&gt;
        &lt;/xs:sequence&gt;
      &lt;/xs:extension&gt;
    &lt;/xs:complexContent&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="SyllableConstituent"&gt;
    &lt;xs:sequence&gt;
      &lt;xs:element name="label" type="xs:string" minOccurs="0"/&gt;
      &lt;xs:element name="phon" type="Phoneme" nillable="true" minOccurs="0" maxOccurs="unbounded"/&gt;
      &lt;xs:element name="type" type="SyllableConstituentType" minOccurs="0"/&gt;
    &lt;/xs:sequence&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="Phoneme"&gt;
    &lt;xs:complexContent&gt;
      &lt;xs:extension base="Object"&gt;
        &lt;xs:sequence&gt;
          &lt;xs:element name="articulationGestures" type="ArticulationGestures" minOccurs="0"/&gt;
          &lt;xs:element name="category" type="PhonemeCategory" minOccurs="0"/&gt;
          &lt;xs:element name="label" type="xs:string" minOccurs="0"/&gt;
          &lt;xs:element name="phonemeType" type="phoneme_type" minOccurs="0"/&gt;
          &lt;xs:element name="role" type="Role" minOccurs="0"/&gt;
          &lt;xs:element name="sonority" type="PhonemeSonority" minOccurs="0"/&gt;
        &lt;/xs:sequence&gt;
      &lt;/xs:extension&gt;
    &lt;/xs:complexContent&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="ArticulationGestures"&gt;
    &lt;xs:sequence&gt;
      &lt;xs:element name="glottis" type="Aperture" minOccurs="0"/&gt;
      &lt;xs:element name="lip" type="Lip" minOccurs="0"/&gt;
      &lt;xs:element name="tongue" type="Tongue" minOccurs="0"/&gt;
      &lt;xs:element name="velum" type="Aperture" minOccurs="0"/&gt;
    &lt;/xs:sequence&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="Lip"&gt;
    &lt;xs:sequence&gt;
      &lt;xs:element name="aperture" type="Aperture" minOccurs="0"/&gt;
      &lt;xs:element name="protusion" type="xs:string" minOccurs="0"/&gt;
    &lt;/xs:sequence&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="Tongue"&gt;
    &lt;xs:sequence&gt;
      &lt;xs:element name="bodyConstriction" type="BodyConstriction" minOccurs="0"/&gt;
      &lt;xs:element name="tipConstriction" type="TipConstriction" minOccurs="0"/&gt;
    &lt;/xs:sequence&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="BodyConstriction"&gt;
    &lt;xs:sequence&gt;
      &lt;xs:element name="degree" type="xs:string" minOccurs="0"/&gt;
      &lt;xs:element name="location" type="BodyConstrictionLocation" minOccurs="0"/&gt;
    &lt;/xs:sequence&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="TipConstriction"&gt;
    &lt;xs:sequence&gt;
      &lt;xs:element name="degree" type="xs:string" minOccurs="0"/&gt;
      &lt;xs:element name="location" type="TipConstrictionLocation" minOccurs="0"/&gt;
    &lt;/xs:sequence&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="Role"&gt;
    &lt;xs:sequence&gt;
      &lt;xs:element name="epenthetic" type="xs:boolean"/&gt;
      &lt;xs:element name="liaison" type="xs:boolean"/&gt;
    &lt;/xs:sequence&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:complexType name="SyllablePosition"&gt;
    &lt;xs:sequence&gt;
      &lt;xs:element name="rank" type="xs:int"/&gt;
      &lt;xs:element name="syl_number" type="xs:int"/&gt;
    &lt;/xs:sequence&gt;
  &lt;/xs:complexType&gt;

  &lt;xs:simpleType name="ContourDirection"&gt;
    &lt;xs:restriction base="xs:string"&gt;
      &lt;xs:enumeration value="Raising"/&gt;
      &lt;xs:enumeration value="Falling"/&gt;
      &lt;xs:enumeration value="Falling_raising"/&gt;
      &lt;xs:enumeration value="Raising_falling"/&gt;
      &lt;xs:enumeration value="Unspecified"/&gt;
    &lt;/xs:restriction&gt;
  &lt;/xs:simpleType&gt;

  &lt;xs:simpleType name="ContourFunction"&gt;
    &lt;xs:restriction base="xs:string"&gt;
      &lt;xs:enumeration value="Conclusive"/&gt;
      &lt;xs:enumeration value="NonConclusive"/&gt;
    &lt;/xs:restriction&gt;
  &lt;/xs:simpleType&gt;

  &lt;xs:simpleType name="ContourPosition"&gt;
    &lt;xs:restriction base="xs:string"&gt;
      &lt;xs:enumeration value="Final"/&gt;
      &lt;xs:enumeration value="Penultimate"/&gt;
      &lt;xs:enumeration value="Unspecified"/&gt;
    &lt;/xs:restriction&gt;
  &lt;/xs:simpleType&gt;

  &lt;xs:simpleType name="Aperture"&gt;
    &lt;xs:restriction base="xs:string"&gt;
      &lt;xs:enumeration value="wide"/&gt;
      &lt;xs:enumeration value="narrow"/&gt;
      &lt;xs:enumeration value="closed"/&gt;
    &lt;/xs:restriction&gt;
  &lt;/xs:simpleType&gt;

  &lt;xs:simpleType name="BodyConstrictionLocation"&gt;
    &lt;xs:restriction base="xs:string"&gt;
      &lt;xs:enumeration value="wide"/&gt;
      &lt;xs:enumeration value="narrow"/&gt;
      &lt;xs:enumeration value="closed"/&gt;
    &lt;/xs:restriction&gt;
  &lt;/xs:simpleType&gt;

  &lt;xs:simpleType name="TipConstrictionLocation"&gt;
    &lt;xs:restriction base="xs:string"&gt;
      &lt;xs:enumeration value="alveolar"/&gt;
      &lt;xs:enumeration value="dental"/&gt;
    &lt;/xs:restriction&gt;
  &lt;/xs:simpleType&gt;

  &lt;xs:simpleType name="PhonemeCategory"&gt;
    &lt;xs:restriction base="xs:string"&gt;
      &lt;xs:enumeration value="vowel"/&gt;
      &lt;xs:enumeration value="consonant"/&gt;
    &lt;/xs:restriction&gt;
  &lt;/xs:simpleType&gt;

  &lt;xs:simpleType name="phoneme_type"&gt;
    &lt;xs:restriction base="xs:string"&gt;
      &lt;xs:enumeration value="occlusive"/&gt;
      &lt;xs:enumeration value="fricative"/&gt;
      &lt;xs:enumeration value="nasal"/&gt;
    &lt;/xs:restriction&gt;
  &lt;/xs:simpleType&gt;

  &lt;xs:simpleType name="PhonemeSonority"&gt;
    &lt;xs:restriction base="xs:string"&gt;
      &lt;xs:enumeration value="voiced"/&gt;
      &lt;xs:enumeration value="voiceless"/&gt;
    &lt;/xs:restriction&gt;
  &lt;/xs:simpleType&gt;

  &lt;xs:simpleType name="SyllableConstituentType"&gt;
    &lt;xs:restriction base="xs:string"&gt;
      &lt;xs:enumeration value="Onset"/&gt;
      &lt;xs:enumeration value="Nucleus"/&gt;
      &lt;xs:enumeration value="Coda"/&gt;
    &lt;/xs:restriction&gt;
  &lt;/xs:simpleType&gt;

  &lt;xs:simpleType name="SyllableStruct"&gt;
    &lt;xs:restriction base="xs:string"&gt;
      &lt;xs:enumeration value="V"/&gt;
      &lt;xs:enumeration value="CV"/&gt;
      &lt;xs:enumeration value="CCV"/&gt;
      &lt;xs:enumeration value="CVC"/&gt;
      &lt;xs:enumeration value="CCVC"/&gt;
      &lt;xs:enumeration value="CVCC"/&gt;
      &lt;xs:enumeration value="VC"/&gt;
      &lt;xs:enumeration value="CCCV"/&gt;
      &lt;xs:enumeration value="CCVCC"/&gt;
      &lt;xs:enumeration value="CCCVC"/&gt;
      &lt;xs:enumeration value="VCC"/&gt;
      &lt;xs:enumeration value="OTHER"/&gt;
    &lt;/xs:restriction&gt;
  &lt;/xs:simpleType&gt;
&lt;/xs:schema&gt;

	</programlisting>
	</para></appendix><bibliography><title>Bibliography</title><!--
	

S. Bird and M. Liberman. A formal framework
for linguistic annotation. In Speech Communication
33(1,2), pages 23–60, september 2001.
8http://lpl-aix.fr/~otim

P.-V. Biron and A. Malhotra. XML Schema Part
2: Datatypes second edition. Recommendation,

S. Boag. XQuery 1.0 : An XML Query Language.
Recommendation, W3C, 2007.

T. Bray, J. Paoli, and C.-M. Sperberg-McQueen.
Extensible Markup Language (XML) 1.0. Recommendation,
W3C, 1998.

J. Clark and S. Derose. XML Path Language
(XPath) V1.0. Recommendation, W3C, 1999.
[17] J. Clark and M. Murata. RELAX NG Specification.
Technical report, OASIS, 2001.

D. Draper et al. XQuery 1.0 and XPath 2.0 Formal
Semantics . Recommendation, W3C, 2007.

P. Durusau and M. Brook O’Donnell. Concurrent
markup for xml documents. In Proceedings
of XML Europe Atlanta, 2002.

M. Fernandez, A. Malhotra, J. Marsh, M. Nagy,
and N. Walsh. XQuery 1.0 and XPath 2.0 Data
Model. Recommendation, W3C, 2007.

I.-E. Iacob and A. Dekhtyar. Towards a query
language for multihierarchical xml: Revisiting
xpath,. In Proceedings of The Eighth International
Workshop on the Web and Databases
(WebDB’05), pages 43 – 48, june 2005.



<bibliomixed xml:id="" xreflabel="">
	
	<emphasis role="ital"></emphasis> 
    in <quote></quote> 
		
	</bibliomixed>

--><bibliomixed xml:id="BRUNO2007B" xreflabel="Bruno 2007b">
	Bruno E., Calabretto S., Murisasco E.
	<emphasis role="ital">Documents textuels multistructurés : un état de l’art, Revue en Sciences du Traitement de l'Information</emphasis> 
    in <quote>I3 (Information - Interaction – Intelligence) , Vol. 7 (1).</quote> 
	2007
	</bibliomixed><bibliomixed xml:id="BRUNO2007" xreflabel="Bruno 2007">
	Bruno, E. and Murisasco, E.
	<emphasis role="ital">An xml environment for multistructured textual documents.</emphasis> 
    in <quote>Proceedings of the Second International Conference on Digital Information Management (ICDIM’07), pages 230–235.</quote> 
	 Lyon, France, October 2007.	
	</bibliomixed><bibliomixed xml:id="BRUNO2006" xreflabel="Bruno 2006">
	Bruno, E. and Murisasco, E.
	<emphasis role="ital">Describing and querying hierarchical structures defined over the same textual data</emphasis> 
    in <quote>Proceedings of the ACM Symposium on Document Engineering (DocEng 2006), pages 147–154.</quote> 
	Amsterdam, The Netherlands, October 2006	
	</bibliomixed><bibliomixed xml:id="JLM2006" xreflabel="Le Maitre 2006">
	Le Maitre, J. 
	<emphasis role="ital">Describing multistructured xml documents by means of delay nodes.</emphasis> 
    in <quote>Proceedings of the 2006 ACM symposium on Document engineering (DocEng ’06), pp 155–164.</quote> 
	Amsterdam, The Netherlands, oct 2006.
	</bibliomixed><bibliomixed xml:id="ALLEN1991" xreflabel="Allen 1991">Allen, J.<emphasis role="ital">Time and time again : The many ways represent time</emphasis> 
		in <quote>International Journal of Intelligent Systems</quote> 
		6(4):341–355, july 1991
	</bibliomixed><bibliomixed xml:id="DLHANDBOOK2003" xreflabel="Baader et al. 2003">
	Baader F., Calvanese D., McGuinness D.L., Nardi D., P. F., Patel-Schneider P.F.
	<emphasis role="ital">The Description Logic Handbook: Theory, Implementation, Applications.</emphasis> 
    Cambridge University Press, Cambridge, UK, 2003. ISBN 0-521-78176-0
		
	</bibliomixed><bibliomixed xml:id="PORTIER2010" xreflabel="Portier 2010">
	Portier, P.-E. and Calabretto S.
	<emphasis role="ital">Multi-structured documents and the emergence of annotations vocabularies.</emphasis> 
    in <quote>Proceedings of Balisage: The Markup Conference 2010. Balisage Series on Markup Technologies, vol. 5.</quote> 
	Montréal, Canada, August 3 - 6, 2010.
	</bibliomixed><bibliomixed xml:id="BIRD2001" xreflabel="Bird 2001">
	Bird S. and Liberman M.
	<emphasis role="ital">A formal framework for linguistic annotation.</emphasis> 
    in <quote>Speech Communication 33(1,2), pages 23–60.</quote> 
    september 2001.
	</bibliomixed><bibliomixed xml:id="BIRD2000" xreflabel="Bird et al. 2000">
	Bird, S., Day, D., Garofolo, J., Henderson, J., Laprun, C., and Liberman, M.
	<emphasis role="ital">ATLAS: A flexible and extensible architecture for linguistic annotation</emphasis> 
    2000
	</bibliomixed><bibliomixed xml:id="IDE2007" xreflabel="Ide 2007">
	Ide, N., Suderman, K. 
	<emphasis role="ital">GrAF: A Graph-based Format for Linguistic Annotations</emphasis> 
    in <quote>Proceedings of the Linguistic Annotation Workshop LAW'07.</quote> 
	2007
	</bibliomixed><bibliomixed xml:id="DEKHTYAR2005" xreflabel="Dekhtyar 2005">
	Dekhtyar A. and Iacob I.E.
	<emphasis role="ital">A framework for management of concurrent xml markup.</emphasis> 
    in <quote>Data and Knowledge Engineering, 52(2):185–208,</quote> 
	2005
	</bibliomixed><bibliomixed xml:id="CHATTI2007" xreflabel="Chatti 2007">
	Chatti, N., Kaouk, S., Calabretto, S. and Pinon J.M..
	<emphasis role="ital">Multix: an xml based formalism to encode multi-structured documents.</emphasis> 
    in <quote>Proceedings of Extreme Markup Languages Conference.</quote> 
	August 6-10 2007.  
	</bibliomixed><bibliomixed xml:id="DJEMAL2008" xreflabel="Djemal 2008">
	Djemal K., Soule-Dupuy and Valles-Parlangeau, C.
	<emphasis role="ital">Modeling and exploitation of multistructured documents.</emphasis> 
    in <quote>Proceedings of the IEEE 3rd International Conference on Information and Communication Technologies: From Theory to Applications (ICTTA’ 08).</quote> 
    Damascus, Syria, April 2008.
	</bibliomixed><bibliomixed xml:id="SGML" xreflabel="Goldfarb 1990">
	Goldfarb, C.-F. and Rubinsky Y.
	<emphasis role="ital">The SGML handbook.</emphasis> 
    <quote>Clarendon Press,</quote> 
	Oxford, 1990.
	</bibliomixed><bibliomixed xml:id="HILBERT2005" xreflabel="Hilbert 2005">
	Hilbert M., Schonefeld O. and Witt A.
	<emphasis role="ital">Making concur work.</emphasis> 
    in <quote>Proceedings of The Extreme Markup Languages Conference.</quote> 
	August 2005.
	</bibliomixed><bibliomixed xml:id="DEROSE2004" xreflabel="DeRose 2004">
	DeRose, S.
	<emphasis role="ital">Markup overlap : a review and a horse.</emphasis> 
    in <quote>In Proceedings of The Extreme markup language Conference.</quote> 
	2004
	</bibliomixed><bibliomixed xml:id="JAGADISH2004" xreflabel="Jagadish et al. 2004">
	Jagadish, H.-V., Lakshmanan, L.-V.-S., Scannapieco, M., Srivastava, D. and Wiwatwattana N.
	<emphasis role="ital">Colorful XML: One Hierarchy Isn’t Enough.</emphasis> 
    in <quote>Proceedings of The International Conference on Management of Data (SIGMOD’04), pages 251–262.</quote> 
	2004	
	</bibliomixed><bibliomixed xml:id="TEIP4" xreflabel="TEI P4">
	Sperberg-McQueen, C.-M. and Burnard, L.
	<emphasis role="ital">Tei p4 guidelines for electronic text encoding and interchange.</emphasis> 
	2001
	</bibliomixed><bibliomixed xml:id="SPERBERG2000" xreflabel="Sperberg-McQueen 2000">
	Sperberg-McQueen, C-M and Huitfeldt, C.
	<emphasis role="ital">Goddag: A data structure for overlapping hierarchies.</emphasis> 
    in <quote>Proceedings of The Principles of Digital Document and electronic publishing (DDEP/PODDP’00), pages 139–160.</quote> 
	2000
	</bibliomixed><bibliomixed xml:id="TENNINSON2002" xreflabel="Tennison 2002">
	Tennison, J. and Wendell, P.
	<emphasis role="ital">Layered markup and annotation language (lmnl)</emphasis> 
    in <quote>Proceedongs of The Extreme Markup Languages Conference.</quote> 
	2002
	</bibliomixed><bibliomixed xml:id="WITT2004" xreflabel="Witt 2004">
	Witt, A.
	<emphasis role="ital">Multiple hierarchies : news aspects of an old solution.</emphasis> 
    in <quote>Proceedings of The Extreme markup language Conference.</quote> 
	2004
	</bibliomixed><bibliomixed xml:id="LAW2010" xreflabel="Blache 2010b">
	Blache, P., Bertrand, R., Bigi, B., Bruno, E., Cela, E., Esperrer, R., Ferre, G., Guardiola, M., Hirst, D., Magro, E., JC, M., C, M., Ma, M., Murisasco, E., I, N., P, N., B, P., Laurent, P., J, P.-V., Seinturier, J., N, T., Marion, T., and Stephane, R.
	<emphasis role="ital">Multimodal annotation of conversational data.</emphasis> 
    in <quote>In Proceedings of the fourth linguistic annotation workwhop (LAW), pages 186–191.</quote> 
    Assocation for computational Lunguistics (ACL). 2010
	</bibliomixed><bibliomixed xml:id="COPESTAKE2003" xreflabel="Copestake 2003">
	Copestake, A.
	<emphasis role="ital">Definitions of Typed Feature Structures.</emphasis> 
    in <quote>Collaborative Language Engineering: A Case Study in Efficient Grammar-based Processing</quote> 
    CSLI Publications, Ventura Hall, Stanford University, Stanford, CA 94305-4115, 2003.
	</bibliomixed><bibliomixed xml:id="SPARQL2007" xreflabel="Prud’hommeaux 2007">
	Prud’hommeaux, E. and Seaborne, A.
	<emphasis role="ital">Sparql query language for rdf (working draft)</emphasis> 
	<quote>Technical report</quote> 
	W3C.
	<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.w3.org/2009/sparql/wiki/Main_Page</link>
	</bibliomixed><bibliomixed xml:id="SCHMIDT2009" xreflabel="Schmidt et al. 2009">Schmidt, T., Duncan, S., Ehmer, O., Hoyt, J., Kipp, M., Loehr, D., Magnusson, M., Rose, T., and Sloetjes, H.
	  <emphasis role="ital">chapter An exchange format for multimodal annotations</emphasis> 
		in <quote>Multimodal corpora.</quote> 
		pages 207–221. Springer-Verlag, Berlin, Heidelberg, 2009
	</bibliomixed><bibliomixed xml:id="STHRENBERG2009" xreflabel="Sthrenberg 2009">Sthrenberg, M. and Jettka, D.<emphasis role="ital">A toolkit for multidimensional markup - the development of sgf to xstandoff</emphasis> 
		in <quote>Proceedings of Balisage: The Markup Conference 2009</quote> 
		Assocation for computational Lunguistics(ACL), Balisage Series on Markup Technologies, vol. 3.
		<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.xstandoff.net/</link>
	</bibliomixed><bibliomixed xml:id="ICGL2010" xreflabel="Blache 2010">Blache, Philippe and Bigi, Brigitte and Prévot, Laurent and Rauzy, Stéphane and Seinturier, Julien<emphasis role="ital">Annotation schemes, annotation tools and the question of interoperability: from Typed Feature Structures to XML Schemas</emphasis> 
		in <quote>Proceedings of the 2nd International Conférence on Global Interoperability for Language Resources</quote> 
		(compiled under Act of Congress of 18-20 January, 2010). City University of Hong Kong
		<link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest">http://www.yale.edu/lawweb/avalon/raleigh.htm</link>.
	</bibliomixed><bibliomixed xml:id="CARPENTER1992" xreflabel="Carpenter 1992">
	  Carpenter, R. L.
	  <emphasis role="ital">The Logic of Typed Feature Structures.</emphasis> 
		in <quote>volume 32 of Cambridge Tracts in Theoretical Computer Science</quote> 
		Cambridge University Press, The Edinburgh Building, Shaftesbury Road, Cambridge CB2 8RU, United Kingdom. 1992
	</bibliomixed></bibliography></article>