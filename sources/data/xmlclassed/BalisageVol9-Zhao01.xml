<?xml version="1.0" encoding="UTF-8" standalone="no"?><classedDocument><article xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" class="po-hcontainer e0 e0" version="5.0-subset Balisage-1.3" xml:id="HR-23632987-8973"><title class="po-block e1 e1"><textual class="po-textual">Quality Control Practice for Scholars Portal, an XML-based E-journals Repository</textual></title><info class="po-record e2 e2"><confgroup class="po-record e3 e3"><conftitle class="po-field e4 e4"><textual class="po-textual">International Symposium on Quality Assurance and Quality Control in XML</textual></conftitle><confdates class="po-field e5 e5"><textual class="po-textual">August 6, 2012</textual></confdates></confgroup><abstract class="po-container e6 e6"><para class="po-block e7 e7"><textual class="po-textual">Ontario Scholars Portal (SP) is an XML based digital repository containing over
        31,000,000 articles from more than 13,000 full text journals of 24 publishers which covers every
        academic discipline. Starting in 2006, SP began adopting NLM Journal Archiving and
        Interchange Tag Set v2.3 for its XML based E-journals system using MarkLogic. The
        publishers' native data is transformed to NLM Tag Set in SP in order to normalize data
        elements to a single standard for archiving, display and searching. Scholars Portal has
        established extremely high standards for ensuring that the content loaded into Scholars
        Portal is accurate and complete. Through the entire workflow from data ingest , data
        conversion and data display, quality control procedures have been implemented to ensure the
        integrity of the digital repository. </textual></para></abstract><author class="po-record e8 e8"><personname class="po-record e9 e9"><firstname class="po-field e10 e10"><textual class="po-textual">Wei</textual></firstname><surname class="po-field e11 e11"><textual class="po-textual">Zhao</textual></surname></personname><personblurb class="po-container e12 e12"><para class="po-block e13 e13"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></para></personblurb><affiliation class="po-record e14 e14"><jobtitle class="po-field e15 e15"><textual class="po-textual">Metadata Librarian</textual></jobtitle><orgname class="po-block e16 e16"><textual class="po-textual">OCUL Scholars Portal</textual></orgname></affiliation><email class="po-field e17 e17"><textual class="po-textual">w.zhao@utoronto.ca</textual></email></author><author class="po-record e18 e18"><personname class="po-record e19 e19"><firstname class="po-field e20 e20"><textual class="po-textual">Jayanthy</textual></firstname><surname class="po-field e21 e21"><textual class="po-textual">Chengan</textual></surname></personname><personblurb class="po-container e22 e22"><para class="po-block e23 e23"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></para></personblurb><affiliation class="po-record e24 e24"><jobtitle class="po-field e25 e25"><textual class="po-textual">Senior Software Developer</textual></jobtitle><orgname class="po-block e26 e26"><textual class="po-textual">OCUL Scholars Portal</textual></orgname></affiliation><email class="po-field e27 e27"><textual class="po-textual">jayanthy.chengan@utoronto.ca</textual></email></author><author class="po-record e28 e28"><personname class="po-record e29 e29"><firstname class="po-field e30 e30"><textual class="po-textual">Agnes</textual></firstname><surname class="po-field e31 e31"><textual class="po-textual">Bai</textual></surname></personname><personblurb class="po-container e32 e32"><para class="po-block e33 e33"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></para></personblurb><affiliation class="po-record e34 e34"><jobtitle class="po-field e35 e35"><textual class="po-textual">System and Web Development Analyst</textual></jobtitle><orgname class="po-block e36 e36"><textual class="po-textual">OCUL Scholars Portal</textual></orgname></affiliation><email class="po-field e37 e37"><textual class="po-textual">agnes.bai@utoronto.ca</textual></email></author><legalnotice class="po-container e38 e38"><para class="po-block e39 e39"><textual class="po-textual">Copyright © 2012 by the authors. Used with permission.</textual></para></legalnotice><keywordset class="po-table e40 e40" role="author"><keyword class="po-field e41 e41"><textual class="po-textual">Quality Assurance</textual></keyword><keyword class="po-field e42 e42"><textual class="po-textual">Quality Control</textual></keyword><keyword class="po-field e43 e43"><textual class="po-textual">Scholars Portal</textual></keyword><keyword class="po-field e44 e44"><textual class="po-textual">XML</textual></keyword></keywordset></info><section class="po-hcontainer e45 e45"><title class="po-block e46 e46"><textual class="po-textual">Introduction</textual></title><para class="po-block e47 e47"><textual class="po-textual">Ontario Scholars Portal (SP) is an XML-based digital repository containing over 32 Million
      articles from more than 13,000 full text journals of 24 publishers which covers every academic
      discipline. The E-journal service is available to faculty and students of 21 universities
      spread across the province of Ontario. The data provided by the publishers are in XML or SGML
      format typically with different DTD or schema. The publishers’ native data is transformed to
      the NLM Journal Interchange and Archiving Tag Set in SP in order to normalize data elements to
      a single standard for archiving, display and searching. To fulfill OCUL’s mission of
        </textual><quote class="po-inline e48 e48"><textual class="po-textual">provide and preserve academic resources essential for teaching, learning and research
          (</textual><xref class="po-milestone e49 e49" linkend="ref1"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">)</textual></quote><textual class="po-textual">, SP has established high standards to ensure the high
      quality of their resource and service. A series of procedures and tools have been implemented
      throughout the workflow. In addition, SP is undergoing the TDR (Trustworthy Digital
      Repository) audit process since January 2012 to further make the content reliable and
      long-term preservation.</textual></para></section><section class="po-hcontainer e50 e50"><title class="po-block e51 e51"><textual class="po-textual">Background</textual></title><para class="po-block e52 e52"><textual class="po-textual">The SP development team began planning for a migration of the Scholars Portal e-journals
      repository from ScienceServer to a new XML-based database using MarkLogic in 2006.  During
      this process SP team decided to adopt Archiving and Interchange DTD (</textual><xref class="po-milestone e53 e53" linkend="ref2"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">)
      as the standard for the new e-journal system. The publishers’ native data is transformed to
      the NLM Journal Interchange and Archiving Tag Set v.3.0. The transformed NLM XML files are
      then stored in MarkLogic database for display and searching while the publisher’s source data
      resides on the file system for long-term preservation. SP ingests the data from 25 vendors, 10
      of these vendors provides descriptive metadata in XML file using NLM DTD suite. The remaining
      vendors use their home-developed DTDs in XML, SGML header or text file as the descriptive
      metadata. The quality of the incoming data varies with publishers causing data problems as
      previously addressed by Portico, the data is not always processed with standard tools that
      enforced well-formedness or validity (</textual><xref class="po-milestone e54 e54" linkend="ref3"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">). Some of the issues with
      incoming data to SP includes: omitting the DTD or encoding declarations, employ the elements
      which is not included in the DTD, adopts a new DTD without notification and includes invalid
      entities.</textual></para><para class="po-block e55 e55"><textual class="po-textual">Here are some examples of the publisher's data with errors.</textual></para><para class="po-block e56 e56"><textual class="po-textual">Example 1 shows the invalid value in
      &lt;mm&gt;:</textual><programlisting class="po-block e57 e57" xml:space="preserve"><textual class="po-textual">        &lt;jrn_info&gt;            
        &lt;jrn_title&gt;First Language&lt;/jrn_title&gt;            
        &lt;ISSN&gt;0142-7237&lt;/ISSN&gt;            
        &lt;vol&gt;32&lt;/vol&gt;            
        &lt;iss&gt;1-2&lt;/iss&gt;            
        &lt;date&gt;                
        &lt;yy&gt;2012&lt;/yy&gt;                
        </textual><emphasis class="po-inline e58 e58" role="bold"><textual class="po-textual">&lt;mm&gt;Data incorrect-05&lt;/mm&gt;</textual></emphasis><textual class="po-textual">
        &lt;/date&gt;        
        &lt;jrn_info&gt;</textual></programlisting><textual class="po-textual">
    </textual></para><para class="po-block e59 e59"><textual class="po-textual">Example 2 shows valid xml elements &lt;volume&gt; and &lt;issue&gt; but holds invalid
      data:</textual><programlisting class="po-block e60 e60" xml:space="preserve"><textual class="po-textual">        &lt;pub-date pubtype="epub"&gt;
        &lt;day&gt;5&lt;/day&gt;
        &lt;month&gt;1&lt;/month&gt;
        &lt;year&gt;2011&lt;/year&gt;
        &lt;/pub-date&gt;
        </textual><emphasis class="po-inline e61 e61" role="bold"><textual class="po-textual">&lt;volume&gt;00&lt;/volume&gt;
        &lt;issue&gt;00&lt;/issue&gt;</textual></emphasis><textual class="po-textual">
        &lt;fpage&gt;483&lt;/fpage&gt;
        &lt;lpage&gt;490&lt;/lpage&gt;
        ... </textual></programlisting></para><para class="po-block e62 e62"><textual class="po-textual">Example 3 shows the entity not being processed
      properly:</textual><programlisting class="po-block e63 e63" xml:space="preserve"><textual class="po-textual">        &lt;surname&gt;Orr[</textual><emphasis class="po-inline e64 e64" role="bold"><textual class="po-textual">ugrave</textual></emphasis><textual class="po-textual">]&lt;/surname&gt; 
        &lt;article-title&gt;     From &amp;#xE532;&amp;#x210B;&amp;#x2110;&amp;#xE530; and RDF to OWL&lt;/article-title&gt;</textual></programlisting></para><para class="po-block e65 e65"><textual class="po-textual">A local loading agreement is signed when the vendor agrees to load their content on
      Scholars Portal. In this agreement, the licensor agrees to provide Licensed Materials in SGML
      or XML structure information (metadata) for each article conforming to the publishers DTD or
      XML Schema (</textual><xref class="po-milestone e66 e66" linkend="ref5"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">). In practice, some publishers do not check the
      well-formedness or validate the data before sending the data and in some cases do not have the
      technical resource to do so. Some small publishers contact the third party to supply the data
      and causing communication problems.</textual></para></section><section class="po-hcontainer e67 e67"><title class="po-block e68 e68"><textual class="po-textual">Quality Control Practice</textual></title><para class="po-block e69 e69"><textual class="po-textual">Scholars Portal is committed to ensuring the integrity of digital objects within the
      repository. Scholars Portal quality control standards include checking fixity each time the
      digital object is moved during the ingest process. This ensures that the file has been
      transferred correctly without becoming corrupted during the process. Errors are recorded
      automatically in an error log and an email notification is send immediately to the metadata
      librarian. Then the cause of errors were analyzed and corrected as soon as possible (</textual><xref class="po-milestone e70 e70" linkend="ref4"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">).</textual></para><para class="po-block e71 e71"><textual class="po-textual">The Ingest Process Overview (</textual><xref class="po-milestone e72 e72" linkend="sp_ingest"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">) shows the different aspects of
      the digital object's journey from the time it is ingested into the repository to the time it
      is made accessible to the designated community.</textual></para><figure class="po-container e73 e73" xml:id="sp_ingest"><title class="po-block e74 e74"><textual class="po-textual">Scholarsportal Ingest Process Overview</textual></title><mediaobject class="po-container e75 e75"><imageobject class="po-container e76 e76"><imagedata class="po-meta e77 e77" fileref="../../../vol9/graphics/Zhao01/Zhao01-001.png" format="png" width="85%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure><section class="po-hcontainer e78 e78"><title class="po-block e79 e79"><textual class="po-textual">1. Quality Control procedures during FTP automation</textual></title><para class="po-block e80 e80"><textual class="po-textual">Depending on the publisher, incoming data is either pulled or pushed from the
        publisher's FTP into SP Ejournals FTP location. After a new dataset is saved into the
        Ejournals FTP, it is retrieved and the file size is compared to that of the original copy
        held in the publisher FTP server. If the file size does not match, the script sets the error
        flag and increments the try count. Once the try count hits three with an error flag, the
        file is deemed to be corrupted and an email is sent to the responsible members within SP.
        Datasets with successful results from the file size comparison proceeds to the next step of
        decompression. If there is an error during decompression, the script writes the file name to
        the error log and saves the error file to a temporary directory for further investigation.
        The log file information is then emailed to JIRA (</textual><xref class="po-milestone e81 e81" linkend="ref4"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">). Here is an
        example of the log with decompressing error. </textual><figure class="po-container e82 e82" xml:id="decom_error_log"><title class="po-block e83 e83"><textual class="po-textual">Decompression Error Log</textual></title><mediaobject class="po-container e84 e84"><imageobject class="po-container e85 e85"><imagedata class="po-meta e86 e86" fileref="../../../vol9/graphics/Zhao01/Zhao01-002.png" format="png"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure><textual class="po-textual">
      </textual></para></section><section class="po-hcontainer e87 e87"><title class="po-block e88 e88"><textual class="po-textual">2. Quality Control procedures during E-journals loading</textual></title><para class="po-block e89 e89"><textual class="po-textual">The data transformation from the publishers’ native data to Scholars Portal NLM XML data
        is processed in two steps - mapping and coding. Creating XML transformations in these two
        separate steps not only maximizes the skills of various team members, but also reduces
        development time and cost, and increases accuracy of the finished code (</textual><xref class="po-milestone e90 e90" linkend="ref6"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">). First, the mapping is created by metadata librarian who posses strong analytical
        skills, ability to articulate complex relationships and familiarity with both publisher’s
        data structure and NLM data structure. The crosswalk includes the mapping of the path from
        source to target data and the explanation of decisions and compromises. Second, the
        programmer with coding experiences then develops the loader according to the crosswalk using
        Java. A test environment is set up so the transformations are tested before the data is
        loaded into production. The metadata librarian inspects the output with the crosswalk
        mapping and go through several iterations to make sure the data are transformed completely
        and explicitly. After loading into production system, the transformation of each dataset has
        been logged for any errors (</textual><xref class="po-milestone e91 e91" linkend="ref7"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">). </textual></para><section class="po-hcontainer e92 e92"><title class="po-block e93 e93"><textual class="po-textual">2.1 Parsing the source file </textual></title><para class="po-block e94 e94"><textual class="po-textual">SP receives the publisher's data either in SGML or XML.  In case of SGML format, OSX
          is used to parse and validate the SGML document and to write an equivalent XML document to
          a temporary directory for further transformation. </textual></para><para class="po-block e95 e95"><textual class="po-textual">The java library(javax.xml.parsers) parses the content of the given input source as an
          XML document and return a new DOM Document object.  SAXException is thrown in case of any
          error during parsing.</textual></para><para class="po-block e96 e96"><textual class="po-textual">Some of the common issues in source file are:</textual></para><para class="po-block e97 e97"><emphasis class="po-inline e98 e98" role="bold"><textual class="po-textual">Problem a: </textual></emphasis><textual class="po-textual"> Different encoding in the source file
          (example: iso-8859-1 , UTF-8)</textual></para><para class="po-block e99 e99"><emphasis class="po-inline e100 e100" role="bold"><textual class="po-textual">Action: </textual></emphasis><textual class="po-textual"> The source file is converted to UTF-8
          encoding in java before parsing. datastring.getBytes("UTF-8")</textual></para><para class="po-block e101 e101"><emphasis class="po-inline e102 e102" role="bold"><textual class="po-textual">Problem b: </textual></emphasis><textual class="po-textual"> Errors are thrown due to the presence of
          Character Entity in the source file and not declared.</textual></para><para class="po-block e103 e103"><emphasis class="po-inline e104 e104" role="bold"><textual class="po-textual">Action: </textual></emphasis><textual class="po-textual"> External Entity file is added to the source
          file &lt;DOCTYPE before parsing.</textual></para><para class="po-block e105 e105"><emphasis class="po-inline e106 e106" role="bold"><textual class="po-textual">Problem c: </textual></emphasis><textual class="po-textual"> If the tag is not terminated by the
          matching end-tag or due to the presence of any invalid tags that are not specified in the
          DTD.</textual></para><para class="po-block e107 e107"><textual class="po-textual">
          </textual><emphasis class="po-inline e108 e108" role="bold"><textual class="po-textual">Action: </textual></emphasis><textual class="po-textual">Inform the publisher about the error and request
          them to correct and resend the data.</textual></para><para class="po-block e109 e109"><textual class="po-textual">Figure 3 shows the log file indicating the invalid tags used in the source
          data</textual></para><figure class="po-container e110 e110" xml:id="spie"><mediaobject class="po-container e111 e111"><imageobject class="po-container e112 e112"><imagedata class="po-meta e113 e113" fileref="../../../vol9/graphics/Zhao01/Zhao01-003.png" format="png" width="85%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure><para class="po-block e114 e114"><emphasis class="po-inline e115 e115" role="bold"><textual class="po-textual">Problem d:</textual></emphasis><textual class="po-textual"> The implementation of new DTD is done in
          publisher data without advance notice from publisher.</textual></para><para class="po-block e116 e116"><emphasis class="po-inline e117 e117" role="bold"><textual class="po-textual">Action: </textual></emphasis><textual class="po-textual">The error is logged and the email is sent to the
          publisher requesting for the new DTD. </textual></para></section><section class="po-hcontainer e118 e118"><title class="po-block e119 e119"><textual class="po-textual">2.2 Transforming to NLM xml</textual></title><para class="po-block e120 e120"><textual class="po-textual">After parsing the source file, a well-formatted xml file is ready to be processed by
          the transforming program. The transforming process is based on the crosswalk to convert
          the parsed xml file to NLM xml data structure. After the conversion, the document is
          validated by several criteria which are listed below before adding to MarkLogic
          database:</textual></para><section class="po-hcontainer e121 e121"><title class="po-block e122 e122"><textual class="po-textual">2.2.1. Mandatory fields</textual></title><para class="po-block e123 e123"><textual class="po-textual">ISSN and Publication Date which are used for indexing are mandatory fields for
            loading articles into the database. Missing mandatory fields will cause the article to
            not load into the database and an error message is generated in the log file. </textual></para></section><section class="po-hcontainer e124 e124"><title class="po-block e125 e125"><textual class="po-textual">2.2.2. Missing content</textual></title><para class="po-block e126 e126"><textual class="po-textual">When there is missing content, the team makes their best effort to maximize the
            usage of the data provided by the publisher for the benefits of the end users.</textual></para><para class="po-block e127 e127"><textual class="po-textual">Some of the common issues are:</textual></para><para class="po-block e128 e128"><emphasis class="po-inline e129 e129" role="bold"><textual class="po-textual">Problem a: Missing pdf</textual></emphasis><textual class="po-textual"> - In the loader program, a
            check is made if the pdf file is available in the physical location and the link to the
            pdf file is created in the xml file. If the pdf file is missing, an error message is
            generated in the log file. The article is loaded with metadata only. The error is
            reported in the log file and the QA staff contacts the publisher to request the pdf
            file. The publishers usually send the pdf with metadata again, and the article will be
            replaced with full content.</textual></para><para class="po-block e130 e130"><emphasis class="po-inline e131 e131" role="bold"><textual class="po-textual">Problem b: Missing figures</textual></emphasis><textual class="po-textual"> - If any of the
            figures of a article is missing, the full text article is still loaded to the database
            if the pdf file is available. The &lt;body&gt; element’s attribute is set to display=no
            for this article so the content of the body can be used for searching and indexing, but
            not for displaying. </textual></para><para class="po-block e132 e132"><emphasis class="po-inline e133 e133" role="bold"><textual class="po-textual">Problem c: Not properly tagged in &lt;body&gt;</textual></emphasis><textual class="po-textual"> -
            Another scenario when setting display=no for the &lt;body&gt; element is that when the
            content is not properly tagged, then there would be no full-text display in the
            interface. However, the article is loaded into the database for searching and indexing
            purposes. </textual></para><para class="po-block e134 e134"><textual class="po-textual">Sample Log files:</textual></para><figure class="po-container e135 e135" xml:id="nopdf"><mediaobject class="po-container e136 e136"><imageobject class="po-container e137 e137"><imagedata class="po-meta e138 e138" fileref="../../../vol9/graphics/Zhao01/Zhao01-004.png" format="png" width="85%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure><figure class="po-container e139 e139" xml:id="nopubdate"><mediaobject class="po-container e140 e140"><imageobject class="po-container e141 e141"><imagedata class="po-meta e142 e142" fileref="../../../vol9/graphics/Zhao01/Zhao01-005.png" format="png" width="85%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure></section></section></section><section class="po-hcontainer e143 e143"><title class="po-block e144 e144"><textual class="po-textual">3. Log file checking procedures</textual></title><para class="po-block e145 e145"><textual class="po-textual">The data loading log files are examined daily by an automated script and report any
        error to JIRA and email to the team. </textual></para><para class="po-block e146 e146"><textual class="po-textual">JIRA is used as a tool to track all the problems during data ingest process. QA staff
        reviews the JIRA issues and analyze the problem which then is reported to the publisher or
        assigned to the programmer for loader modification.</textual></para><para class="po-block e147 e147"><textual class="po-textual">
        </textual><figure class="po-container e148 e148" xml:id="figure1"><title class="po-block e149 e149"><textual class="po-textual">Flowchart for Log File Check</textual></title><mediaobject class="po-container e150 e150"><imageobject class="po-container e151 e151"><imagedata class="po-meta e152 e152" fileref="../../../vol9/graphics/Zhao01/Zhao01-006.png" format="png" width="75%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure><textual class="po-textual">
      </textual></para><para class="po-block e153 e153"><textual class="po-textual">An example of the process for a JIRA issue solved shown as 6 steps below:</textual><itemizedlist class="po-table e154 e154"><listitem class="po-container e155 e155"><para class="po-block e156 e156"><textual class="po-textual">Step 1: JIRA issue created daily by the automated java script in case of
            errors.</textual><figure class="po-container e157 e157" xml:id="jira_error"><title class="po-block e158 e158"><textual class="po-textual">JIRA Error Log</textual></title><mediaobject class="po-container e159 e159"><imageobject class="po-container e160 e160"><imagedata class="po-meta e161 e161" fileref="../../../vol9/graphics/Zhao01/Zhao01-007.png" format="png" width="99%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure></para></listitem><listitem class="po-container e162 e162"><para class="po-block e163 e163"><textual class="po-textual">Step 2: The log file reviewed by the QA staff</textual><figure class="po-container e164 e164" xml:id="logfile"><title class="po-block e165 e165"><textual class="po-textual">Log File</textual></title><mediaobject class="po-container e166 e166"><imageobject class="po-container e167 e167"><imagedata class="po-meta e168 e168" fileref="../../../vol9/graphics/Zhao01/Zhao01-008.png" format="png" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure></para></listitem><listitem class="po-container e169 e169"><para class="po-block e170 e170"><textual class="po-textual">Step 3: The source data problem identified </textual><figure class="po-container e171 e171" xml:id="sage_source_file"><title class="po-block e172 e172"><textual class="po-textual">Sage Source File</textual></title><mediaobject class="po-container e173 e173"><imageobject class="po-container e174 e174"><imagedata class="po-meta e175 e175" fileref="../../../vol9/graphics/Zhao01/Zhao01-009.png" format="png"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure><textual class="po-textual">
          </textual></para></listitem><listitem class="po-container e176 e176"><para class="po-block e177 e177"><textual class="po-textual">Step 4: Problem addressed and request sent to the publisher</textual><figure class="po-container e178 e178" xml:id="sage_email"><title class="po-block e179 e179"><textual class="po-textual">Email to the Publisher</textual></title><mediaobject class="po-container e180 e180"><imageobject class="po-container e181 e181"><imagedata class="po-meta e182 e182" fileref="../../../vol9/graphics/Zhao01/Zhao01-010.png" format="png"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure></para></listitem><listitem class="po-container e183 e183"><para class="po-block e184 e184"><textual class="po-textual">Step 5: The corrected data received under new dataset</textual><figure class="po-container e185 e185" xml:id="sage_listfiles"><title class="po-block e186 e186"><textual class="po-textual">New dataset</textual></title><mediaobject class="po-container e187 e187"><imageobject class="po-container e188 e188"><imagedata class="po-meta e189 e189" fileref="../../../vol9/graphics/Zhao01/Zhao01-011.png" format="png"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure></para></listitem><listitem class="po-container e190 e190"><para class="po-block e191 e191"><textual class="po-textual">Step 6: The data loading log file showing no error </textual><figure class="po-container e192 e192" xml:id="Sage_log_file_2"><title class="po-block e193 e193"><textual class="po-textual">Log file</textual></title><mediaobject class="po-container e194 e194"><imageobject class="po-container e195 e195"><imagedata class="po-meta e196 e196" fileref="../../../vol9/graphics/Zhao01/Zhao01-012.png" format="png"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject></mediaobject></figure></para></listitem></itemizedlist></para><para class="po-block e197 e197"><textual class="po-textual">To ensure the publishers continue sending the current updated content, a script is
        scheduled to run monthly to check the latest dataset loaded from each publisher. If any
        unusual gap is found, the QA team investigates the cause of any missing updates.</textual></para><para class="po-block e198 e198"><textual class="po-textual">Besides those generated automatically by the system, error reports also are sent to SP
        QA staff by the librarians, faculty and students who rely on the e-journals repository for
        research, teaching and learning. A form has been posted on SP website for the end user to
        send the report and track the problem solving process.</textual></para></section></section><section class="po-hcontainer e199 e199"><title class="po-block e200 e200"><textual class="po-textual">Conclusion</textual></title><para class="po-block e201 e201"><textual class="po-textual">Scholars Portal E-journals repository is ever growing with approximately 75,000 records
      added daily in 2012. The technology offers the ability to monitor and report the errors
      automatically; however, the problem solving highly rely on the human interface—the
      Scholars Portal QA and technical staff and the publishers’ content supply support team.
      Scholars Portal’s policy is not to correct the publisher’s source data but to report the
      problem back to the publisher when it cannot be handled by SP loader program. Some
      publishers provide prompt response which helps SP team to have the data available to the user
      community without any delays. To divide the staff time wisely to handle the fast-growing
      daily new content and to fix the problem is the challenge to SP team.</textual></para></section><section class="po-hcontainer e202 e202"><title class="po-block e203 e203"><textual class="po-textual">Acknowledgements</textual></title><para class="po-block e204 e204"><textual class="po-textual">The workflow charts are created by Aurianne Steinman.</textual></para></section><bibliography class="po-hcontainer e205 e205"><title class="po-block e206 e206"><textual class="po-textual">Bibliography</textual></title><bibliomixed class="po-block e207 e207" xml:id="ref1" xreflabel="OCUL 2012"><textual class="po-textual">OCUL. Strategic Plan. [online] [cited 19 April
      2012]
      </textual><link class="po-inline e208 e208" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.ocul.on.ca/sites/default/files/OCUL_Strategic_Plan.pdf</textual></link></bibliomixed><bibliomixed class="po-block e209 e209" xml:id="ref2" xreflabel="NLM 2012"><textual class="po-textual">NLM. Archiving and Interchange Tag Set Version
      3.0. [online]. [cited 19 April 2012]
        </textual><link class="po-inline e210 e210" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://dtd.nlm.nih.gov/archiving/tag-library/3.0/index.html</textual></link></bibliomixed><bibliomixed class="po-block e211 e211" xml:id="ref3" xreflabel="Morrissey 2010"><textual class="po-textual">Morrissey, Sheila, John Meyer, Sushil
      Bhattarai, Sachin Kurdikar, Jie Ling, Matthew Stoeffler and Umadevi Thanneeru. </textual><quote class="po-inline e212 e212"><textual class="po-textual">Portico:
        A Case Study in the Use of XML for the Long-Term Preservation of Digital Artifacts.</textual></quote><textual class="po-textual">
      Presented at International Symposium on XML for the Long Haul: Issues in the Long-term
      Preservation of XML, Montréal, Canada, August 2, 2010. In </textual><emphasis class="po-inline e213 e213" role="ital"><textual class="po-textual">Proceedings of
        the International Symposium on XML for the Long Haul: Issues in the Long-term Preservation
        of XML.</textual></emphasis><textual class="po-textual"> Balisage Series on Markup Technologies, vol. 6 (2010).
      doi:</textual><biblioid class="po-atom e214 doi e214"><textual class="po-textual">10.4242/BalisageVol6.Morrissey01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e215 e215" xml:id="ref4" xreflabel="Scholars Portal 2012"><textual class="po-textual">Scholars Portal. Quality Control
      Specifications. [online]. [cited 19 April 2012].
        </textual><link class="po-inline e216 e216" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://spotdocs.scholarsportal.info/display/OAIS/Quality+Control+Specifications</textual></link></bibliomixed><bibliomixed class="po-block e217 e217" xml:id="ref5" xreflabel="OCUL"><textual class="po-textual">OCUL. Local Loading License. [online]. [cited 19
      April 2012] . </textual><link class="po-inline e218 e218" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.ocul.on.ca/node/114</textual></link></bibliomixed><bibliomixed class="po-block e219 e219" xml:id="ref6" xreflabel="Usdin"><textual class="po-textual">Usdin, Tommie, Piez Wendell . Separating Mapping
      from Coding in Transformation Tasks. Presented at: XML 2007; 2007 Dec 3-5; Boston,
      MA.</textual></bibliomixed><bibliomixed class="po-block e220 e220" xml:id="ref7" xreflabel="Zhao 2010"><textual class="po-textual">Zhao, W, Arvind, V. Aggregating E-Journals:
      Adopting the Journal Archiving and Interchange Tag Set to Build a Shared E-Journal Archive for
      Ontario. In: </textual><emphasis class="po-inline e221 e221" role="ital"><textual class="po-textual">Proceedings of the Journal Article Tag Suite Conference
        2011</textual></emphasis><textual class="po-textual"> [Internet]. Bethesda (MD): National Center for Biotechnology Information
      (US); 2011</textual></bibliomixed></bibliography></article></classedDocument>