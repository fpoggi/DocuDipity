<?xml version="1.0" encoding="UTF-8" standalone="no"?><classedDocument><article xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" class="po-hcontainer e0 e0" version="5.0-subset Balisage-1.2"><title class="po-block e1 e1"><textual class="po-textual">You Pull, I’ll Push: on the Polarity of Pipelines</textual></title><info class="po-record e2 e2"><confgroup class="po-record e3 e3"><conftitle class="po-field e4 e4"><textual class="po-textual">Balisage: The Markup Conference 2009</textual></conftitle><confdates class="po-field e5 e5"><textual class="po-textual">August 11 - 14, 2009</textual></confdates></confgroup><abstract class="po-container e6 e6"><para class="po-block e7 e7"><textual class="po-textual">Pipelines provide an excellent way of structuring XML applications, simplifying complex
processing tasks and enabling the reuse of generic components, using a variety of technologies.
Efficient pipelines often pass data from one stage to the next as a sequence of 
  </textual><emphasis class="po-inline e8 e8" role="ital"><textual class="po-textual">events</textual></emphasis><textual class="po-textual">, representing the structure of the tree as a by notifying
</textual><code class="po-atom e9 e9"><textual class="po-textual">startElement</textual></code><textual class="po-textual">, </textual><code class="po-atom e10 e10"><textual class="po-textual">endElement</textual></code><textual class="po-textual"> and similar transitions.</textual></para><para class="po-block e11 e11"><textual class="po-textual">The control flow in a pipeline can either run with the data flow (push polarity) or against
 the flow (pull polarity). Performance problems occur when components with different polarity need
 to be integrated into the same pipeline: traditionally this problem is handled either by buffering
 the data in memory (leading to scalability problems as well as loss of latency), or by using
 multiple threads, which introduces coordination overheads.</textual></para><para class="po-block e12 e12"><textual class="po-textual">This paper looks at a different way of managing polarity conflicts, by applying the concepts
 of program inversion developed during the days of batch magnetic tape data processing. It specifically
 examines how this concept can be applied to the compilation of XSLT stylesheets, both single and multi-phase.</textual></para></abstract><author class="po-record e13 e13"><personname class="po-record e14 e14"><firstname class="po-field e15 e15"><textual class="po-textual">Michael</textual></firstname><surname class="po-field e16 e16"><textual class="po-textual">Kay</textual></surname></personname><personblurb class="po-container e17 e17"><para class="po-block e18 e18"><textual class="po-textual">Michael Kay is the editor of the W3C XSLT specification, and is a member of the XQuery
and XML Schema Working Groups. He is the developer of the Saxon XSLT, XQuery, and XML Schema processor.
He is the author of </textual><quote class="po-inline e19 e19"><textual class="po-textual">XSLT Programmer's Reference</textual></quote><textual class="po-textual"> (now in its fourth edition) and a contributor
to many other books.</textual></para><para class="po-block e20 e20"><textual class="po-textual">He is a member of the Advisory Board for Balisage 2009, and Chair of the associated Symposium
on Processing XML Efficiently.</textual></para></personblurb><affiliation class="po-record e21 e21"><jobtitle class="po-field e22 e22"><textual class="po-textual">Director</textual></jobtitle><orgname class="po-block e23 e23"><textual class="po-textual">Saxonica Limited</textual></orgname></affiliation><email class="po-field e24 e24"><textual class="po-textual">mike@saxonica.com</textual></email></author><legalnotice class="po-container e25 e25"><para class="po-block e26 e26"><textual class="po-textual">Copyright © 2009 Michael Kay.</textual></para></legalnotice><keywordset class="po-table e27 e27" role="author"><keyword class="po-field e28 e28"><textual class="po-textual">XML</textual></keyword><keyword class="po-field e29 e29"><textual class="po-textual">Pipelines</textual></keyword><keyword class="po-field e30 e30"><textual class="po-textual">Push</textual></keyword><keyword class="po-field e31 e31"><textual class="po-textual">Pull</textual></keyword><keyword class="po-field e32 e32"><textual class="po-textual">Jackson Structured Programming</textual></keyword><keyword class="po-field e33 e33"><textual class="po-textual">Program Inversion</textual></keyword></keywordset></info><section class="po-hcontainer e34 e34"><title class="po-block e35 e35"><textual class="po-textual">Pipelines: an Introduction</textual></title><para class="po-block e36 e36"><textual class="po-textual">It has been known for a long time [see for example 
      </textual><xref class="po-milestone e37 e37" linkend="Thompson2001"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">, </textual><xref class="po-milestone e38 e38" linkend="McGrath2002"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">, </textual><xref class="po-milestone e39 e39" linkend="McGrath2004"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]
      that processing of XML documents can conveniently be
organized in the form of a pipeline. In such a pipeline, the work is divided into a sequence of
steps, each of which takes an XML document as input, and produces another XML document as output.
Constructing an application in the form of a pipeline has many advantages, the main ones being
(a) that the code of each step in the pipeline is kept very simple; (b) that it is very
easy to assemble an application from a set of components, thus maximizing the potential for
component reuse, and (c) there is no requirement that each step in a pipeline should use
the same technology; it's easy to mix XSLT, XQuery, Java and so on in different stages.</textual></para><para class="po-block e40 e40"><textual class="po-textual">A number of products are available to assist with the development and management
of pipeline-based applications, examples being Orbeon [</textual><xref class="po-milestone e41 e41" linkend="orbeon"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">] and 
  Apache Cocoon [</textual><xref class="po-milestone e42 e42" linkend="cocoon"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]. More recently W3C
has developed a standard language, XProc [</textual><xref class="po-milestone e43 e43" linkend="xproc"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">], for the definition of pipelines.</textual></para><para class="po-block e44 e44"><textual class="po-textual">One of the benefits of structuring an application using pipelines is that different technologies
can be used to implement each step within a pipeline. This maximizes component reusability, since
the ability to make use of an existing component is not dependent on the choice of technology used
to implement the component. This only works, of course, if there are some kind of standards for plugging
heterogeneous components together.</textual></para><para class="po-block e45 e45"><textual class="po-textual">Ideally, components will be able to pass information to each other without the overhead of
serializing the data as lexical XML and then reparsing it. Equally, they will be able to pass information
without buffering the entire document in memory. This suggests that in an optimal interface, the
data will be passed between components as a stream of events (for example, </textual><code class="po-atom e46 e46"><textual class="po-textual">startElement</textual></code><textual class="po-textual">,
</textual><code class="po-atom e47 e47"><textual class="po-textual">endElement</textual></code><textual class="po-textual">, etc).</textual></para><para class="po-block e48 e48"><textual class="po-textual">The question then arises, how should the components of a pipeline be written? One can envisage
three styles:</textual></para><itemizedlist class="po-table e49 e49"><listitem class="po-container e50 e50"><para class="po-block e51 e51"><textual class="po-textual">Each component is written as a complete program that reads XML from its input
and writes XML to its output. We will call this a main-loop component, because in general it contains
a program loop containing read and write instructions.</textual></para></listitem><listitem class="po-container e52 e52"><para class="po-block e53 e53"><textual class="po-textual">A component may be written to be called repeatedly by the component that supplies its 
input, once for each item of input. This is an event-driven style of programming, and we will call
this a push component.</textual></para></listitem><listitem class="po-container e54 e54"><para class="po-block e55 e55"><textual class="po-textual">A component may be written to be called repeatedly by the component that consumes 
its output. That is, the component is called whenever some more data is required. We will call
this a pull component.</textual></para></listitem></itemizedlist><para class="po-block e56 e56"><textual class="po-textual">These three styles of component are illustrated in Figure 1.</textual></para><figure class="po-container e57 e57" xml:id="fig1"><mediaobject class="po-container e58 e58"><imageobject class="po-container e59 e59"><imagedata class="po-meta e60 e60" fileref="../../../vol3/graphics/Kay01/Kay01-001.png" format="png" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e61 e61"><para class="po-block e62 e62"><textual class="po-textual">Fig 1. Three styles of pipeline component. The arrows indicate the direction of control flow;
          the direction of data flow is in all cases from left to right.</textual></para></caption></mediaobject></figure><para class="po-block e63 e63"><textual class="po-textual">A push filter is a component of a pipeline that is invoked repeatedly by its upstream neighbour
(the supplier of its input), and that in turn makes multiple calls to its downstream neighbour
(the consumer of its output). Similarly, a pull filter is a component that is invoked repeatedly by
its downstream neighbour (the consumer of its output), and that in turn makes repeated requests for data
from its upstream neighbour (the supplier of its input).</textual></para><para class="po-block e64 e64"><textual class="po-textual">Each of these styles has advantages and disadvantages, from the points of view of the developer
of the component and the user of the component. When it comes
to constructing a pipeline, however, we probably have to face the fact that we will sooner or later
want to integrate components that have been written in different styles: main-loop components, 
push components, and pull components; one aim of this paper is to address the integration challenges 
this poses.</textual></para><section class="po-hcontainer e65 e65"><title class="po-block e66 e66"><textual class="po-textual">Pipelines within a Query or Stylesheet</textual></title><para class="po-block e67 e67"><textual class="po-textual">The concepts described in this paper can be applied at various levels of the system. One can
consider a pipeline in which each component is a complete XSLT or XQuery transformation. Or
one can consider a pipeline of operations contained within a single stylesheet or query: this often
manifests itself as a multi-phase transformation whose logic looks something like this:</textual></para><programlisting class="po-block e68 e68" xml:space="preserve"><textual class="po-textual">
&lt;xsl:variable name="x"&gt;
  &lt;temp&gt;
    &lt;xsl:apply-templates select="/" mode="phase-1"/&gt;
  &lt;/temp&gt;
&lt;/xsl:variable&gt;
&lt;xsl:variable name="y"&gt;
  &lt;tump&gt;
    &lt;xsl:apply-templates select="$x" mode="phase-2"/&gt;
  &lt;/tump&gt;
&lt;/xsl:variable&gt;
&lt;xsl:template name="entry"&gt;
  &lt;xsl:apply-templates select="$y" mode="phase-3"/&gt;
&lt;/xsl:template&gt;
</textual></programlisting><para class="po-block e69 e69"><textual class="po-textual">We can think of this as a sequence of three “push” components if we adopt the XSLT 1.0 paradigm
which describes literal result elements, </textual><code class="po-atom e70 e70"><textual class="po-textual">xsl:apply-templates</textual></code><textual class="po-textual">, and other instructions that
create new nodes as “writing to the result tree”. The terminology has changed in XSLT 2.0; such
instructions are now described as constructing a node and returning it to its caller. That is, the language
has changed between the two releases from talking about a push model to talking about a pull model. 
By and large this is only a matter of presentation. But the 1.0
model is probably closer to the way many implementations are likely to work internally.</textual></para><para class="po-block e71 e71"><textual class="po-textual">An internal pipeline within a single XQuery has a more pull-like feel to it. The equivalent might
be:</textual></para><programlisting class="po-block e72 e72" xml:space="preserve"><textual class="po-textual">
declare function f:phase-1($d as document-node()) {
  &lt;temp&gt;{f:process($d)}&lt;/temp&gt;
}

declare function f:phase-2($x as element(temp)) {
  &lt;tump&gt;{f:manipulate($x)}&lt;/tump&gt;
} 

declare function f:phase-3($y as element(tump)) {
  &lt;html&gt;{f:render($y)}&lt;/html&gt;
} 

f:phase-3(f:phase-2(f:phase-1(/)))
</textual></programlisting><para class="po-block e73 e73"><textual class="po-textual">The “pull” nature of this pipeline arises from the use of function calls as the composition
mechanism; the control logic starts from the last stage in the pipeline, and each stage invokes
its predecessor by means of a function call.</textual></para><para class="po-block e74 e74"><textual class="po-textual">However, because XSLT and XQuery are both declarative languages, this user view (or specification view)
of how the languages work might not always match the internal reality. The underlying XSLT engine
might compile “pull” code from an </textual><code class="po-atom e75 e75"><textual class="po-textual">xsl:apply-templates</textual></code><textual class="po-textual"> instruction, or might compile
“push” code from a function call. This flexibility, which we shall examine in more detail later,
turns out to be one of the major benefits of writing in a declarative language.</textual></para></section><section class="po-hcontainer e76 e76"><title class="po-block e77 e77"><textual class="po-textual">Pipelines within an XSLT or XQuery processor</textual></title><para class="po-block e78 e78"><textual class="po-textual">We can also look at pipelines as implemented internally within an XSLT or XQuery processor,
or within other components such as XML parsers, validators, and serializers. The serializer is the component
responsible for converting a tree representation of an XML document into lexical XML markup; it is controlled
by a number of user-settable properties as described in [</textual><xref class="po-milestone e79 e79" linkend="serialization"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]. The serializer in Saxon, for
example [see </textual><xref class="po-milestone e80 e80" linkend="saxon"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">] and [</textual><xref class="po-milestone e81 e81" linkend="Kay2001"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">] is implemented internally as a 
  pipeline containing one or more of the following components:</textual></para><itemizedlist class="po-table e82 e82"><listitem class="po-container e83 e83"><para class="po-block e84 e84"><textual class="po-textual">An </textual><code class="po-atom e85 e85"><textual class="po-textual">UncommittedEmitter</textual></code><textual class="po-textual">, which decides dynamically whether the output
method is XML, XHTML, or HTML, and constructs the rest of the pipeline accordingly</textual></para></listitem><listitem class="po-container e86 e86"><para class="po-block e87 e87"><textual class="po-textual">A </textual><code class="po-atom e88 e88"><textual class="po-textual">CharacterMapExpander</textual></code><textual class="po-textual">, which handles any </textual><code class="po-atom e89 e89"><textual class="po-textual">xsl:character-map</textual></code><textual class="po-textual">
declarations in the stylesheet</textual></para></listitem><listitem class="po-container e90 e90"><para class="po-block e91 e91"><textual class="po-textual">A </textual><code class="po-atom e92 e92"><textual class="po-textual">UnicodeNormalizer</textual></code><textual class="po-textual">, which converts character sequences into
composed or decomposed Unicode Normal Form</textual></para></listitem><listitem class="po-container e93 e93"><para class="po-block e94 e94"><textual class="po-textual">A </textual><code class="po-atom e95 e95"><textual class="po-textual">URIEscaper</textual></code><textual class="po-textual"> which performs percent-encoding of HTML URI-valued
attributes such as </textual><code class="po-atom e96 e96"><textual class="po-textual">href</textual></code></para></listitem><listitem class="po-container e97 e97"><para class="po-block e98 e98"><textual class="po-textual">A </textual><code class="po-atom e99 e99"><textual class="po-textual">MetaTagAdjuster</textual></code><textual class="po-textual"> which adds, deletes, or modifies </textual><code class="po-atom e100 e100"><textual class="po-textual">&lt;meta&gt;</textual></code><textual class="po-textual">
elements appearing within the </textual><code class="po-atom e101 e101"><textual class="po-textual">&lt;head&gt;</textual></code><textual class="po-textual"> element of an HTML or XHTML document</textual></para></listitem><listitem class="po-container e102 e102"><para class="po-block e103 e103"><textual class="po-textual">A </textual><code class="po-atom e104 e104"><textual class="po-textual">CDATAFilter</textual></code><textual class="po-textual">, which wraps selected text nodes in CDATA sections</textual></para></listitem><listitem class="po-container e105 e105"><para class="po-block e106 e106"><textual class="po-textual">An </textual><code class="po-atom e107 e107"><textual class="po-textual">XML10ContentChecker</textual></code><textual class="po-textual"> which checks that the output
contains only characters allowed by XML 1.0 (used only in the case where XML 1.1 input is permitted
but XML 1.0 output is required)</textual></para></listitem><listitem class="po-container e108 e108"><para class="po-block e109 e109"><textual class="po-textual">An </textual><code class="po-atom e110 e110"><textual class="po-textual">Indenter</textual></code><textual class="po-textual">, customized to XML, HTML, or XHTML, which adds newlines
and indentation</textual></para></listitem><listitem class="po-container e111 e111"><para class="po-block e112 e112"><textual class="po-textual">An </textual><code class="po-atom e113 e113"><textual class="po-textual">Emitter</textual></code><textual class="po-textual">, customized to XML, HTML, XHTML, or text, which acts as the
final stage of the pipeline, emitting a sequence of characters.</textual></para></listitem></itemizedlist><para class="po-block e114 e114"><textual class="po-textual">Note that for a given task, the actual serialization pipeline will often contain very few
of these components: if the </textual><code class="po-atom e115 e115"><textual class="po-textual">cdata-section-elements</textual></code><textual class="po-textual"> attribute of the </textual><code class="po-atom e116 e116"><textual class="po-textual">xsl:output</textual></code><textual class="po-textual">
declaration is absent, for example, there will be no </textual><code class="po-atom e117 e117"><textual class="po-textual">CDATAFilter</textual></code><textual class="po-textual"> on the pipeline.
Moreover, the pipeline may contain components not in the above list: Saxon provides an interface
allowing the serialization pipeline to be customized with additional user-defined components.</textual></para><para class="po-block e118 e118"><textual class="po-textual">Does this design perform well? In some respects, it is not optimized; for example it would be
  possible to implement character map expansion and Unicode normalization in a single “for each character” loop
with fewer instructions than when they are done in separate loops. However, for most workloads this
is more than compensated by the fact that there are no “per event” or “per character” tests for
optional operations that are not actually needed. Much of the logic is carried out at pipeline 
configuration time; if the </textual><code class="po-atom e119 e119"><textual class="po-textual">CDATAFilter</textual></code><textual class="po-textual"> is not included in the pipeline, then there
  will be no once-per-node test to say “should this text node be formatted as a CDATA section?” So
the net effect is that the user pays no price for facilities that are not used.</textual></para><para class="po-block e120 e120"><textual class="po-textual">In Saxon, the serializer is implemented as a push pipeline: each component uses a SAX-like
interface to pass XML events to the next stage in the pipeline. This seems a natural design given
that the serializer is writing output, and is thus providing a “write” service to its ultimate client
(which might be the XSLT transformation engine, or a user application). </textual></para><para class="po-block e121 e121"><textual class="po-textual">Another internal pipeline within Saxon is the schema validation pipeline, used to validate
  instance documents against the rules defined in an XSD Schema [</textual><xref class="po-milestone e122 e122" linkend="xsd"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]. This again consists
of a number of components, which in this case are assembled even more dynamically; every time a
start tag is encountered, a new component is added to the pipeline to validate the contents of that
element, and this component is then removed from the pipeline when the matching end tag is found.
Also, if an element defines one or more identity constraints (</textual><code class="po-atom e123 e123"><textual class="po-textual">xs:unique</textual></code><textual class="po-textual">, </textual><code class="po-atom e124 e124"><textual class="po-textual">xs:key</textual></code><textual class="po-textual">,
  and </textual><code class="po-atom e125 e125"><textual class="po-textual">xs:keyref</textual></code><textual class="po-textual">), then a “watch” component is added to the pipeline to watch for elements
that match the select expression of the constraint; when such an element is encountered, a further
“watch” is added to detect and act on elements and attributes that match one of the field expressions
of the constraint. This illustrates one of the benefits of using a push pipeline: it is very easy
for such a pipeline to branch, so that one component pushes a single event to many listeners. In this
case the multiple listeners represent, for example, the multiple fields that can appear in a single
identity constraint, or the multiple identity constraints that can exist for a single element declaration
in a schema. Such branching is not possible in a pull pipeline, for obvious reasons.</textual></para></section></section><section class="po-hcontainer e126 e126"><title class="po-block e127 e127"><textual class="po-textual">Push vs. pull parsing</textual></title><para class="po-block e128 e128"><textual class="po-textual">For some people, the terms “push” and “pull” are associated primarily with styles of XML parsing.
    In particular, with a push parser API like SAX, the main control loop is in the parser, and the user
    application is invoked to notify significant events such as start and end tags. With a pull parser API 
    like StAX, the main control loop is in the user application, which repeatedly requests the next event 
    by calling the parser.
  </textual></para><para class="po-block e129 e129"><textual class="po-textual">This usage of the terms “push” and “pull” is simply a special case of the way we use the terms in this paper, for
  the case of a pipeline that has two stages only, the XML parser and the user application.</textual></para><para class="po-block e130 e130"><textual class="po-textual">It is probably true that both the SAX and StAX APIs have been designed rather too closely for this
  particular use case (the interface between parsers and user-written applications) rather than for the
  more general requirement of communication between arbitrary steps in a pipeline. In this paper, however,
  we are concerned with general principles and not with the specific design of these two APIs. (StAX, in fact,
  offers two different pull APIs with different trade-offs between functionality and speed, and indeed, it also
  bundles in two complementary push APIs as well.)</textual></para><para class="po-block e131 e131"><textual class="po-textual">At the parsing level, the debate between advocates of push and pull parsing APIs hinges primarily on usability, not performance.
  There are some performance differences, but they are fairly marginal. For example, with a pull API it is easier
  for the consumer of the data to skip parts of the document (for example, when a start tag has been notified
  it can skip to the matching end tag), which has the potential to reduce the cost of processing the unwanted
  data. Many of the performance issues relate to how many times character strings are moved from one buffer
  to another, and such factors depend on the fine detail of the API design rather than on whether it is a push
  or pull interface.</textual></para><para class="po-block e132 e132"><textual class="po-textual">As regards usability, pull parsing does appear to be more attractive to many users. I believe this
  is primarily because programmers like to be in control: writing the code that owns the main control loop is
  easier than writing event-driven code. It means, for example, that much of the current state is maintained
  on the stack provided automatically by the programming language, rather than needing to be maintained manually
  on a stack implemented by the user application.</textual></para><para class="po-block e133 e133"><textual class="po-textual">Unfortunately, in a multi-stage pipeline this advantage tends to disappear. Typically only one 
  component in the pipeline can own the main control loop: the others will either be push filters or pull filters.  
  </textual></para><para class="po-block e134 e134"><textual class="po-textual">A difference between pull and push parsing becomes noticeable when the correspondence
      between input and output events is not one-to-one. 
      A push filter can easily generate zero, one, or more output events in response
      to each input event. The same effect can be achieved in a pull filter, but it requires more intricate management
      of state information between calls. For this reason, my experience is that while a pull parser API is attractive
    when the application can then be written as a single control loop, writing a pipeline consisting entirely of
    pull filters is trickier than writing an equivalent push pipeline.</textual></para></section><section class="po-hcontainer e135 e135"><title class="po-block e136 e136"><textual class="po-textual">Branching and Merging</textual></title><para class="po-block e137 e137"><textual class="po-textual">A significant difference between pull and push pipelines is this: a push component can readily 
    send its output to more than one destination, whereas a pull component can readily read data from more than
  one source. This is illustrated in Figures 2 and 3. 
  By its nature, a push pipeline cannot handle multiple streamed inputs, nor can a pull pipeline
  handle multiple streamed outputs.</textual></para><figure class="po-container e138 e138" xml:id="fig2"><mediaobject class="po-container e139 e139"><imageobject class="po-container e140 e140"><imagedata class="po-meta e141 e141" fileref="../../../vol3/graphics/Kay01/Kay01-002.png" format="png" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e142 e142"><para class="po-block e143 e143"><textual class="po-textual">Fig 2. Branching in a push pipeline. A component can write to several destinations.</textual></para></caption></mediaobject></figure><figure class="po-container e144 e144" xml:id="fig3"><mediaobject class="po-container e145 e145"><imageobject class="po-container e146 e146"><imagedata class="po-meta e147 e147" fileref="../../../vol3/graphics/Kay01/Kay01-003.png" format="png" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e148 e148"><para class="po-block e149 e149"><textual class="po-textual">Fig 3. Merging in a pull pipeline. A component can read from several sources.</textual></para></caption></mediaobject></figure><para class="po-block e150 e150"><textual class="po-textual">As already mentioned, a situation where branching is useful is in evaluating uniqueness constraints
  during schema validation. At any given point during a streamed validation of an instance document, any
  number of uniqueness constraints can be active. These might have the same scope (employee number and social
  security number must both be unique over all employees) or they might have different scope (promotion date
  must be unique within an employee history). In Saxon's schema validator, every time a new uniqueness constraint
  comes into scope, a uniqueness monitor for that constraint is activated; all parsing events are distributed
  to all active uniqueness monitors. This design is only possible with a push pipeline.</textual></para><para class="po-block e151 e151"><textual class="po-textual">A situation where merging might be useful is in implementing the XPath 2.0 </textual><code class="po-atom e152 e152"><textual class="po-textual">deep-equal()</textual></code><textual class="po-textual">
  function. One can envisage implementing this by means of a streaming pass over both inputs (especially, say, in the
  case where both operands are calls to the </textual><code class="po-atom e153 e153"><textual class="po-textual">doc()</textual></code><textual class="po-textual"> function, the intent being to compare two 
  complete XML documents).
  Any significant difference between the two event streams would then cause the function to return false. This
  is only possible with a pull pipeline. Because Saxon's architecture is predominantly push-based, it does not
  offer a streaming implementation of the </textual><code class="po-atom e154 e154"><textual class="po-textual">deep-equal()</textual></code><textual class="po-textual"> function — instead it requires both operands to
  exist as trees in memory.</textual></para></section><section class="po-hcontainer e155 e155"><title class="po-block e156 e156"><textual class="po-textual">Pipeline Granularity</textual></title><para class="po-block e157 e157"><textual class="po-textual">In the serialization and validation pipelines discussed above, the calls from
  one component to the next are at the level of an “event”. This is similar to a SAX event (start element,
end element, text node, comment node) and so on, except that in Saxon, the internal push interface treats
each attribute as a separate event notified after the start tag; namespaces are also notified as events,
representing a namespace declaration or undeclaration. A pull pipeline can also operate at the same
granularity: in the StAX </textual><code class="po-atom e158 e158"><textual class="po-textual">XMLEventReader</textual></code><textual class="po-textual"> interface, a call on </textual><code class="po-atom e159 e159"><textual class="po-textual">nextEvent()</textual></code><textual class="po-textual">
returns an </textual><code class="po-atom e160 e160"><textual class="po-textual">XMLEvent</textual></code><textual class="po-textual"> object, which again represents a parsing event such as StartElement,
EndElement, Characters, or Comment. As with SAX, the attributes are delivered as part of the
StartElement event.</textual></para><para class="po-block e161 e161"><textual class="po-textual">Saxon's XPath engine, by contrast, makes extensive use of pipelines in which the unit of
data transfer is not a parsing event, but an XPath item (that is, a node or atomic value).
Many XPath operations, especially in XPath 2.0, take sequences of items as
their input and deliver sequences of items as their result. An obvious example is a filter
expression </textual><code class="po-atom e162 e162"><textual class="po-textual">SEQ[PRED]</textual></code><textual class="po-textual">, where the output sequence is that subset of the input items that satisfy some
predicate. This kind of list processing is well established in functional programming languages,
and to deliver acceptable performance it is always implemented using pipelines, to avoid
allocating memory to intermediate results. Pipelining also benefits execution through “early exit”:
an operator only needs to read as much of its input as is needed to deliver a result. 
Typically each expression in the expression tree is
represented at run-time by an iterator which delivers the results an item at a time in response to
a call (such as </textual><code class="po-atom e163 e163"><textual class="po-textual">next()</textual></code><textual class="po-textual">) from the consumer of the data; the implementation of this iterator
  in turn makes calls on </textual><code class="po-atom e164 e164"><textual class="po-textual">next()</textual></code><textual class="po-textual"> to get data from the iterators representing its subexpressions.</textual></para><para class="po-block e165 e165"><textual class="po-textual">A pull pipeline works well here because in general,
an XPath expression takes input sequences from several subexpressions but delivers a single sequence
as its result. For example, the union operator (assuming its inputs are do not need to be sorted into
 document order, which is usually the case) can be implemented by an iterator that switches between reading from
 its two input streams, never looking ahead more than one item for either.</textual></para><para class="po-block e166 e166"><textual class="po-textual">Push processing can also be useful at the item level, however. An example is a recursive function
that operates over a sequence:</textual></para><programlisting class="po-block e167 e167" xml:space="preserve"><textual class="po-textual">
&lt;xsl:function name="f:compute-running-total" as="element(transaction-with-balance)*"&gt;
  &lt;xsl:param name="input" as="element(transaction)*"/&gt;
  &lt;xsl:param name="current-balance" as="xs:decimal"/&gt;
  &lt;xsl:if test="exists($input)"&gt;
    &lt;transaction-with-balance amount="{$input[1]/@amount}" balance="{$current-balance + $amount}"/&gt;
    &lt;xsl:sequence select="f:compute-running-total(remove($input, 1), $current-balance + $amount}"/&gt;
  &lt;/xsl:if&gt;
&lt;/xsl:function&gt;
</textual></programlisting><para class="po-block e168 e168"><textual class="po-textual">A push implementation of this function will typically write each computed element to the output
destination as soon as it is constructed. A pull implementation, unless optimized, is likely to construct successive
sequences of length 1, 2, 3,,, n, with a great deal of copying of intermediate results. Furthermore, a push
implementation can benefit more easily from tail call optimization, whereby on a recursive call the stackframe
of the calling function is reused for the called function, avoiding stack overflow when processing a lengthy
input sequence.</textual></para><para class="po-block e169 e169"><textual class="po-textual">Saxon is capable of evaluating this function in either push or pull polarity. As a general rule in Saxon,
tree construction operations (such as </textual><code class="po-atom e170 e170"><textual class="po-textual">xsl:element</textual></code><textual class="po-textual">) work in push polarity; XPath operations that navigate through
an input document work in pull polarity; and flow of control constructs such as function calls or conditional expressions
can work in either direction, generally choosing the polarity of their parent instruction by preference.</textual></para><para class="po-block e171 e171"><textual class="po-textual">As well as pipelines that operate at the event level or the item level, XQuery in particular can take
  advantage of pipelines in which the unit of data is a tuple. This underpins the semantics of XQuery FLWOR
  expressions. Currently in Saxon there is only one instance of a pipeline involving tuples, which is needed
  to support certain unusual cases of the </textual><code class="po-atom e172 e172"><textual class="po-textual">order by</textual></code><textual class="po-textual"> clause in a FLWOR expression. In future, however,
  tuples will need to be implemented more deeply in the infrastructure as they are essential to the support
  of new facilities in XQuery 1.1 such as grouping and windowing.</textual></para><section class="po-hcontainer e173 e173"><title class="po-block e174 e174"><textual class="po-textual">Hybrid Granularity</textual></title><para class="po-block e175 e175"><textual class="po-textual">The Saxon push interface allows both parsing events and complete items to be sent down the pipeline.
This arises naturally from an XSLT instruction such as:</textual></para><programlisting class="po-block e176 e176" xml:space="preserve"><textual class="po-textual">
&lt;xsl:element name="x"&gt;
  &lt;xsl:attribute name="a" select="1"/&gt;
  &lt;xsl:sequence select="doc('abc.xml')"/&gt;
&lt;/xsl:element&gt;
</textual></programlisting><para class="po-block e177 e177"><textual class="po-textual">The values passed down the pipeline by this instruction are a start-element event, an attribute event,
  a document node, and an end-element event. This is a hybrid sequence containing both “composed” nodes (the
  document node), and “decomposed” events representing nodes (the start and end element events); the attribute
node fits into both categories.</textual></para><para class="po-block e178 e178"><textual class="po-textual">Saxon provides two pipeline filters called </textual><code class="po-atom e179 e179"><textual class="po-textual">compose</textual></code><textual class="po-textual"> and </textual><code class="po-atom e180 e180"><textual class="po-textual">decompose</textual></code><textual class="po-textual">. When added
  to a push pipeline, the </textual><code class="po-atom e181 e181"><textual class="po-textual">compose</textual></code><textual class="po-textual"> filter acts as a tree builder: a sequence of start-element and 
  end-element events is converted into a tree, which is then passed on down the pipeline as a single composed node.
  The </textual><code class="po-atom e182 e182"><textual class="po-textual">decompose</textual></code><textual class="po-textual"> filter does the reverse: if it receives a document or element node, it decomposes this
  into a sequence of parse events. The decision whether to compose a sequence or decompose it is delayed until
it is known what the recipient of the data intends to do with it: if the eventual recipient is a serializer, then
decomposed form is preferred, while if it is a tree builder, on an operation that requires a “real tree” as input,
then composed form is needed.</textual></para></section></section><section class="po-hcontainer e183 e183"><title class="po-block e184 e184"><textual class="po-textual">When push meets pull</textual></title><para class="po-block e185 e185"><emphasis class="po-inline e186 e186" role="ital"><textual class="po-textual">Or: When pull comes to shove...</textual></emphasis></para><para class="po-block e187 e187"><textual class="po-textual">The preceding discussion establishes that there are places where it makes more sense to do pull
  processing, and places where push is more sensible. But we have also seen that changing polarity
  can cause a noticeable performance cost. So what happens when a push pipeline meets
  a pull pipeline?</textual></para><para class="po-block e188 e188"><textual class="po-textual">To make this more concrete, a simple design approach for an XSLT 1.0 processor is as follows:</textual></para><orderedlist class="po-table e189 e189"><listitem class="po-container e190 e190"><para class="po-block e191 e191"><textual class="po-textual">The source document is built as a tree in memory, typically by a two-stage pipeline consisting
    of a push parser and a tree-builder, perhaps with intermediate filters to perform operations such as
    DTD or schema validation, or XInclude processing.</textual></para></listitem><listitem class="po-container e192 e192"><para class="po-block e193 e193"><textual class="po-textual">Path expressions in the XSLT stylesheet are evaluated using a pull pipeline in which
    the values passed down the pipeline are (references to) nodes in the source tree.</textual></para></listitem><listitem class="po-container e194 e194"><para class="po-block e195 e195"><textual class="po-textual">Instructions in the XSLT stylesheet that construct nodes in the result tree are evaluated 
      by sending decomposed events (start-element, end-element, etc). If the result tree is serialized,
    these events can pass directly to the serializer, which itself is implemented as a push component, eliminating
    the need to construct the result tree physically in memory.</textual></para></listitem></orderedlist><para class="po-block e196 e196"><textual class="po-textual">So we have a push stage, then a pull stage, then another push stage, as illustrated in Figure 4.</textual></para><figure class="po-container e197 e197" xml:id="fig4"><mediaobject class="po-container e198 e198"><imageobject class="po-container e199 e199"><imagedata class="po-meta e200 e200" fileref="../../../vol3/graphics/Kay01/Kay01-004.png" format="png" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e201 e201"><para class="po-block e202 e202"><textual class="po-textual">Fig 4. Typical structure of an XSLT 1.0 processor.</textual></para></caption></mediaobject></figure><para class="po-block e203 e203"><textual class="po-textual">Between the parsing pipeline that processes the source tree and the XPath evaluation pipeline that reads
  it, there is a polarity change from push to pull, and this is typically handled by allocating memory to hold
  the complete tree. That is, the pipeline is interrupted; there is a need for a reservoir of memory with
  sufficient capacity to hold the entire source tree. At the same time, there is a latency impact, because the
  second pipeline stage typically cannot start operation until the first has finished.</textual></para><para class="po-block e204 e204"><textual class="po-textual">A similar conflict typically arises in a straightforward implementation of intra-stylesheet pipelines
  based on temporary trees in XSLT 2.0 (or in XSLT 1.0 with the </textual><code class="po-atom e205 e205"><textual class="po-textual">node-set()</textual></code><textual class="po-textual"> extension). The chances
    are that a variable holding a temporary tree will actually be materialized in memory — constructed as the final
    destination of a push pipeline — to be read by a pull pipeline that only starts operation once the tree writing
  has finished. Contrast this with a variable that simply holds a sequence of existing nodes or atomic values,
  where the process that creates the sequence and the process that reads it can often be pipelined together,
  avoiding the need to physically materialize the variable's value.</textual></para><para class="po-block e206 e206"><textual class="po-textual">By contrast, passing data from a pull pipeline to a push pipeline is no problem. In between there is
  a component that owns the control loop, reading data from the pull side, and writing it to the push side.</textual></para><para class="po-block e207 e207"><textual class="po-textual">Once pipelines become more complex, the turbulence caused by push/pull conflicts can have
      a significant effect on performance. The flow is interrupted every time such buffering occurs, and this does affect both
      memory usage and latency. A recent paper [</textual><xref class="po-milestone e208 e208" linkend="Kay2008"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">] explores the effect of changing certain pull/push decisions
      within the Saxon XQuery processor. This examines the behaviour of a particular query in the XMark benchmark:</textual></para><itemizedlist class="po-table e209 e209"><listitem class="po-container e210 e210"><para class="po-block e211 e211"><textual class="po-textual">Using default execution with push polarity, the query takes 1926ms</textual></para></listitem><listitem class="po-container e212 e212"><para class="po-block e213 e213"><textual class="po-textual">Forcing the query to run with pull polarity, execution time increases to 3496ms,
        because of the need to buffer the result tree before serialization.</textual></para></listitem><listitem class="po-container e214 e214"><para class="po-block e215 e215"><textual class="po-textual">Running the query as a whole with push polarity, but using pull polarity for the
        FLWOR expression that computes the content of the main result element gives a run-time of 2720ms</textual></para></listitem></itemizedlist><para class="po-block e216 e216"><textual class="po-textual">The conclusion to be drawn from these results is not that push is better than pull or vice versa, but
      that </textual><emphasis class="po-inline e217 e217" role="ital"><textual class="po-textual">changes in polarity</textual></emphasis><textual class="po-textual"> as the data passes down the pipeline are
      expensive and need to be avoided.</textual></para><para class="po-block e218 e218"><emphasis class="po-inline e219 e219" role="ital"><textual class="po-textual">The problem is probably worse in XQuery than in XSLT. XSLT has two sublanguages: the XSLT
    instruction set, and the XPath expression language. It makes sense for XPath expressions to pull, and for
    XSLT instructions to push. Because the two sublanguages are independent and don't compose very well, this
    generates relatively few conflicts. By contrast, XQuery is a single language where these constructs are
    fully composable, and using the same evaluation strategy is therefore likely to lead to more turbulence.</textual></emphasis></para><para class="po-block e220 e220"><textual class="po-textual">There is an alternative way to graft a push pipeline to a pull pipeline. Rather than allocating
  memory to hold the accumulated data, it is possible to operate the two in separate threads. With two threads there can
  be two control loops. Data written by the push thread can be placed in a cyclic buffer, from which the pull
  thread can read it, as illustrated in Figure 5.</textual></para><figure class="po-container e221 e221" xml:id="fig5"><mediaobject class="po-container e222 e222"><imageobject class="po-container e223 e223"><imagedata class="po-meta e224 e224" fileref="../../../vol3/graphics/Kay01/Kay01-005.png" format="png" width="90%"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e225 e225"><para class="po-block e226 e226"><textual class="po-textual">Fig 5. Using a cyclic buffer to resolve a push-pull conflict.</textual></para></caption></mediaobject></figure><para class="po-block e227 e227"><textual class="po-textual">Saxon uses this technique to support the limited kind of streamed processing available in Saxon-SA 9.1
  and earlier releases [see </textual><xref class="po-milestone e228 e228" linkend="saxon-streaming"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]. Although this offers limited functionality, it has proved a boon to those users who
  need to handle source documents in the gigabyte range, stretching the capacity of available real memory.
  The idea here is that the result of an expression such as </textual><code class="po-atom e229 e229"><textual class="po-textual">doc('big.xml')//unit</textual></code><textual class="po-textual"> can be
  delivered (piped) as a sequence of </textual><code class="po-atom e230 e230"><textual class="po-textual">unit</textual></code><textual class="po-textual"> elements, each of which is a small subtree
  of the original large document. Many transformations (as noted by [</textual><xref class="po-milestone e231 e231" linkend="McGrath2004"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">] have the 
    characteristic that the transformation can be effected by dividing the source documents into a sequence of
    small trees rooted at what McGrath calls a </textual><emphasis class="po-inline e232 e232" role="ital"><textual class="po-textual">fulcrum</textual></emphasis><textual class="po-textual"> element, applying a transformation to each of these subtrees,
    and then combining the results back into a single result tree; this construct is explicitly geared to
    this kind of transformation. To satisfy the semantics of the language, it is only possible to do this
  if the expression appears in a context where the subtree is copied, for example 
    </textual><code class="po-atom e233 e233"><textual class="po-textual">&lt;xsl:copy-of select="doc('big.xml')//unit"/&gt;</textual></code><textual class="po-textual">. This is because without the copying,
  the recipient of the data would be allowed to navigate away from the </textual><code class="po-atom e234 e234"><textual class="po-textual">unit</textual></code><textual class="po-textual"> element using
  XPath axes such as </textual><code class="po-atom e235 e235"><textual class="po-textual">parent</textual></code><textual class="po-textual"> or </textual><code class="po-atom e236 e236"><textual class="po-textual">following-sibling</textual></code><textual class="po-textual">. With a copy, the </textual><code class="po-atom e237 e237"><textual class="po-textual">unit</textual></code><textual class="po-textual">
  element becomes a standalone (parentless) element, so any attempt at such navigation returns nothing.
  Of course there is no real copying going on here: it's just that the system behaves as if it built a large
  tree containing the whole source document, and then copied small parts of it to be processed one at a time.</textual></para><para class="po-block e238 e238"><textual class="po-textual">The subset of XPath that Saxon allows to be used in this streaming mode is quite restrictive. It is
  based originally on the subset defined in the XML Schema specification for the definition of
  uniqueness and referential integrity constraints. It only allows downward selection. Unlike Saxon's usual strategy
  for XPath evaluation, this streaming subset of XPath is evaluated in push polarity: a SAX parser is used to parse
  the source document, and the resulting events are then passed through a series of push filters whose effect
  is to reduce the document to a sequence of elements representing the parts selected by the path expression (the fulcrum elements).
  The remaining events then go to a tree builder which builds each element subtree in turn as a real tree in memory;
  the sequence of nodes representing the fulcrum elements are then pushed into a cyclic buffer where
  they are read by the pull pipeline (in a separate thread) that consumes the data and transforms it using 
  further XSLT instructions.</textual></para><para class="po-block e239 e239"><textual class="po-textual">It would be possible to avoid this two-thread approach by reimplementing the first stage as a pull
  pipeline, starting with a pull parser (StAX), and then filtering the parsing events in pull polarity. There
  are several reasons this has not been done. Firstly, the code was originally written to work within Saxon's
  schema validator (which works in push polarity), and it would be costly to rewrite it. Secondly, as
  already discussed, writing pull-based filters is probably more difficult than writing push-based
  filters. Finally, all other processes that can take place on the parsing pipeline, for example schema validation,
  would also need to be rewritten to operate in pull polarity, and this is simply not a practical proposition.
  Nevertheless, it needs to be recognized that the current design is an engineering compromise. But as such
  it is convenient to the purpose of this paper, because it exemplifies the fact that when you want to reuse
  streaming components, you will sometimes find that some of them have the wrong polarity.</textual></para></section><section class="po-hcontainer e240 e240"><title class="po-block e241 e241"><textual class="po-textual">Coroutines</textual></title><para class="po-block e242 e242"><textual class="po-textual">Handling the push-pull conflict using multiple threads, as discussed in the previous section,
    is actually overkill. Threads offer two significant features: each thread has its own execution stack
    to maintain state, and each thread can be independently scheduled. We need the first feature, we don't need 
    the second. Or to put it another way, we don't really need threads at all: we need coroutines. (In fact,
    we can probably make do with the restricted kind of coroutine sometimes called a 
    </textual><emphasis class="po-inline e243 e243" role="ital"><textual class="po-textual">generator</textual></emphasis><textual class="po-textual">; but the terminology in this area varies). </textual></para><para class="po-block e244 e244"><textual class="po-textual">The key idea here is that two components can each be written as a loop, maintaining whatever
    data they wish in local variables within the loop. One component issues </textual><code class="po-atom e245 e245"><textual class="po-textual">write</textual></code><textual class="po-textual"> calls
    within its loop to push data out; the other issues </textual><code class="po-atom e246 e246"><textual class="po-textual">read</textual></code><textual class="po-textual"> calls within its loop to pull data in.
    When the writer issues its write request, control passes to the reader at the point where it issued its read 
    request; and when the reader issues its read request, control passes back to the writer so that it can
    compute its next output and write it.</textual></para><para class="po-block e247 e247"><textual class="po-textual">Of course, this extends to a pipeline with more than two components. It also extends to a branching
    pipeline in which one component writes several output streams for consumption by different readers.
    And to a merging pipeline, in which one component reads from several input streams supplied by different
    writers. Essentially it means that as far as the programmer is concerned, there are no push or pull components
    any more: every component owns its own control loop. This, as we have seen, should simplify the programming
    of the component, and it should also improve reusability, since components are no longer restricted to operate
    in either a push or pull pipeline: they can work in both.</textual></para><para class="po-block e248 e248"><emphasis class="po-inline e249 e249" role="ital"><textual class="po-textual">How come this doesn't lead to deadlocks? The answer is that you can't have
    a general graph of coroutines reading and writing to each other, as you can with threads. The coroutines are
    not true peers; there has to be a hierarchic control relationship represented by the way in which they
    are originally invoked.</textual></emphasis></para><para class="po-block e250 e250"><textual class="po-textual">Unfortunately this concept, to be usable in practice, requires support from the programming language
    and compiler, which is rarely forthcoming in modern programming languages, though the </textual><code class="po-atom e251 e251"><textual class="po-textual">yield</textual></code><textual class="po-textual">
    construct found in Javascript and C# comes close.</textual></para><para class="po-block e252 e252"><textual class="po-textual">However, XSLT is a programming language, and we are in control of its compiler, so this raises the
    question of whether user-level intra-stylesheet pipelines can indeed be implemented as coroutines.
    Specifically, can we generate code from XSLT templates such that the XSLT code that writes data to
    a temporary tree runs as a coroutine alongside the XSLT code that reads data from the temporary tree?
    In principle, one of the major benefits of having a stateless declarative language like XSLT is that
    the implemented execution model can diverge dramatically from the structure of the code as seen by its 
    author.</textual></para><para class="po-block e253 e253"><textual class="po-textual">Clearly this is only going to work if the temporary tree is processed
    in a sequential manner. This caveat eliminates many cases: it reflects the fact that a push-pull
    conflict is not the only reason that pipelines break down; they also break because of ordering conflicts
    (data needs to be sorted), or because, in the case of a pull pipeline, data cannot be supplied to more than
    one client in a streamed manner. But if we work on the assumption, for the moment, that we can identify
    an XSLT process that reads a temporary tree in a sequential manner (we'll come back to this later), then in principle
    we should be able to run this as a coroutine alongside the process that writes the tree, without buffering
    the tree in memory.</textual></para><para class="po-block e254 e254"><textual class="po-textual">At this point, it will be useful to rediscover the concept of program inversion, an idea
    from the days of sequential data processing using magnetic tape, that was designed 
    specifically to tackle this problem.</textual></para></section><section class="po-hcontainer e255 e255"><title class="po-block e256 e256"><textual class="po-textual">Jackson Structured Programming and the Concept of Inversion</textual></title><para class="po-block e257 e257"><textual class="po-textual">Michael Jackson (not the singer) developed the method of program construction known
    as JSP (Jackson Structured Programming) initially as a way of designing the batch processing
    systems of the 1960s and early 1970s, characterised by their use of sequential 
    data files stored on open-reel magnetic tapes. The method is fully described in a 1975 book
    [</textual><xref class="po-milestone e258 e258" linkend="Jackson1975"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">], but most readers will find it easier to consult a 
    retrospective analysis written by Jackson in 2001 [</textual><xref class="po-milestone e259 e259" linkend="Jackson2001"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]</textual></para><para class="po-block e260 e260"><textual class="po-textual">The files used in these systems were generally organized as a hierarchy (for example,
    customers, orders, then order lines) and were processed sequentially. There was insufficient
    main memory to hold more than a fraction of the file contents: a reel of magnetic tape held typically
    20Mb, while 128Kb of main memory was considered generous. So processing consisted of reading one or more
    tapes sequentially, typically a master file and a transaction file containing details of changes,
    merging the data from the multiple inputs, and then writing the output
    to another tape.</textual></para><para class="po-block e261 e261"><textual class="po-textual">The essential principle of JSP was the idea that the structure of the program should mirror
    the structure of the data. JSP used a graphical notation to represent hierarchic structure embodying
    the basic elements of sequence, choice, and iteration, and this same notation was used to represent the
    structure both of the data and of the resulting program. The notation is illustrated in Figure 6.
    In his retrospective, Jackson acknowledges
    that the ideas he was advocating had a great deal in common with parallel developments in compiler-writing;
    his graphical notation was essentially a BNF schema for data files, and his program structure similar to 
    that of a recursive descent parser derived from that grammar. But of course no-one saw it that way at 
    the time: compiler technology was still in its infancy.</textual></para><figure class="po-container e262 e262" xml:id="fig6"><mediaobject class="po-container e263 e263"><imageobject class="po-container e264 e264"><imagedata class="po-meta e265 e265" fileref="../../../vol3/graphics/Kay01/Kay01-006.png" format="png"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></imagedata></imageobject><caption class="po-container e266 e266"><para class="po-block e267 e267"><textual class="po-textual">Fig 6. Jackson notation for sequence, iteration, and choice.</textual></para></caption></mediaobject></figure><para class="po-block e268 e268"><textual class="po-textual">So, what happens when the structure of the output file does not correspond in a simple way
    to the structure of the input? This is known as a </textual><emphasis class="po-inline e269 e269" role="ital"><textual class="po-textual">structure clash</textual></emphasis><textual class="po-textual">.
    Jackson identified three kinds of structure clash:</textual></para><itemizedlist class="po-table e270 e270"><listitem class="po-container e271 e271"><para class="po-block e272 e272"><textual class="po-textual">An </textual><emphasis class="po-inline e273 e273" role="ital"><textual class="po-textual">interleaving clash</textual></emphasis><textual class="po-textual">, typically involving
      transformation of a single input sequence (all employees, say) into multiple output
      sequences (employees by department)</textual></para></listitem><listitem class="po-container e274 e274"><para class="po-block e275 e275"><textual class="po-textual">An </textual><emphasis class="po-inline e276 e276" role="ital"><textual class="po-textual">ordering clash</textual></emphasis><textual class="po-textual">, involving sorting the data
      into a different order</textual></para></listitem><listitem class="po-container e277 e277"><para class="po-block e278 e278"><textual class="po-textual">A </textual><emphasis class="po-inline e279 e279" role="ital"><textual class="po-textual">boundary clash</textual></emphasis><textual class="po-textual">, involving constructing
      a new hierarchy for the existing records without changing their order (in the language of the markup world,
      this is the problem of parallel hierarchies running through the same data, with one hierarchy being
      primary in the input and a different hierarchy being primary in the output). </textual></para></listitem></itemizedlist><para class="po-block e280 e280"><textual class="po-textual">Of these, the one that caused most problems in program design was the boundary clash, and
    Jackson's approach to solving it was to split the process into two phases, a flattening phase that
    eliminates the first hierarchy, followed by a grouping phase that imposes the second hierarchy.
    So we see that the notion of the pipeline as a mechanism for breaking down the processing of hierarchic data
    has a long pedigree.</textual></para><para class="po-block e281 e281"><textual class="po-textual">In the world of magnetic tape, the problem was that the output of one phase of processing was typically
    written to tape, to be read again by the next phase. Since writing 20Mb of data to a tape could take an hour,
    this clearly created a problem, and this is where the idea of inversion comes into the picture.</textual></para><para class="po-block e282 e282"><textual class="po-textual">Jackson recognized that the intermediate file could be eliminated if, instead of the second phase
    of processing owning its own control loop, it were rearranged to be called by the first program every time
    another record became available. JSP refers to this rearrangement as an inversion. Crucially, Jackson
    recognized that this did not necessarily mean that the second phase had to be written in what we would
    now call a “push” style: inversion was a mechanical transformation of a program text that could be performed
    by a compiler. Jackson went on to produce a COBOL preprocessor that automated this task.</textual></para><para class="po-block e283 e283"><textual class="po-textual">Again there is a similarity with compiler technology. A bottom-up parser is an inversion of the
    top-down parser for the same grammar; whereas the top-down parser has the structure Jackson would advocate,
    mirroring the structure of the input file, the bottom-up equivalent is event-driven. The challenge in writing
    a correct bottom-up (push) parser for a complex grammar is considerable, because of the difficulty of
    maintaining state between calls; but the task can be automated given a high-level description of the
    grammar to be processed.</textual></para><para class="po-block e284 e284"><textual class="po-textual">The relationship between a conversational application and a transactional one is another example
    of an inversion. A conversational application owns the control loop and issues write requests to talk to the
    user, and read requests to get their replies. This relies on the application retaining state in main memory (or
    paged out to secondary store) while waiting for user responses, which severely limits concurrency.
    A transactional application, whether written according to the conventions of a traditional mainframe TP 
    monitor or according to the more modern architecture of the web, is event-based: a message from the user
    activates the application, which has to retrieve the state of the conversation from some holding place,
    process the message, and then save the state again before replying to the user.</textual></para><para class="po-block e285 e285"><textual class="po-textual">The UK mainframe manufacturer
    ICL developed a very successful fourth-generation application development environment under the name
    RADS (it was subsequently marketed as QuickBuild) [</textual><xref class="po-milestone e286 e286" linkend="Brown1981"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">, </textual><xref class="po-milestone e287 e287" linkend="Cosh1981"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]. 
    QuickBuild was designed according to JSP principles. 
    Interactive applications were written in a conversational style (as if they owned the control loop), and
    were then automatically compiled into transactional code - again, an automated inversion. A similar
    idea can also be seen in the scripting language used by the Cocoon framework [</textual><xref class="po-milestone e288 e288" linkend="cocoon-flow"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e289 e289"><textual class="po-textual">In all these examples, the user achieves the benefits that come from writing the application
    as a controlling application (maintainability, readability, reusability) combining these with the
    improvements in system performance that come from using a push-based control model.</textual></para><para class="po-block e290 e290"><textual class="po-textual">How does inversion actually work? Essentially, whereever the application issues a read request
    for more data, this needs to be translated into instructions that save the state (including the reentry point),
    and exit. Then a new entry point needs to be created for the module, to be invoked when data becomes available,
    which restores the state and resumes execution at the correct entry point. Typically the state here means
    the data on the stack, together with the reentry point (or program counter). 
    This state is sometimes known as a </textual><emphasis class="po-inline e291 e291" role="ital"><textual class="po-textual">continuation</textual></emphasis><textual class="po-textual">;
    some modern programming languages, even if they do not compile inverted code automatically, offer continuations
    as a way of achieving a similar effect by hand. The </textual><code class="po-atom e292 e292"><textual class="po-textual">yield</textual></code><textual class="po-textual"> construct in C# is an example.</textual></para><para class="po-block e293 e293"><textual class="po-textual">Inversion does not depend on a program being written in a declarative language like XSLT with
    no immutable variables. But it becomes a lot easier to analyze the language to determine what parts of the state
    are significant, and to avoid saving and restoring unnecessary parts of the state, if the language is
    sufficiently high level. The essential requirement is not that variables are immutable, but that it
    is clear from static analysis which variables need to be preserved as part of the state. In the case
    of XSLT, the term “variables” here includes the dynamic execution context: that is, the context item,
    position, and size, as well as more obscure context variables such as the current grouping key and current
    mode. The next section explores inversion of XSLT programs in more detail.</textual></para></section><section class="po-hcontainer e294 e294"><title class="po-block e295 e295"><textual class="po-textual">Inversion in XSLT</textual></title><para class="po-block e296 e296"><textual class="po-textual">Let's look at inversion in XSLT. Specifically, let's take a simple stylesheet and see how it can
      be compiled in such a way that it is driven by push events coming from the XML parser, and in turn
      drives the serializer by issuing similar push events. Such a stylesheet would be fully streamable,
      allowing execution without building either the source tree or the result tree in memory.</textual></para><para class="po-block e297 e297"><textual class="po-textual">Clearly not all stylesheets are fully streamable in this way, and it's not the intent in this
      paper to try to define exactly what conditions a stylesheet must satisfy in order to be streamable.
      The XSL Working Group in W3C is currently working on this problem, and hopefully will publish its first
      results soon after the Balisage 2009 conference. The focus here is on a different problem:
      having determined the code is streamable in principle, how do we actually arrange the execution to
      perform streaming?</textual></para><section class="po-hcontainer e298 e298"><title class="po-block e299 e299"><textual class="po-textual">Inverting a single-phase stylesheet</textual></title><para class="po-block e300 e300"><textual class="po-textual">We'll start with a single-phase stylesheet, one that is self-evidently streamable in that the push
    events needed to construct the result tree are a subsequence of the push events representing the source tree. 
    Hopefully if we can establish that a single-phase streamable
    stylesheet can be inverted, it should then be possible to see how multiple streamable phases can be
    pipelined together without allocating memory for buffering intermediate results.</textual></para><para class="po-block e301 e301"><textual class="po-textual">Here is a simple stylesheet that deletes all the </textual><code class="po-atom e302 e302"><textual class="po-textual">NOTE</textual></code><textual class="po-textual"> elements from a source
      document, wherever they appear.</textual></para><programlisting class="po-block e303 e303" xml:space="preserve"><textual class="po-textual">
      &lt;xsl:stylesheet version="2.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform"&gt;
      
      &lt;xsl:template match="*"&gt;
        &lt;xsl:copy&gt;
          &lt;xsl:copy-of select="@*"/&gt;
          &lt;xsl:apply-templates/&gt;
        &lt;/xsl:copy&gt;
      &lt;/xsl:template&gt;
      
      &lt;xsl:template match="NOTE"/&gt;

      &lt;/xsl:stylesheet&gt;</textual></programlisting><para class="po-block e304 e304"><textual class="po-textual">XSLT 2.0 describes the semantics of this code in terms of functional composition: 
    </textual><code class="po-atom e305 e305"><textual class="po-textual">xsl:apply-templates</textual></code><textual class="po-textual"> is an expression that returns a result (which in this case will
    always be a sequence of elements); this sequence is then used as an operand of the containing
    instruction (</textual><code class="po-atom e306 e306"><textual class="po-textual">xsl:copy</textual></code><textual class="po-textual">), which copies these elements, adding a new parent element to
    construct a larger tree at each stage of processing.</textual></para><para class="po-block e307 e307"><textual class="po-textual">In practice, however, the execution model is likely to be closer to the way XSLT 1.0 
    describes the semantics. The 1.0 specification talks of instructions writing nodes to the result tree:
    that is, of data being pushed to the next stage in the pipeline. It's easy to visualize the start
    and end tags of the </textual><code class="po-atom e308 e308"><textual class="po-textual">xsl:copy</textual></code><textual class="po-textual"> instruction as if they were separate sub-instructions, one 
    pushing a </textual><code class="po-atom e309 e309"><textual class="po-textual">startElement</textual></code><textual class="po-textual"> event to the result, the other pushing a matching 
      </textual><code class="po-atom e310 e310"><textual class="po-textual">endElement</textual></code><textual class="po-textual"> event.</textual></para><para class="po-block e311 e311"><textual class="po-textual">One can see this effect at work in Saxon's XQuery compiler. Saxon-SA has the capability to compile
    XQuery to Java source code, which makes the execution strategy rather visible. Given this query:</textual></para><programlisting class="po-block e312 e312" xml:space="preserve"><textual class="po-textual">
    &lt;e&gt;
      &lt;date&gt;{current-dateTime()}&lt;/date&gt;
    &lt;/e&gt; </textual></programlisting><para class="po-block e313 e313"><textual class="po-textual">the resulting Java code (simplified only very slightly for comprehension) is:</textual></para><programlisting class="po-block e314 e314" xml:space="preserve"><textual class="po-textual">
    public void process(final XPathContext context) throws XPathException {
        SequenceReceiver out = context.getReceiver();
        out.startElement(name_e, type_untyped);
        out.startElement(name_date, type_untyped);
        out.append(context.getCurrentDateTime());
        out.endElement();
        out.endElement();
    }</textual></programlisting><para class="po-block e315 e315"><textual class="po-textual">This query, of course, reads no data: it was chosen deliberately to show how the construction
    of the result tree is optimized away. Although Saxon's XSLT processor does not have the ability to generate
    Java code, the execution model of the interpreter follows the same pattern. If it did generate code, the
    code for the identity template in our example stylesheet would look something like this (this is idealized
    code; it leaves out messy details such as maintaining the context position):</textual></para><programlisting class="po-block e316 e316" xml:space="preserve"><textual class="po-textual">
    public void template1234(final XPathContext context) throws XPathException {
        SequenceReceiver out = context.getReceiver();
        NodeInfo current = context.getCurrentNode();
        out.startElement(current.getNodeName(), type_untyped);
        Iterator attributes = current.iterateAxis(Axis.ATTRIBUTE);
        while (attributes.hasNext()) {
            NodeInfo attr = attributes.next();
            out.attribute(attr.getNodeName(), attr.getStringValue());
        }
        XPathContext context2 = context.newContext();
        Iterator children = current.iterateAxis(Axis.ATTRIBUTE);
        while (children.hasNext()) {
            NodeInfo child = children.next();
            applyTemplates(child, context2);
        }
        out.endElement();
    }      
    </textual></programlisting><para class="po-block e317 e317"><textual class="po-textual">We can see that this code is written in the form of a control loop. It reads its input using
    imperatives such as </textual><code class="po-atom e318 e318"><textual class="po-textual">children.next()</textual></code><textual class="po-textual"> (and, indirectly, via </textual><code class="po-atom e319 e319"><textual class="po-textual">applyTemplate()</textual></code><textual class="po-textual">),
    and it writes its output using imperatives such as </textual><code class="po-atom e320 e320"><textual class="po-textual">startElement()</textual></code><textual class="po-textual"> and </textual><code class="po-atom e321 e321"><textual class="po-textual">endElement()</textual></code><textual class="po-textual">.
    To make this code streamable with respect to the input from the parser, we need to invert it. It will 
    end up looking something like the code for the Saxon schema validator. This maintains a stack of
    element handlers, one for each currently open element; if an element is being processed by a template
    rule, then the element handler would be a class with methods </textual><code class="po-atom e322 e322"><textual class="po-textual">startElement()</textual></code><textual class="po-textual"> and 
    </textual><code class="po-atom e323 e323"><textual class="po-textual">endElement()</textual></code><textual class="po-textual"> which for the identity template would look something like this:</textual></para><programlisting class="po-block e324 e324" xml:space="preserve"><textual class="po-textual">
    public State startElement(final XPathContext context) throws XPathException {
        SequenceReceiver out = context.getReceiver();
        NodeInfo current = context.getCurrentNode();
        out.startElement(current.getNodeName(), type_untyped);
        return applyTemplatesState ;
    }
    
    public void endElement(final XPathContext context) throws XPathException {
        SequenceReceiver out = context.getReceiver();
        out.endElement();
    }        
    </textual></programlisting><para class="po-block e325 e325"><textual class="po-textual">The object </textual><code class="po-atom e326 e326"><textual class="po-textual">applyTemplatesState</textual></code><textual class="po-textual"> is the </textual><emphasis class="po-inline e327 e327" role="ital"><textual class="po-textual">continuation</textual></emphasis><textual class="po-textual">,
    the data that tells the despatcher what to do next: in this case, to select template rules to process
    the events representing children of this element, adding those templates to the stack of state information.</textual></para><para class="po-block e328 e328"><textual class="po-textual">The inversion of a template will not always be as simple as this, of course. In general on exit from
    the </textual><code class="po-atom e329 e329"><textual class="po-textual">startElement()</textual></code><textual class="po-textual"> call, all information about current variables and the current context
    needs to be saved on a stack, and restored from the stack when </textual><code class="po-atom e330 e330"><textual class="po-textual">endElement()</textual></code><textual class="po-textual"> is called.
    If the template contains an </textual><code class="po-atom e331 e331"><textual class="po-textual">xsl:choose</textual></code><textual class="po-textual"> instruction, the retained state information will need
    to remember which branch of the choice is active, and so on.</textual></para><para class="po-block e332 e332"><textual class="po-textual">If the template uses </textual><code class="po-atom e333 e333"><textual class="po-textual">xsl:for-each</textual></code><textual class="po-textual"> to process the children of the context node,
      the simplest way to handle this is probably by rewriting the </textual><code class="po-atom e334 e334"><textual class="po-textual">xsl:for-each</textual></code><textual class="po-textual"> as a call
    on </textual><code class="po-atom e335 e335"><textual class="po-textual">xsl:apply-templates</textual></code><textual class="po-textual"> in some singular mode, passing all the in-scope variables as parameters.
    This reduces the number of cases that need to be handled by the inversion logic. Other more complex constructs
    such as </textual><code class="po-atom e336 e336"><textual class="po-textual">xsl:for-each-group</textual></code><textual class="po-textual">, however, still need individual treatment if they are to be made
    amenable to streaming.</textual></para></section><section class="po-hcontainer e337 e337"><title class="po-block e338 e338"><textual class="po-textual">Inverting a multi-phase stylesheet</textual></title><para class="po-block e339 e339"><textual class="po-textual">A multi-phase stylesheet typically uses a temporary tree (or sequence) in a variable
      to hold the intermediate results that form the output of one phase and the input to the next.
      Ideally each phase will use a different mode:</textual></para><programlisting class="po-block e340 e340" xml:space="preserve"><textual class="po-textual">
     &lt;xsl:variable name="phase1output"&gt;
       &lt;xsl:apply-template select="/" mode="m1"/&gt;
     &lt;/xsl:variable&gt;
     
     &lt;xsl:variable name="phase2output"&gt;
       &lt;xsl:apply-templates select="$phase1output" mode="m2"/&gt;
     &lt;/xsl:variable&gt;
     
     &lt;xsl:template match="/"&gt;
       &lt;xsl:apply-templates select="$phase2output" mode="m3"/&gt;
     &lt;/xsl:template&gt;
     </textual></programlisting><para class="po-block e341 e341"><textual class="po-textual">Provided it can be established that the processing of a temporary tree such as
     </textual><code class="po-atom e342 e342"><textual class="po-textual">phase1output</textual></code><textual class="po-textual"> is streamable (which, as we have said, is beyond the scope of this
     paper), there is essentially no additional difficulty in pipelining the different phases
     together in such a way that the intermediate results are not buffered in memory. Phase 1 writes
     to </textual><code class="po-atom e343 e343"><textual class="po-textual">phase1output</textual></code><textual class="po-textual"> by pushing events; the inverted code for phase 2 is immediately activated
     to process these events as they occur.</textual></para></section><section class="po-hcontainer e344 e344"><title class="po-block e345 e345"><textual class="po-textual">Must it be pushed, or can it be pulled?</textual></title><para class="po-block e346 e346"><textual class="po-textual">The previous sections describe how XSLT code, considered as a control loop, can be inverted
      with respect to its input, so that it acts as a push filter, processing events originating from the
      previous phase of processing.</textual></para><para class="po-block e347 e347"><textual class="po-textual">It's reasonable to ask whether one could not equally well invert the code with respect to its
      output, so that it acts as a pull filter, responding to requests for more data originating from
      the subsequent phase of processing, that is, from the consumer of its output.</textual></para><para class="po-block e348 e348"><textual class="po-textual">The answer is that this is also possible, though I have not explored this avenue in as much
      detail: because the Saxon serializer and schema validators work only in push polarity, there is a strong
      tendency to use push polarity for everything else as well.</textual></para><para class="po-block e349 e349"><textual class="po-textual">We have already seen that the key difference between push and polarity is that a push
      component can send data to multiple recipients, whereas a pull component can read data from multiple
      sources. XSLT in its current form has few constructs that requires the ability to
      stream input from multiple sources in parallel (the example of the </textual><code class="po-atom e350 e350"><textual class="po-textual">deep-equal()</textual></code><textual class="po-textual"> function
      was a little contrived). An </textual><code class="po-atom e351 e351"><textual class="po-textual">xsl:merge</textual></code><textual class="po-textual"> instruction is under consideration
      for XSLT 2.1, and one can see how this would benefit from streamed processing in pull polarity.
      Meanwhile it should be evident how the ability of push pipelines to branch to multiple destinations could be
      exploited in cases where one component in a pipeline writes temporary data to a variable, and
      two separate components both read from this variable. If both these components are streamable, there
      is no reason why the fact that the variable has more than one reader should result in it being
      buffered in memory; the events generated by the component that writes to the variable can be broadcast
      to all the readers of the variable, provided that each of them is streamable with respect to that
      variable.
      </textual></para><para class="po-block e352 e352"><textual class="po-textual">So, inversion into pull polarity is possible, but inversion to push code seems to have
      more practical utility at present.</textual></para></section></section><section class="po-hcontainer e353 e353"><title class="po-block e354 e354"><textual class="po-textual">Conclusions</textual></title><para class="po-block e355 e355"><textual class="po-textual">Pipelines have been recognized for many years as a good way to structure XML applications,
  and the emergence of XProc as a standard language for describing pipelines can only encourage this.
  For performance, the stages of a pipeline should communicate by means of streams of events.
  Traditionally, this can be done either by writing components with pull polarity (the consumer calls
  the supplier when data is required), or by components with push polarity (the supplier calls the consumer
  when data is available). Performance problems arise when components with different polarity are mixed
  within the same pipeline.</textual></para><para class="po-block e356 e356"><textual class="po-textual">This is seen within the internal pipelining of an XSLT processor. The scaleability of XSLT is limited
  because most processors build the source tree in memory. This is sometimes needed because the transformation
  accesses the data not in its original order; but in many cases the tree is built only because of the polarity
  clash that exists between the push operation used by the XML parser and validator, and the pull operation
  used by the XPath processor when navigating the tree. Many XSLT processors avoid building the result tree
  in memory, and this is because there is no polarity clash: the XSLT instruction evaluation and the result tree
  serialization both operate with push polarity.</textual></para><para class="po-block e357 e357"><textual class="po-textual">This problem is not new. Jackson tackled it when designing batch processing systems using magnetic tape.
  He formalized the concepts of structure clashes that prevent streamed operation, and he developed the idea
  of program inversion as a way of automatically transforming a pull program to a push program or vice versa.
  What this paper has attempted to do is to demonstrate that the same ideas can be applied to the XML-based
  pipeline systems of today. As the usage of XML increases and more and more users find themselves applying
  languages like XSLT and XQuery to multi-gigabyte datasets, a technology that can remove the problems
  caused by pipeline polarity clashes has great potential.</textual></para></section><bibliography class="po-hcontainer e358 e358"><title class="po-block e359 e359"><textual class="po-textual">Bibliography</textual></title><bibliomixed class="po-block e360 e360" xml:id="cocoon" xreflabel="Cocoon"><textual class="po-textual">Apache Cocoon. </textual><link class="po-inline e361 e361" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://cocoon.apache.org/</textual></link></bibliomixed><bibliomixed class="po-block e362 e362" xml:id="cocoon-flow" xreflabel="Cocoon Flow"><textual class="po-textual">Advanced Control Flow: Cocoon and continuations. </textual><link class="po-inline e363 e363" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://cocoon.apache.org/2.1/userdocs/flow/how-does-it-work.html</textual></link></bibliomixed><bibliomixed class="po-block e364 e364" xml:id="Brown1981" xreflabel="Brown1981"><textual class="po-textual">A. P. G. Brown, H. G. Cosh, and D. J. L Gradwell.
  Database Processing in RADS - Rapid Application Development System. In Proc 1st British National Conf.
  on Databases (BNCOD-1), Cambridge, 1981</textual></bibliomixed><bibliomixed class="po-block e365 e365" xml:id="Cosh1981" xreflabel="Cosh1981"><textual class="po-textual">H. G. Cosh, A. P. G. Brown, and D. J. L Gradwell.
    RADS - ICL's Rapid Application Development System. In Proc 3rd Conf of European Cooperation in Informatics,
    Munich, 1981. Springer, ISBN 3-540-10855-8</textual></bibliomixed><bibliomixed class="po-block e366 e366" xml:id="Jackson1975" xreflabel="Jackson1975"><textual class="po-textual">Michael A Jackson.
    Principles of Program Design. Academic Press, 1975</textual></bibliomixed><bibliomixed class="po-block e367 e367" xml:id="Jackson2001" xreflabel="Jackson2001"><textual class="po-textual">Michael A. Jackson. 
    JSP in Perspective. sd&amp;m Pioneers' Conference, Bonn, June 2001.
    </textual><link class="po-inline e368 e368" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://mcs.open.ac.uk/mj665/JSPPers1.pdf</textual></link></bibliomixed><bibliomixed class="po-block e369 e369" xml:id="Kay2001" xreflabel="Kay2001"><textual class="po-textual">Michael Kay. Saxon: Anatomy of an XSLT Processor. IBM DeveloperWorks, Feb 2001.
    </textual><link class="po-inline e370 e370" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.ibm.com/developerworks/library/x-xslt2/</textual></link></bibliomixed><bibliomixed class="po-block e371 e371" xml:id="Kay2008" xreflabel="Kay2008"><textual class="po-textual">Michael Kay. Ten Reasons why Saxon XQuery is Fast. 
    IEEE Data Engineering Bulletin, 31(4):65-, Dec 2008.
    </textual><link class="po-inline e372 e372" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://sites.computer.org/debull/A08dec/saxonica.pdf</textual></link></bibliomixed><bibliomixed class="po-block e373 e373" xml:id="McGrath2002" xreflabel="McGrath2002"><textual class="po-textual">Sean McGrath. 
    XPipe — A Pipeline Based Approach To XML Processing, Proc. XML Europe 2002, Barcelona, Spain, May 2002.</textual></bibliomixed><bibliomixed class="po-block e374 e374" xml:id="McGrath2004" xreflabel="McGrath2004"><textual class="po-textual">Sean McGrath. 
    Performing impossible feats of XML processing with pipelining, Proc XML Open 2004, 
    </textual><link class="po-inline e375 e375" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://seanmcgrath.blogspot.com/pipelines.ppt</textual></link><textual class="po-textual"> (Microsoft Powerpoint)</textual></bibliomixed><bibliomixed class="po-block e376 e376" xml:id="orbeon" xreflabel="Orbeon"><link class="po-inline e377 e377" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.orbeon.com/</textual></link></bibliomixed><bibliomixed class="po-block e378 e378" xml:id="saxon" xreflabel="Saxon"><link class="po-inline e379 e379" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.saxonica.com/</textual></link></bibliomixed><bibliomixed class="po-block e380 e380" xml:id="saxon-streaming" xreflabel="Saxon Streaming"><textual class="po-textual">Streaming of Large Documents (in the Saxon documentation).
    </textual><link class="po-inline e381 e381" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.saxonica.com/documentation/sourcedocs/serial.html</textual></link></bibliomixed><bibliomixed class="po-block e382 e382" xml:id="serialization" xreflabel="W3C Serialization"><textual class="po-textual">Scott Boag et al, eds. XSLT 2.0 and XQuery 1.0 Serialization.
    W3C Recommendation, 23 January 2007.
    </textual><link class="po-inline e383 e383" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.w3.org/TR/xslt-xquery-serialization/</textual></link></bibliomixed><bibliomixed class="po-block e384 e384" xml:id="Thompson2001" xreflabel="Thompson2001"><textual class="po-textual">Henry S. Thompson. 
    The XML Meta-Architecture. Presented at XML DevCon, London, Feb 2001. 
    </textual><link class="po-inline e385 e385" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.ltg.ed.ac.uk/~ht/XML_MetaArchitecture.html</textual></link></bibliomixed><bibliomixed class="po-block e386 e386" xml:id="xproc" xreflabel="W3C XProc"><textual class="po-textual">Norman Walsh, Alex Milowski, and Henry S. Thompson, eds. 
    XProc: An XML Pipeline Language. W3C Candidate Recommendation, 26 November 2008.
    </textual><link class="po-inline e387 e387" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.w3.org/TR/xproc/</textual></link></bibliomixed><bibliomixed class="po-block e388 e388" xml:id="xsd" xreflabel="W3C XML Schema"><textual class="po-textual">Henry S. Thompson et al, eds. 
    XML Schema Part1: Structures. 2nd Edition. W3C Recommendation, 28 October 2004.
    </textual><link class="po-inline e389 e389" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple"><textual class="po-textual">http://www.w3.org/TR/xproc/</textual></link></bibliomixed></bibliography></article></classedDocument>