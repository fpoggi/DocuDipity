<?xml version="1.0" encoding="UTF-8" standalone="no"?><classedDocument><article xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" class="po-hcontainer e0 e0" version="5.0-subset Balisage-1.3"><title class="po-block e1 e1"><textual class="po-textual">Things stay the same, or, the real meaning of technical work</textual></title><info class="po-record e2 e2"><confgroup class="po-record e3 e3"><conftitle class="po-field e4 e4"><textual class="po-textual">Balisage: The Markup Conference 2012</textual></conftitle><confdates class="po-field e5 e5"><textual class="po-textual">August 7 - 10, 2012</textual></confdates></confgroup><abstract class="po-container e6 e6"><para class="po-block e7 e7"><textual class="po-textual">What does not change when things change.</textual></para></abstract><author class="po-record e8 e8"><personname class="po-record e9 e9"><firstname class="po-field e10 e10"><textual class="po-textual">C. M.</textual></firstname><surname class="po-field e11 e11"><textual class="po-textual">Sperberg-McQueen</textual></surname></personname><personblurb class="po-container e12 e12"><para class="po-block e13 e13"><textual class="po-textual">C. M. Sperberg-McQueen is the founder of Black Mesa Technologies LLC,
a consultancy specializing in the use of descriptive markup to help
memory institutions preserve cultural heritage information for the
long haul.  He has served as co-editor of the XML 1.0 specification,
the Guidelines of the Text Encoding Initiative, and the XML Schema
Definition Language (XSD) 1.1 specification.  He holds a doctorate in
comparative literature.</textual></para></personblurb><affiliation class="po-record e14 e14"><orgname class="po-block e15 e15"><textual class="po-textual">Black Mesa Technologies LLC</textual></orgname></affiliation></author><legalnotice class="po-container e16 e16"><para class="po-block e17 e17"><textual class="po-textual">Copyright © 2012 by the author</textual></para></legalnotice></info><para class="po-block e18 e18"><textual class="po-textual">Murray Maloney just called my attention to a
recently case horoscope which covers the next couple 
of hours.  It seems to be describing at least the title of my talk, </textual><quote class="po-inline e19 e19"><textual class="po-textual">Things stay the same,</textual></quote><textual class="po-textual"> but is perhaps
describing the conference as a whole.  It says:
</textual><blockquote class="po-container e20 e20"><para class="po-block e21 e21"><textual class="po-textual">Attempts to change things fail. Others resist your suggestions and stand in your way.</textual></para><para class="po-block e22 e22"><textual class="po-textual">Comforts are a bother.</textual></para></blockquote><textual class="po-textual">
I wasn’t quite sure at first what to make of that last bit, but now I think it’s telling us there’s no conference lunch today.</textual></para><para class="po-block e23 e23"><textual class="po-textual">As the horoscope suggests, as people — as human beings — we seem to have trouble with change.</textual></para><para class="po-block e24 e24"><textual class="po-textual">At one level, we run into difficulties when the meanings of technical terms shift.  That’s part of language history, but it leads to complications, as Tommie Usdin told us in her opening on Tuesday [</textual><xref class="po-milestone e25 e25" linkend="t915p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].  It can lead to resentment if people re-use old terms with new meanings; it can lead to resentment if they coin new terms when we think they could have used old ones or the terms that we coined before they coined theirs.</textual></para><para class="po-block e26 e26"><textual class="po-textual">That low-level problem is matched by similar problems at higher levels of abstraction or system complexity.  We’re all familiar with the problems of building systems to accommodate change and with the challenges that come with trying to accommodate the changes that actually happen even after you have built a system to accommodate change because you discover that you built it to accommodate </textual><emphasis class="po-inline e27 e27"><textual class="po-textual">this</textual></emphasis><textual class="po-textual"> kind of change [</textual><emphasis class="po-inline e28 e28"><textual class="po-textual">gesture</textual></emphasis><textual class="po-textual">], and if people would only make that kind of change instead of </textual><emphasis class="po-inline e29 e29"><textual class="po-textual">that other</textual></emphasis><textual class="po-textual"> kind of change [</textual><emphasis class="po-inline e30 e30"><textual class="po-textual">gesture</textual></emphasis><textual class="po-textual">], our system would be fine.  But people don’t always change in the way that we want them to.  Keeping track of things is complicated.  Keeping track of how things got the way they are is an important topic; without that, we have no memories. Ashley Clark’s paper on meta-stylesheets and the provenance of XSL transformations addresses a key problem for every process undertaken by any institution that hopes to have any form of institutional memory [</textual><xref class="po-milestone e31 e31" linkend="w1100l"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e32 e32"><textual class="po-textual">The difficulty of change isn’t peculiar to technical
areas.</textual></para><para class="po-block e33 e33"><textual class="po-textual">The challenge of dealing with change has been with us for a long
time. We have a long history of efforts to deal with change. 
Centuries of stoic and neo-stoic philosophy teach us to discipline
our emotions and not to allow ourselves to come to care for things
that may change.</textual></para><para class="po-block e34 e34"><textual class="po-textual">The neo-stoic approach somehow feels like an attempt to deal
with the emotional side — the emotional difficulties —
of change. One of the reasons we are uncomfortable with change is it
reminds us that time is passing.  Not just time in general, but
</textual><emphasis class="po-inline e35 e35"><textual class="po-textual">our</textual></emphasis><textual class="po-textual"> time is passing; our mortality is nearing.
Many of us have some difficulty, at least some of the time,
contemplating our mortality with complete equanimity. But even in less
emotional contexts, change and time are hard.  A lot of us here
— a lot of people in IT generally — began in other
fields and got into IT through specific application domains, so I
can’t be the only person here who has trained in another field
but occasionally reads computer science textbooks.  And so I doubt
that I’m the only one who has been struck by the contortions
that formal descriptions of Turing machines go through to explain the
change of state in a Turing machine or even a finite state automaton.
A completely informal introduction to Turing machines has no problem
with this topic at all, 
but any skilled mathematician trying to provide a more
careful description will bend over backwards to
avoid talking about time or change of any kind.  They will begin
with an
elaborate description, completely static, of the state of a Turing
machine.  They will then develop an elaborate 
rule for comparing
two Turing machine states so as to determine 
where they differ and where they resemble each
other.  And finally they will describe the construction of
sequences of Turing machine states, each adjacent pair
of states related by a similarity relation based on
the rule for comparison, to ensure that any two 
adjacent states are similar in all but exactly one way.  
They may spend pages and pages
— or worse only half a page, in compressed
and laconic form, with no explanation,
motivation, or guidance — all in order
to avoid saying </textual><quote class="po-inline e36 e36"><textual class="po-textual">The machine changes state</textual></quote><textual class="po-textual">.
Why?
Because our formal systems just don’t deal well with 
change.</textual><footnote class="po-popup e37 e37"><para class="po-block e38 e38"><textual class="po-textual">Or,
at least, some of our formal systems don't, 
logic and philosophy prominent among them.  
Oddly enough, mathematics
has no particular trouble with this, or at least hasn’t since
Newton showed how to do describe change mathematically; 
before Newton, it was apparently just as bad for
straight math as for logic today.</textual></para></footnote><textual class="po-textual">
I submit to you that at least
some of the difficulties Claus Huitfeldt reported on,
some of the objections philosophers have raised against 
viewing documents as timed
abstract objects (or against timed abstract objects
more generally) stem from to
this weakness in our formal systems:  their inability to accept change
[</textual><xref class="po-milestone e39 e39" linkend="h900p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]. </textual></para><para class="po-block e40 e40"><textual class="po-textual">Unfortunately, the difference between change and stability is
one we cannot get away with ignoring, because the difference between
change and stability, and the relation between them, are in some sense
at the heart of the idea of descriptive markup. Years ago, computer
scientists at the University of Waterloo wrote a paper that was
distributed in manuscript — distributed fairly widely but never
published in this form — that said among other things the
critique of SGML and the critique in particular of the ontological
pretensions of SGML theorists. And in that draft, the author, Darrell
Raymond said:</textual></para><blockquote class="po-container e41 e41"><para class="po-block e42 e42"><textual class="po-textual">Yes, descriptive markup rescues authors from the frying pan of typography only to hurl them headlong into the hellfire of ontology.</textual></para><attribution class="po-block e43 e43"><textual class="po-textual">[</textual><xref class="po-milestone e44 e44" linkend="Raymond"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]</textual></attribution></blockquote><para class="po-block e45 e45"><textual class="po-textual">We might well ask how that happened. Why did ontology suddenly
break out as an area of concern in the slightly unexpected province of
technical publication? And I would like to suggest a possible answer
to you.</textual><footnote class="po-popup e46 e46"><para class="po-block e47 e47"><textual class="po-textual">I should point out that the discussion of the
change and stability in technical publishing offered
here is a kind of Just-So story about the origins
of descriptive markup intended to illustrate the
relevance of change and stability to descriptive markup,
and vice versa.  It is not intended and should not be 
taken as a full historical account of all the issues
on the minds of those who developed the idea of
descriptive markup or the SGML specification.</textual></para></footnote><textual class="po-textual">
Put yourself in the position of the tech publishing managers
who were struggling to develop the concepts which we now know as
descriptive markup and which became SGML — generic coding and
then SGML and then XML. They are perfectly aware that when they print
manuals this week or this month for this year’s release of the
operating system, chapter titles will be in a particular font-face
— they will be Garamond 16 point on 18 demi-bold with a 7 quad
vertical jump and a horizontal rule and so forth. But they are also
acutely aware that that’s not essential. That that’s not
a permanent part of the document. They’re acutely aware because
they are involved in the design decisions, and they know perfectly
well that some people really hate Garamond, and it may change. And
they are also acutely aware that changing that kind of thing manually
is extremely expensive, so they want a way to encode the document that
won’t require manual change every time the style changes
because style is part of their professional identity. They know
perfectly well that style changes. They know perfectly well that when
the big new version of the operating system comes out eighteen months
from now, they’re going to have a ground up redesign of the
entire technical library. There will be a new look; they don’t
what it’s going to be because the contact hasn’t been issued yet, but etc., etc.</textual></para><para class="po-block e48 e48"><textual class="po-textual">So we want a way to represent a document that will work for the
styles we’ve got now and for the styles we’re going to
have in eighteen months with the new big release. How do we do that?
Well, we need to find some aspect of the document to call out that can
be related to the styling and that’s not going to change. The
style is going to change, and the kind of processing we’re
going to do with the document may change. (In the early 80’s
not everybody had a well-developed expectation of being able to do
full-text searching and build things other than printed pages from
documents, but a lot of people knew it was possible even if they
didn’t have software to do it themselves, and they had fond
hopes.) The one thing that’s not going to change between now
and eighteen months from now is the structure of the sentence:
</textual><quote class="po-inline e49 e49"><textual class="po-textual">we want it to be 16 on 18 Garamond demi-bold because
it’s a chapter title.</textual></quote><textual class="po-textual"> Everything in that sentence is
going to change except </textual><quote class="po-inline e50 e50"><textual class="po-textual">We want it to be [styled in a certain
way] because it’s a chapter title.</textual></quote><textual class="po-textual"> Our ideas about what
we think this part of the document </textual><emphasis class="po-inline e51 e51"><textual class="po-textual">is</textual></emphasis><textual class="po-textual"> are going
to change more slowly, maybe not at all. But at least they’re
going to change more slowly than what we do with this piece of the
document. It is natural, then that any effort to produce reusable
document representations is going to push us a little bit toward
ontology, toward a statement of what the thing is and not what we want
to do with it.</textual></para><para class="po-block e52 e52"><textual class="po-textual">Now, it’s possible to over-emphasize the ontological
pretensions of descriptive markup, and I’m sure that many of us
who got enthusiastic about SGML in the 1980’s did so. But there
are philosophers who tell us almost no statements are really permanent in the way I have just described.
The American philosopher W.V.O. Quine spent much of his
career attacking what is called the analytic/synthetic
distinction.  That is the common philosophical doctrine that some
sentences are true by virtue of the definition of the terms [</textual><xref class="po-milestone e53 e53" linkend="Quine1951"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]. For example, consider the sentences
</textual><quote class="po-inline e54 e54"><textual class="po-textual">A bachelor is an unmarried man,</textual></quote><textual class="po-textual">
or </textual><quote class="po-inline e55 e55"><textual class="po-textual">a spinster is an unmarried woman.</textual></quote><textual class="po-textual"> The
standard analysis in terms of the analytic/synthetic
distinction says that these sentences say nothing at all
abut the real world, and so no empirical observation of
the real world can possibly render them true or false.
They are not </textual><emphasis class="po-inline e56 e56"><textual class="po-textual">about</textual></emphasis><textual class="po-textual"> the real world;
they are about the definitions of terms in our language. 
Sentences like these are true or false because 
of the meanings of their words and not because of any
state of affairs in the real world.
By contrast, the sentence </textual><quote class="po-inline e57 e57"><textual class="po-textual">Joe is a bachelor</textual></quote><textual class="po-textual"> is an
empirical or synthetic statement and is true or false 
depending not just on the meanings of the words 
</textual><quote class="po-inline e58 e58"><textual class="po-textual">Joe</textual></quote><textual class="po-textual"> and </textual><quote class="po-inline e59 e59"><textual class="po-textual">is</textual></quote><textual class="po-textual"> and </textual><quote class="po-inline e60 e60"><textual class="po-textual">bachelor</textual></quote><textual class="po-textual">
but on whether in fact Joe is or is not married.
Quine said, No, no, no, no. There’s no such bright line
between analytic statements and synthetic statements; there is only a
spectrum between sentences whose truth values we are ready to revise
at a moment’s notice, and sentences whose truth values we are
not so ready to revise.  Our beliefs about the
world, Quine argued,
do not face the tribunal of experience singly, but as a
corporate body. This is 
certainly true in every
formalization of logic I’ve ever seen; if you have a
contradiction in a set of statements, you don’t know which
statement to remove in order to remove the contradiction, and quite
often you have a choice. Just take the simple case: </textual><quote class="po-inline e61 e61"><textual class="po-textual">P</textual></quote><textual class="po-textual">
and </textual><quote class="po-inline e62 e62"><textual class="po-textual">not P.</textual></quote><textual class="po-textual"> Well, we can make that set consistent by
dropping </textual><quote class="po-inline e63 e63"><textual class="po-textual">not P,</textual></quote><textual class="po-textual"> or we can make it consistent by
dropping </textual><quote class="po-inline e64 e64"><textual class="po-textual">P.</textual></quote><textual class="po-textual"> There’s no </textual><emphasis class="po-inline e65 e65" role="ital"><textual class="po-textual">a
priori</textual></emphasis><textual class="po-textual"> distinction.</textual></para><para class="po-block e66 e66"><textual class="po-textual">Quine said what we call the truths of logic are just the
sentences that we are going to throw to the wolves last. 
If, one fine morning in the physics lab, the data 
from our physical measurements don't
match the expected values, we are prepared to accept 
the proposition that we must have
misread the dial on the instrument.
We resolve to be more careful.
If it happens again the next day and the next,
however, then it becomes harder and harder to believe 
that we have misread the dial so consistently, 
and we begin to think the machine may be out of calibration.
And if the evidence mounts up, we may be willing to consider the
possibility that the machine is actually not measuring what we thought
it was measuring, it’s broken completely, or it’s based
on a wrong physical theory, and it never measured anything. Those are
progressively harder and harder to accept because they involve the
revision of more and more of our world view, but on
Quine's account nothing is sacred, and no part of our
belief system is immune to revision. 
Perhaps that’s the level of ontological commitment that
we can safely make for good descriptive markup: 
It’s not sacred, but it's one of the
parts of our worldview we are least likely to 
change in the normal course of events.
It’s 
useful to say </textual><quote class="po-inline e67 e67"><textual class="po-textual">Call things what they are,</textual></quote><textual class="po-textual"> but
it’s also easy to tie ourselves in knots over the philosophical
questions of what things really are and what things do we believe
really exist. You can build a lot of good practical systems by
dialing that back a little bit and asking instead 
</textual><quote class="po-inline e68 e68"><textual class="po-textual">What do we think
we’re going to think this is, over the course
of the next five
years?</textual></quote></para><para class="po-block e69 e69"><textual class="po-textual">Steven Pemberton showed us the other day that such conceptual
change is not unique to documents. The same problem arises in other
areas. He told us, remember, about an abstraction error in early C
and Unix — the conflation of the notion of character with the
fundamental unit of storage [</textual><xref class="po-milestone e70 e70" linkend="t245p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]. Why is that an
abstraction error? It’s an abstraction error because our
concept of character changes at a different rate from our
implementation of character representation. Implementations, we
know, are going to change a lot, and our concepts change much more
slowly. It’s not that our concepts never change, but they change much
more slowly. It’s an abstraction error to conflate things that
have different rates of change; ultimately, they shear apart, giving
us the technological or conceptual equivalent of
Africa on the one side and South America on the other, 
and like continents our concepts can
drift pretty far apart as time goes by.</textual></para><para class="po-block e71 e71"><textual class="po-textual">What won’t change in the short term are the things we
care about. And what some of us care about may not be what other
people care about. That’s one of the reasons we want
user-definable vocabularies. Sometimes those of us who 
drank the descriptive markup Kool-aid
in the 1980’s may find it extremely counterintuitive
to see that what some people care about is not the logical
structure of the document but the design.
Dianne Kennedy talked to us early in the conference
about the PRISM Source Vocabulary [</textual><xref class="po-milestone e72 e72" linkend="t1145p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">],
which demonstrates conclusively that a sufficiently 
general idea like descriptive markup can be applied in
ways that go well beyond what the original designers
may have had in mind.</textual></para><para class="po-block e73 e73"><textual class="po-textual">Some papers at this conference provide striking illustrations of
just how far we’ve come as a community towards being able to
build whole systems based on standards and descriptive
markup, like Anne Brüggemann-Klein’s paper yesterday about
leveraging XML technology for web applications [</textual><xref class="po-milestone e74 e74" linkend="h445r"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e75 e75"><textual class="po-textual">Even after we relativize the idea in the way 
I’m suggesting, any emphasis on saying what things
are and on data longevity will lead directly to a 
consequent emphasis on getting things
right in the first place. We have to get this right because these
documents are going to be around for a long time.
We’re constructing documents and document
systems for longevity, and if we succeed we are going to
have to live with what we say for a long time. Quality assurance
takes on even more importance in this context than it might
otherwise do. This year's program has had a remarkable 
emphasis on quality
assurance — not just in the pre-conference
symposium on Monday about quality assurance,
but also throughout the conference proper. 
On Monday morning, Dale Waldt gave a general overview 
of the issues, stressing among other things
that you don’t do quality assurance last if you want to have
good quality assurance; you need to push it up-stream as far as
possible [</textual><xref class="po-milestone e76 e76" linkend="m910"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e77 e77"><textual class="po-textual">Wei Zhao and Jeff Beck and their colleagues provided wonderful
descriptions of QA practices in large aggregators like the Ontario
Scholars Portal or PubMed Central. Such aggregators are constrained to
accept input from a wide variety of sources with wide variations in
quality, but they try to produce unified interfaces. So the
aggregators need to try to level the quality by bringing up the lower
bound [</textual><xref class="po-milestone e78 e78" linkend="m1100"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">, </textual><xref class="po-milestone e79 e79" linkend="m1140"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e80 e80"><textual class="po-textual">Keith Rose and Tamara Stoker provided an
inspiring view of what can be done inside a publishing organization when it sets its mind to improve the quality of its data [</textual><xref class="po-milestone e81 e81" linkend="m1220"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].  They were talking about the American Chemical Society, but a lot of what they said could be applied anywhere.</textual></para><para class="po-block e82 e82"><textual class="po-textual">Also on Monday, Charlie Halpern-Hamu gave us a wonderful synoptic overview of a whole sampler of techniques for quality assurance in document projects. </textual><xref class="po-milestone e83 e83" linkend="m245"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].  At least one person was overheard leaving the room saying, </textual><quote class="po-inline e84 e84"><textual class="po-textual">Well, </textual><emphasis class="po-inline e85 e85" role="ital"><textual class="po-textual">that</textual></emphasis><textual class="po-textual"> changes my schedule for next week; that project is going to be redesigned because those techniques will work better for us thatn what we are doing now.</textual></quote></para><para class="po-block e86 e86"><textual class="po-textual">If you want to take quality seriously, you need quality
assurance not just on your data but on other parts of your system.
Eric van der Vlist spoke to us Monday morning about applying quality
assurance not to documents, but using documents to apply quality
assurance to the schemas that we use to validate the documents [</textual><xref class="po-milestone e87 e87" linkend="m950"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e88 e88"><textual class="po-textual">Sheila Morrissey and her colleagues at Portico showed how they extend their focus from the data that they are preserving to the systems they are using to preserve the data [</textual><xref class="po-milestone e89 e89" linkend="m200"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">], and Jorge Williams, in the conference itself, pointed our tools in yet another direction, to validate not deployment packages, but whole RESTful services [</textual><xref class="po-milestone e90 e90" linkend="w900r"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e91 e91"><textual class="po-textual">historically, one of the most important tools in quality
assurance for descriptive markup has been the document grammar and
validation against a schema. The great promise of syntactic validation
both in SGML DTDs and before it in things like the invention of BNF in
the definition of Algol 60 is that it enables the automatic detection
of certain classes of errors. It’s easy to forget that careful
people never promised that automatic detection based on clean syntax
definitions would detect all errors. The value proposition has always
been: when a large class of errors can be detected automatically, it
becomes possible to concentrate expensive, human eyeball resources on
the class of errors that cannot be detected automatically. It’s
easy to think </textual><quote class="po-inline e92 e92"><textual class="po-textual">Oh, gosh, if validation doesn’t catch all
errors, so you still have to have eyeballs, then surely automatic
validation is pointless.</textual></quote><textual class="po-textual"> I think if experience shows that
it’s better to find things automatically if possible, because
it’s cheaper, but that no organization that cares about data
quality can plan to do without human eyeballs entirely. And, of
course, if you don’t actually plan to have any humans looking
at your data, ever, why are you working with it in the first
place?</textual></para><para class="po-block e93 e93"><textual class="po-textual">When thinking about automatic validation, it’s always
tempting to go for more power, but like all error detection,
validation involves a trade-off between power or completeness of
checking and cost. More power in a validation language is not always
an improvement, because the more powerful the validation language is,
the harder it is going to be to reason about the class of documents
accepted as valid. Turing completeness is not necessarily a
recommendation in a validation language, but it’s always
interesting to see just how far you can go in validation while keeping
things tractable. Jakub Malý’s
talk about applying OCL constraints to documents by means of
translation into Schematron shows an interesting
approach in this area [</textual><xref class="po-milestone e94 e94" linkend="h1100p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e95 e95"><textual class="po-textual">Sometimes the challenge is the complexity of the validity
function that you’re calculating, and sometimes the complexity
lies in figuring out just what the validation function is and where we
are expected to be drawing the line between okay input and not okay
input. And sometimes the challenge is figuring out which of those is
the problem that we face: is it hard because we have a complex
validation function or because we can’t figure out what the
validation function is, and how do we tell when we have solved that
problem?  Those not working in healthcare informatice might
not be able to relate to or follow all the details in 
what Kate Hamilton and Lauren Wood were telling us the other day
[</textual><xref class="po-milestone e96 e96" linkend="h1145p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">], but almost everyone can look at the 
complexity of the situation they described and suddenly feel
better about the degree of complexity in the problems we 
face in our own work.</textual></para><para class="po-block e97 e97"><textual class="po-textual">As soon as we decide we want to check things not just for
structural correctness but for veracity or at least verisimilitude, we
find ourselves skating onto the sometimes thin ice of semantics and
ontologies. As Kurt Cagle described in his paper, we will need
mechanisms for managing controlled vocabularies and developing
semantics [</textual><xref class="po-milestone e98 e98" linkend="w945r"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e99 e99"><textual class="po-textual">Predefinition of ontologies is not the only way to achieve
better semantic control of our data. Sometimes we can work bottom up;
Steve DeRose’s talk on text analytics on Monday suggested a lot
of opportunities for plausibility checking using probabilistic, or
stochastic and non-symbolic methods. </textual><xref class="po-milestone e100 e100" linkend="m345"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].
I’m always nervous about purely stochastic methods because
I’m never sure I understand what it is they’re telling
me, and I’m always afraid I’m going to make a fool of
myself by assuming that they’ve passed the Turing test when
actually I’m just talking to a modern version of Eliza. But
text analytics may help us with plausibility checking.</textual></para><para class="po-block e101 e101"><textual class="po-textual">If you’re in the realm of stochastic methods, then
you’re in the realm of sampling and exploratory data analysis
and the techniques that Micah Dubinko talked about, using XQuery to
get an overview of unfamiliar data [</textual><xref class="po-milestone e102 e102" linkend="h245p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]. Someone
hands you a USB stick and says, </textual><quote class="po-inline e103 e103"><textual class="po-textual">I need a summary. Now.</textual></quote><textual class="po-textual">
Quick! What do you do? Well, hopefully you’ve internalized the
techniques Micah Dubink described, because they will help you in that
situation.</textual></para><para class="po-block e104 e104"><textual class="po-textual">Charlie Halpern-Hamu gave a very illuminating talk on a way of
constructing a </textual><textual class="po-textual"> sample to get essentially
similar kinds of results but in the form of a particular test document
that you can use so that you have
a small sample to develop against, but it’s a good sample to
develop against because it exercises as much of your code as can
conveniently be managed, a lot more of your code than you are
otherwise going to get in a single sample [</textual><xref class="po-milestone e105 e105" linkend="w945l"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].
</textual></para><para class="po-block e106 e106"><textual class="po-textual">The topic of testing reminds us of the ongoing, never-ending
discussion between those who wish to prove software correctness by
testing (which cannot be done because tests can never prove the
absence of bugs; they can only prove the presence of bugs) and those
who would like to prove things correct by reasoning. You know,
I’m always more comfortable with code if it can be proven
correct, but I’m also uncomfortably aware that the literature
is littered with articles about people who took code that had been
proven correct and translated it to running code and ran test cases
against it. And particularly, the usual way to bring a program like
that to its knees is to hand it input that doesn’t obey the
contract you made. Yes, of course, Dijkstra’s algorithm for
calculating the greatest common denominator of two integers is going
to fail if you hand it two inputs that are not integers or not
integers within the acceptable range. But, you know, that’s what our users do: they
give us stuff that’s out of range. That’s one of the
reasons why I got interested in validation to begin with.</textual></para><para class="po-block e107 e107"><textual class="po-textual">Sometimes, as Michel Biezunski explained to us yesterday, having valid input and valid output is not enough because there is plenty of valid data that the software doesn’t actually support.  And if you want to publish e-books, take a deep breath and be prepared for the fact that you’re going to have to test e-book readers one by one [</textual><xref class="po-milestone e108 e108" linkend="h400l"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].  That’s a rude awakening for some of us, but it confronts us with the real world.</textual></para><para class="po-block e109 e109"><textual class="po-textual">Sometimes the confrontation with the real world is not quite as depressing as it was during parts of Michel’s talk.  I was very heartened by Liam Quin’s discovery that the percentage of ill-formed XML is not nearly as high as some people have suggested [</textual><xref class="po-milestone e110 e110" linkend="f1145p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].  That made me feel better, but it’s still a reality check.  13%?  Gee, I would have hoped for better than that, even in RSS.</textual></para><para class="po-block e111 e111"><textual class="po-textual">And Betty Harvey’s talk — talk about rubber
meeting the road! I hope that the specs we’re involved in
writing now are as functional and implementable twenty and twenty-five
years and thirty years from now as the specs that she showed us
implementing today [</textual><xref class="po-milestone e112 e112" linkend="f1100p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]. Yes, they look kinda
dated and quaint, but, by golly, they do still work. By golly, maybe
all the work done in the 1980s for future-proofing data did
effectively future-proof some data. That’s a really heartening
thought; I’m very grateful to Betty Harvey for bringing us that
message.</textual></para><para class="po-block e113 e113"><textual class="po-textual">Whenever you have longevity — and we should think about
this if we’re aiming at longevity — you have
maintenance issues. I’ve never done research myself, but I have
been told many times and its seems plausible — it seems
consistent with everything I’ve ever seen in real life
organizations — that the main cost of maintenance is not fixing
errors, even though fixing errors after a program is deployed is very
expensive. The main cost of maintenance is adjusting the program to
run in new environments.</textual></para><para class="po-block e114 e114"><textual class="po-textual">Now, if my thumbnail sketch of history holds any water, one of
the points of SGML and XML was to help information longevity by
recording the properties of the information that don’t change
or don’t change as fast as our processing needs. So, we might
expect that SGML and XML themselves by focusing attention on what
doesn’t change may themselves have a long life. But what we
really care about is not, in the last analysis, a long life for our
technology, but a long life for our information, and that may involve
changing the technology as we go along. Several people have mentioned
in other contexts the example of our grandfather’s ax or
Theseus’ ship; is it still the same ship after we have replaced
each plank? Is it the same ax if it's had three new handles and seven
new heads? In a passage popular among philosophers, W.V.O. Quine
describes with approval a suggestion of the philosopher Otto Neurath.
Quine says:</textual></para><blockquote class="po-container e115 e115"><para class="po-block e116 e116"><textual class="po-textual">Neurath has likened science to a boat which, if we are to rebuild it, we must rebuild plank by plank while staying afloat in it.</textual></para><attribution class="po-block e117 e117"><textual class="po-textual">[</textual><xref class="po-milestone e118 e118" linkend="Quine1960"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]</textual></attribution></blockquote><para class="po-block e119 e119"><textual class="po-textual">I haven’t thought of a better analogy for the situation
of our technology adopters, or a better explanation for their aversion
to change and risk. Many people have observed that users of technology
(as opposed to technologists and evangelists, like many of us in this
room) are famously relunctant to adopt new technology even if it is
clearly better. Why? Partly because change is painful, and partly
because change involves risk. They’re at sea in a boat, and
we’re suggesting that they take out a plank and replace it with
a better plank. That’s going to be risky. But those of us who
are afloat in SGML or XML are in that situation; if we want the ship
to stay afloat, we are going to have to replace some planks, or at
least that’s a possibility we are going to have to face.</textual></para><para class="po-block e120 e120"><textual class="po-textual">One way for technology to grow, of course, in one dimension is to become smaller in another dimension.  So, we must occasionally ask ourselves which dimensions we care about and which aspects of our technology we want to preserve, and which we’re willing to jettison.  The logic of John Cowan’s MicroXML is that by making the syntax and the spec of XML smaller, we can appeal to a larger audience; that’s a trade-off we have to consider [</textual><xref class="po-milestone e121 e121" linkend="f900p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e122 e122"><textual class="po-textual">The more traditional way to grow a technology is to add
functionality, and there the challenge is to add functionality in a
way that feels like an organic development, feels like growth, and
doesn’t feel to the technology adopters like a risky change.
The organic development of XQuery in Mary
Holstege’s talk on type introspection [</textual><xref class="po-milestone e123 e123" linkend="t945p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">] exemplifies the kind of new functionality
that will feel intuitively right to most users of the technology. 
I was similarly heartened to hear Abel Braaksma’s
discussion of higher-order functions and other functional technologies
in XSLT 3.0 [</textual><xref class="po-milestone e124 e124" linkend="f945p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]. Hervé Ruellan’s
discussion of XML entropy seems to suggest ways to develop and
evaluate compression mechanisms for marked-up documents [</textual><xref class="po-milestone e125 e125" linkend="h400r"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e126 e126"><textual class="po-textual">Sometimes the way to find new ways to do things in language is
not just to add new things, but to push what you’ve got a
little harder than some of us would otherwise have pushed it.
That’s the lesson I took from Wendell Piez’s talk on
using XSLT to parse not XML, but LMNL data [</textual><xref class="po-milestone e127 e127" linkend="w1145r"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].
If you are pushing your infrstructure hard enough, the accumulators of
XSLT 3.0 will make some things more convenient, but you don’t
always have to wait for the language developers; sometimes you can
just do it yourself.</textual></para><para class="po-block e128 e128"><textual class="po-textual">The most challenging growth path we are facing is the potential of modifying the XDM.  And I think when we look back on this year’s Balisage, many of us will remember the sequence of talks by Eric van der Vlist, Jonathan Robie, and Hans-Jürgen Rennau on different ways of adapting XDM and, with it, the specs that rely on XDM to the advent of JSON [</textual><xref class="po-milestone e129 e129" linkend="t200p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">, </textual><xref class="po-milestone e130 e130" linkend="t400p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">, </textual><xref class="po-milestone e131 e131" linkend="t445p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].  One reason to do that is to say, </textual><quote class="po-inline e132 e132"><textual class="po-textual">Well, we’re in the situation of anybody doing maintenance.  The context has changed.  There are people out there who want to use JSON; we need to be able to interoperate with them.</textual></quote></para><para class="po-block e133 e133"><textual class="po-textual">But it’s not always a question of </textual><quote class="po-inline e134 e134"><textual class="po-textual">us versus them.</textual></quote><textual class="po-textual">  Sometimes within the same institution, there will be those who want to work with XML or C++ or C-sharp, and others who want to work with different notations.  So, Ari Nordström’s example of finding ways to do things in the notation of your choice as a way of helping keep the peace within an organization is a message we can all take to heart. </textual><xref class="po-milestone e135 e135" linkend="t1100p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].  Remember:  good fences make good neighbors.</textual></para><para class="po-block e136 e136"><textual class="po-textual">The problem is not always even other people in the same
institution. Sometimes it’s we ourselves. We ourselves will
want sometimes to use one notation and sometimes to use another. There
are a million opportunities and a million choices to make; we will
need guidance in the wilderness of standards. Even if we restrict
ourselves to standards and recommendations, we’ll need guidance
of the kind that Maik Stührenberg and Oliver Schonefeld talked
about the other day with their web-based information system about
standards [</textual><xref class="po-milestone e137 e137" linkend="h945p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e138 e138"><textual class="po-textual">Sometimes the right form for some of our information will use the RDF model.  And we will have hybrid systems like the one described by Anna Jordanous, Alan Stanley, and Charlotte Tupman for their ancient documents [</textual><xref class="po-milestone e139 e139" linkend="w900l"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e140 e140"><textual class="po-textual">Sometimes the structure of information we want to manage fits neatly into a tree, and those of us with long memories are still so impressed with how much more powerful and interesting trees are than the one-damn-thing-after-another model of documents that preceded SGML that we are astonished that not everybody is happy with trees, and we think that everybody really ought to be content with trees.  But, thank God, some of us are professional malcontents.  So we should be grateful to those who continue pushing on the issue of overlap and finding the right way to represent our information, even when it has overlapping structures [</textual><xref class="po-milestone e141 e141" linkend="w1100r"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].</textual></para><para class="po-block e142 e142"><textual class="po-textual">Some of the most challenging areas for us when we are looking for the right way to represent our information are those that involve information of multiple kinds for different audiences.  Making information for different audiences co-exist is very difficult, often because the natural representation varies even if we’re fully aware that when we say </textual><quote class="po-inline e143 e143"><textual class="po-textual">natural representation,</textual></quote><textual class="po-textual"> we mean the one we’re most familiar with for that kind of information.</textual></para><para class="po-block e144 e144"><textual class="po-textual">That makes literate programming one of the most challenging areas that we face, but it is also one of the most important because, going back to that QA symposium on Monday, if we really want to preserve our information, it’s not just the documents we have to be able to understand and preserve, but the systems that they are built to interact with.  And so literate programming as a method of making our programs easier to understand and keeping the documentation in sync with the executable code is crucial.  So what Sam Wilmott said, yes [</textual><xref class="po-milestone e145 e145" linkend="w1145l"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].  What David Lee and Norm Walsh said, yes [</textual><xref class="po-milestone e146 e146" linkend="w200p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">, </textual><xref class="po-milestone e147 e147" linkend="w245p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].  What Matthew McCormick said, absolutely [</textual><xref class="po-milestone e148 e148" linkend="w400p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">].  And Mario Blažević’s efforts to bring back SHORTREF and make it work in an environment very different from the SGML environment for which it was originally developed [</textual><xref class="po-milestone e149 e149" linkend="w445p"><textual class="po-textual">Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao Pippo! Ciao</textual></xref><textual class="po-textual">]?  If that makes it easier to have natural notations for information, then it will help information longevity.</textual></para><para class="po-block e150 e150"><textual class="po-textual">Syntax is important.  I’m always a little nervous when people say </textual><quote class="po-inline e151 e151"><textual class="po-textual">Syntax isn’t important; it’s only semantics that’s important</textual></quote><textual class="po-textual"> because I’m acutely aware that if we don’t have agreement on syntax, it’s extremely unlikely that we will understand the semantics that the other person is trying to tell us about.  So, I think syntax is important.  But it’s not important for itself; it’s important because it enables the recording and the exchange of semantic information.</textual></para><para class="po-block e152 e152"><textual class="po-textual">In the same way, technology is important, but it’s not important for itself; it’s important because it can help us (or, in some cases, hinder us) in the pursuit of our goals.  For the technologies that we in this room care about, that often means it’s important because it helps us manage our information:  the information that courses through the veins of our institutions and societies, the information that our organizations care about or that we care about as individuals.  The right technology can help us ensure that what changes as time goes by is our technology and not the information we manage with the help of that technology.</textual></para><para class="po-block e153 e153"><textual class="po-textual">Conferences like this one are important, but they’re not important only in and for themselves, and not only for the talks that constitute the official conference program.  They’re important because they bring us together as people, and they give us the chance to engage with each other, both in the official program and in the hallways and afterwards.  When things work right, conferences help us find solutions to our technical problems.</textual></para><para class="po-block e154 e154"><textual class="po-textual">When everything goes well, conferences — or rather, the people we engage with when we attend conferences — can help us remember why we care about those technical problems:  what we care about and why we care about it.  They can help us achieve clarity in thinking about how to use our technical skills to serve particular ends, to serve the advancement or preservation of a particular technology, or the creation and management and preservation of the information that our institutions or our societies or our cultures care about, to serve the humanity that has created those institutions, those societies, that culture.</textual></para><para class="po-block e155 e155"><textual class="po-textual">Every year I learn a lot by listening to the talks at Balisage, and every year I learn a lot — or sometimes even more — by engaging with the people who attend and make Balisage what it is.  Thank you for being those people.  Thank you for coming to Balisage 2012.</textual></para><bibliography class="po-hcontainer e156 e156"><title class="po-block e157 e157"><textual class="po-textual">References</textual></title><bibliomixed class="po-block e158 e158" xml:id="h400l" xreflabel="Biezunski"><textual class="po-textual">Biezunski, Michel. </textual><quote class="po-inline e159 e159"><textual class="po-textual">Moving sands: Adventures in XML e-book-land.</textual></quote><textual class="po-textual">  Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e160 e160" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e161 doi e161"><textual class="po-textual">10.4242/BalisageVol8.Biezunski01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e162 e162" xml:id="w445p" xreflabel="Blažević"><textual class="po-textual">Blažević, Mario. </textual><quote class="po-inline e163 e163"><textual class="po-textual">Extending XML with SHORTREFs specified in RELAX NG.</textual></quote><textual class="po-textual">  Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e164 e164" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e165 doi e165"><textual class="po-textual">10.4242/BalisageVol8.Blazevic01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e166 e166" xml:id="f945p" xreflabel="Braaksma"><textual class="po-textual">Braaksma, Abel. </textual><quote class="po-inline e167 e167"><textual class="po-textual">Simplifying XSLT stylesheet development using higher order functions.</textual></quote><textual class="po-textual">  Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e168 e168" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e169 doi e169"><textual class="po-textual">10.4242/BalisageVol8.Braaksma01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e170 e170" xml:id="h445r" xreflabel="Brüggemann-Klein, Hahn and Sayih"><textual class="po-textual">Brüggemann-Klein, Anne, Jose Tomas Robles Hahn and Marouane Sayih. </textual><quote class="po-inline e171 e171"><textual class="po-textual">Leveraging XML Technology for Web Applications.</textual></quote><textual class="po-textual">  Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e172 e172" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e173 doi e173"><textual class="po-textual">10.4242/BalisageVol8.Bruggemann-Klein01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e174 e174" xml:id="w945r" xreflabel="Cagle"><textual class="po-textual">Cagle, Kurt. </textual><quote class="po-inline e175 e175"><textual class="po-textual">The Ontologist: Controlled Vocabularies and Semantic Wikis.</textual></quote><textual class="po-textual">  Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e176 e176" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e177 doi e177"><textual class="po-textual">10.4242/BalisageVol8.Cagle01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e178 e178" xml:id="w1100l" xreflabel="Clark"><textual class="po-textual">Clark, Ashley. </textual><quote class="po-inline e179 e179"><textual class="po-textual">Meta-stylesheets: Exploring the Provenance of XSL Transformations.</textual></quote><textual class="po-textual">  Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e180 e180" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e181 doi e181"><textual class="po-textual">10.4242/BalisageVol8.Clark01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e182 e182" xml:id="f900p" xreflabel="Cowan"><textual class="po-textual">Cowan, John. </textual><quote class="po-inline e183 e183"><textual class="po-textual">MicroXML: Who, What, Where, When, Why.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e184 e184" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e185 doi e185"><textual class="po-textual">10.4242/BalisageVol8.Cowan01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e186 e186" xml:id="m345" xreflabel="DeRose"><textual class="po-textual">DeRose, Steven J. </textual><quote class="po-inline e187 e187"><textual class="po-textual">The structure of content.</textual></quote><textual class="po-textual">   Presented at International Symposium on Quality Assurance and Quality Control in XML, Montréal, Canada, August 6, 2012. In </textual><emphasis class="po-inline e188 e188" role="ital"><textual class="po-textual">Proceedings of the International Symposium on Quality Assurance and Quality Control in XML</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 9 (2012). doi:</textual><biblioid class="po-atom e189 doi e189"><textual class="po-textual">10.4242/BalisageVol9.DeRose01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e190 e190" xml:id="h245p" xreflabel="Dubinko"><textual class="po-textual">Dubinko, Micah. </textual><quote class="po-inline e191 e191"><textual class="po-textual">Exploring the Unknown: Understanding and navigating large XML datasets.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e192 e192" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e193 doi e193"><textual class="po-textual">10.4242/BalisageVol8.Dubinko01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e194 e194" xml:id="w400p" xreflabel="Flood, McCormick and Palmer"><textual class="po-textual">Flood, Mark D., Matthew McCormick and Nathan Palmer. </textual><quote class="po-inline e195 e195"><textual class="po-textual">Encoding Transparency: Literate Programming and Test Generation for Scientific Function Libraries.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e196 e196" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e197 doi e197"><textual class="po-textual">10.4242/BalisageVol8.Flood01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e198 e198" xml:id="m245" xreflabel="Halpern-Hamu"><textual class="po-textual">Halpern-Hamu, Charlie. </textual><quote class="po-inline e199 e199"><textual class="po-textual">Case study: Quality assurance and quality control techniques in an XML data conversion project.</textual></quote><textual class="po-textual">   Presented at International Symposium on Quality Assurance and Quality Control in XML, Montréal, Canada, August 6, 2012. In </textual><emphasis class="po-inline e200 e200" role="ital"><textual class="po-textual">Proceedings of the International Symposium on Quality Assurance and Quality Control in XML</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 9 (2012). doi:</textual><biblioid class="po-atom e201 doi e201"><textual class="po-textual">10.4242/BalisageVol9.Halpern-Hamu01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e202 e202" xml:id="w945l" xreflabel="Halpern-Hamu"><textual class="po-textual">Halpern-Hamu, Charlie. </textual><quote class="po-inline e203 e203"><textual class="po-textual">Design considerations in the implementation of a boil-this-corpus-down-to-a-sample-document tool.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e204 e204" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e205 doi e205"><textual class="po-textual">10.4242/BalisageVol8.Halpern-Hamu02</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e206 e206" xml:id="h1145p" xreflabel="Hamilton and Wood"><textual class="po-textual">Hamilton, Kate, and Lauren Wood. </textual><quote class="po-inline e207 e207"><textual class="po-textual">Schematron in the Context of the Clinical Document Architecture (CDA).</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e208 e208" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e209 doi e209"><textual class="po-textual">10.4242/BalisageVol8.Wood01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e210 e210" xml:id="f1100p" xreflabel="Harvey"><textual class="po-textual">Harvey, Betty. </textual><quote class="po-inline e211 e211"><textual class="po-textual">Developing Low-Cost Functional Class 3 IETM.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e212 e212" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e213 doi e213"><textual class="po-textual">10.4242/BalisageVol8.Harvey01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e214 e214" xml:id="t945p" xreflabel="Holstege"><textual class="po-textual">Holstege, Mary. </textual><quote class="po-inline e215 e215"><textual class="po-textual">Type Introspection in XQuery.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e216 e216" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e217 doi e217"><textual class="po-textual">10.4242/BalisageVol8.Holstege01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e218 e218" xml:id="h900p" xreflabel="Huitfeldt, Vitali and Peroni"><textual class="po-textual">Huitfeldt, Claus, Fabio Vitali and Silvio Peroni. </textual><quote class="po-inline e219 e219"><textual class="po-textual">Documents as Timed Abstract Objects.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e220 e220" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e221 doi e221"><textual class="po-textual">10.4242/BalisageVol8.Huitfeldt01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e222 e222" xml:id="w900l" xreflabel="Jordanous, Stanley and Tupman"><textual class="po-textual">Jordanous, Anna, Alan Stanley and Charlotte Tupman. </textual><quote class="po-inline e223 e223"><textual class="po-textual">Contemporary transformation of ancient documents for recording and retrieving maximum information: when one form of markup is not enough.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e224 e224" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e225 doi e225"><textual class="po-textual">10.4242/BalisageVol8.Jordanous01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e226 e226" xml:id="m1140" xreflabel="Kelly and Beck"><textual class="po-textual">Kelly, Christopher, and Jeff Beck. </textual><quote class="po-inline e227 e227"><textual class="po-textual">Quality Control of PMC Content: A Case Study.</textual></quote><textual class="po-textual">   Presented at International Symposium on Quality Assurance and Quality Control in XML, Montréal, Canada, August 6, 2012. In </textual><emphasis class="po-inline e228 e228" role="ital"><textual class="po-textual">Proceedings of the International Symposium on Quality Assurance and Quality Control in XML</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 9 (2012). doi:</textual><biblioid class="po-atom e229 doi e229"><textual class="po-textual">10.4242/BalisageVol9.Beck01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e230 e230" xml:id="t1145p" xreflabel="Kennedy"><textual class="po-textual">Kennedy, Dianne. </textual><quote class="po-inline e231 e231"><textual class="po-textual">Finally — an XML Markup Solution for Design-Based Publishers: Introducing the PRISM Source Vocabulary.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e232 e232" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e233 doi e233"><textual class="po-textual">10.4242/BalisageVol8.Kennedy01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e234 e234" xml:id="w200p" xreflabel="Lee"><textual class="po-textual">Lee, David. </textual><quote class="po-inline e235 e235"><textual class="po-textual">CodeUp: Marking up Programming Languages and the winding road to an XML Syntax.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e236 e236" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e237 doi e237"><textual class="po-textual">10.4242/BalisageVol8.Lee01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e238 e238" xml:id="h1100p" xreflabel="Malý and Nečaský"><textual class="po-textual">Malý, Jakub, and Martin Nečaský. </textual><quote class="po-inline e239 e239"><textual class="po-textual">Utilizing new capabilities of XML languages to verify integrity constraints.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e240 e240" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e241 doi e241"><textual class="po-textual">10.4242/BalisageVol8.Maly01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e242 e242" xml:id="w1100r" xreflabel="Marcoux, Huitfeldt and Sperberg-McQueen"><textual class="po-textual">Marcoux, Yves, Claus Huitfeldt and C. M. Sperberg-McQueen. </textual><quote class="po-inline e243 e243"><textual class="po-textual">The MLCD Overlap Corpus (MOC): Project report.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e244 e244" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e245 doi e245"><textual class="po-textual">10.4242/BalisageVol8.Huitfeldt02</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e246 e246" xml:id="m200" xreflabel="Morrissey et al."><textual class="po-textual">Morrissey, Sheila M., John Meyer, Sushil Bhattarai, Gautham Kalwala, Sachin Kurdikar, Jie Ling, Matt Stoeffler and Umadevi Thanneeru. </textual><quote class="po-inline e247 e247"><textual class="po-textual">Beyond Well-Formed and Valid: QA for XML Configuration Files.</textual></quote><textual class="po-textual">   Presented at International Symposium on Quality Assurance and Quality Control in XML, Montréal, Canada, August 6, 2012. In </textual><emphasis class="po-inline e248 e248" role="ital"><textual class="po-textual">Proceedings of the International Symposium on Quality Assurance and Quality Control in XML</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 9 (2012). doi:</textual><biblioid class="po-atom e249 doi e249"><textual class="po-textual">10.4242/BalisageVol9.Morrissey01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e250 e250" xml:id="t1100p" xreflabel="Nordström"><textual class="po-textual">Nordström, Ari. </textual><quote class="po-inline e251 e251"><textual class="po-textual">Using XML to Implement XML: Or, Since XProc Is XML, Shouldn’t Everything Else Be, Too?</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e252 e252" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e253 doi e253"><textual class="po-textual">10.4242/BalisageVol8.Nordstrom01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e254 e254" xml:id="t245p" xreflabel="Pemberton"><textual class="po-textual">Pemberton, Steven. </textual><quote class="po-inline e255 e255"><textual class="po-textual">Serialisation, abstraction, and XML applications.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e256 e256" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e257 doi e257"><textual class="po-textual">10.4242/BalisageVol8.Pemberton01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e258 e258" xml:id="w1145r" xreflabel="Piez"><textual class="po-textual">Piez, Wendell. </textual><quote class="po-inline e259 e259"><textual class="po-textual">Luminescent: parsing LMNL by XSLT upconversion.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e260 e260" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e261 doi e261"><textual class="po-textual">10.4242/BalisageVol8.Piez01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e262 e262" xml:id="f1145p" xreflabel="Quin"><textual class="po-textual">Quin, Liam R. E. </textual><quote class="po-inline e263 e263"><textual class="po-textual">Characterizing ill-formed XML on the web: An analysis of the Amsterdam Corpus by document type.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e264 e264" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e265 doi e265"><textual class="po-textual">10.4242/BalisageVol8.Quin01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e266 e266" xml:id="Quine1951" xreflabel="Quine"><textual class="po-textual">Quine, Willard Van Orgman. </textual><quote class="po-inline e267 e267"><textual class="po-textual">Two dogmas of empiricism.</textual></quote><textual class="po-textual"> </textual><emphasis class="po-inline e268 e268" role="ital"><textual class="po-textual">The Philosophical Review</textual></emphasis><textual class="po-textual"> 60 (1951):20-43. Reprinted in W.V.O. Quine. </textual><emphasis class="po-inline e269 e269" role="ital"><textual class="po-textual">From a Logical Point of View</textual></emphasis><textual class="po-textual">. Harvard University Press, 1953; second, revised, edition 1961.</textual></bibliomixed><bibliomixed class="po-block e270 e270" xml:id="Quine1960" xreflabel="Quine"><textual class="po-textual">Quine, Willard Van Orgman. </textual><emphasis class="po-inline e271 e271" role="ital"><textual class="po-textual">Word and Object</textual></emphasis><textual class="po-textual">. Cambridge, MA:  MITS Press, 1960 [pages 3-5].</textual></bibliomixed><bibliomixed class="po-block e272 e272" xml:id="Raymond" xreflabel="Raymond, Tompa and Wood"><textual class="po-textual">Raymond, Darrell, Frank Tompa and Derick Wood. </textual><quote class="po-inline e273 e273"><textual class="po-textual">From Data Representation to Data Model: Meta-Semantic Issues in the Evolution of SGML.</textual></quote><textual class="po-textual"> </textual><emphasis class="po-inline e274 e274" role="ital"><textual class="po-textual">Computer Standards &amp; Interfaces</textual></emphasis><textual class="po-textual"> 18 (1996): 25-36.</textual></bibliomixed><bibliomixed class="po-block e275 e275" xml:id="t445p" xreflabel="Rennau"><textual class="po-textual">Rennau, Hans-Jürgen. </textual><quote class="po-inline e276 e276"><textual class="po-textual">From XML to UDL: a unified document language, supporting multiple markup languages.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e277 e277" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e278 doi e278"><textual class="po-textual">10.4242/BalisageVol8.Rennau01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e279 e279" xml:id="t400p" xreflabel="Robie"><textual class="po-textual">Robie, Jonathan. </textual><quote class="po-inline e280 e280"><textual class="po-textual">XQuery, XSLT and JSON: Adapting the XML stack for a world of XML, HTML, JSON and JavaScript.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e281 e281" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e282 doi e282"><textual class="po-textual">10.4242/BalisageVol8.Robie01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e283 e283" xml:id="h400r" xreflabel="Ruellan"><textual class="po-textual">Ruellan, Hervé. </textual><quote class="po-inline e284 e284"><textual class="po-textual">XML Entropy Study.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e285 e285" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e286 doi e286"><textual class="po-textual">10.4242/BalisageVol8.Ruellan01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e287 e287" xml:id="m1220" xreflabel="Stoker and Rose"><textual class="po-textual">Stoker, Tamara, and Keith Rose. </textual><quote class="po-inline e288 e288"><textual class="po-textual">ACS Publications — Ensuring XML Quality.</textual></quote><textual class="po-textual">   Presented at International Symposium on Quality Assurance and Quality Control in XML, Montréal, Canada, August 6, 2012. In </textual><emphasis class="po-inline e289 e289" role="ital"><textual class="po-textual">Proceedings of the International Symposium on Quality Assurance and Quality Control in XML</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 9 (2012). doi:</textual><biblioid class="po-atom e290 doi e290"><textual class="po-textual">10.4242/BalisageVol9.Rose01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e291 e291" xml:id="h945p" xreflabel="Stührenberg, Schonefeld and Witt"><textual class="po-textual">Stührenberg, Maik, Oliver Schonefeld and Andreas Witt. </textual><quote class="po-inline e292 e292"><textual class="po-textual">A standards-related web-based information system.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e293 e293" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e294 doi e294"><textual class="po-textual">10.4242/BalisageVol8.Stuhrenberg01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e295 e295" xml:id="t915p" xreflabel="Usdin"><textual class="po-textual">Usdin, B. Tommie. </textual><quote class="po-inline e296 e296"><textual class="po-textual">Things change, or, the `real meaning’ of technical terms.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e297 e297" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e298 doi e298"><textual class="po-textual">10.4242/BalisageVol8.Usdin01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e299 e299" xml:id="m910" xreflabel="Waldt"><textual class="po-textual">Waldt, Dale. </textual><quote class="po-inline e300 e300"><textual class="po-textual">Quality assurance in the XML world: Beyond validation.</textual></quote><textual class="po-textual">   Presented at International Symposium on Quality Assurance and Quality Control in XML, Montréal, Canada, August 6, 2012. In </textual><emphasis class="po-inline e301 e301" role="ital"><textual class="po-textual">Proceedings of the International Symposium on Quality Assurance and Quality Control in XML</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 9 (2012). doi:</textual><biblioid class="po-atom e302 doi e302"><textual class="po-textual">10.4242/BalisageVol9.Waldt01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e303 e303" xml:id="w245p" xreflabel="Walsh"><textual class="po-textual">Walsh, Norman. </textual><quote class="po-inline e304 e304"><textual class="po-textual">On XML Languages….</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e305 e305" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e306 doi e306"><textual class="po-textual">10.4242/BalisageVol8.Walsh01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e307 e307" xml:id="w900r" xreflabel="Williams and Cramer"><textual class="po-textual">Williams, Jorge Luis, and David Cramer. </textual><quote class="po-inline e308 e308"><textual class="po-textual">Using XProc, XSLT 2.0, and XSD 1.1 to validate RESTful services.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e309 e309" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e310 doi e310"><textual class="po-textual">10.4242/BalisageVol8.Williams01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e311 e311" xml:id="w1145l" xreflabel="Wilmott"><textual class="po-textual">Wilmott, Sam. </textual><quote class="po-inline e312 e312"><textual class="po-textual">Literate Programming: A Case Study and Observations.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e313 e313" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e314 doi e314"><textual class="po-textual">10.4242/BalisageVol8.Wilmott01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e315 e315" xml:id="t200p" xreflabel="van der Vlist"><textual class="po-textual">van der Vlist, Eric. </textual><quote class="po-inline e316 e316"><textual class="po-textual">Fleshing the XDM chimera.</textual></quote><textual class="po-textual">   Presented at Balisage: The Markup Conference 2012, Montréal, Canada, August 7 - 10, 2012. In </textual><emphasis class="po-inline e317 e317" role="ital"><textual class="po-textual">Proceedings of Balisage: The Markup Conference 2012</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 8 (2012). doi:</textual><biblioid class="po-atom e318 doi e318"><textual class="po-textual">10.4242/BalisageVol8.Vlist01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e319 e319" xml:id="m950" xreflabel="van der Vlist"><textual class="po-textual">van der Vlist, Eric. </textual><quote class="po-inline e320 e320"><textual class="po-textual">XML instances to validate XML schemas.</textual></quote><textual class="po-textual">   Presented at International Symposium on Quality Assurance and Quality Control in XML, Montréal, Canada, August 6, 2012. In </textual><emphasis class="po-inline e321 e321" role="ital"><textual class="po-textual">Proceedings of the International Symposium on Quality Assurance and Quality Control in XML</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 9 (2012). doi:</textual><biblioid class="po-atom e322 doi e322"><textual class="po-textual">10.4242/BalisageVol9.Vlist02</textual></biblioid><textual class="po-textual">.</textual></bibliomixed><bibliomixed class="po-block e323 e323" xml:id="m1100" xreflabel="Zhao, Chengan and Bai"><textual class="po-textual">Zhao, Wei, Jayanthy Chengan and Agnes Bai. </textual><quote class="po-inline e324 e324"><textual class="po-textual">Quality Control Practice for Scholars Portal, an XML-based E-journals Repository.</textual></quote><textual class="po-textual">   Presented at International Symposium on Quality Assurance and Quality Control in XML, Montréal, Canada, August 6, 2012. In </textual><emphasis class="po-inline e325 e325" role="ital"><textual class="po-textual">Proceedings of the International Symposium on Quality Assurance and Quality Control in XML</textual></emphasis><textual class="po-textual">. Balisage Series on Markup Technologies, vol. 9 (2012). doi:</textual><biblioid class="po-atom e326 doi e326"><textual class="po-textual">10.4242/BalisageVol9.Zhao01</textual></biblioid><textual class="po-textual">.</textual></bibliomixed></bibliography></article></classedDocument>