<div id="mainContainerTOC">
   <div id="mainContainerTitleTOC" onclick="$('#mainContainerEntriesTOC').toggle('1000');">Table of Content</div>
   <div id="mainContainerEntriesTOC" style="display:none;">
      <div class="headedContainerTOC">
         <div class="headedContainerTitleTOC"><a href="#GrammardrivenMarkupGenerationANCHOR" name="GrammardrivenMarkupGenerationTOC">Grammar-driven Markup Generation</a></div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#Introduction%0A%0AANCHOR" name="Introduction%0A%0ATOC"> Introduction
                  
                  </a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#Example%0AANCHOR" name="Example%0ATOC"> Example 
                  </a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#DesignandImplementation%0A%0AANCHOR" name="DesignandImplementation%0A%0ATOC"> Design and Implementation
                  
                  </a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#Results%0A%0AANCHOR" name="Results%0A%0ATOC"> Results
                  
                  </a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#RelatedWork%0A%0AANCHOR" name="RelatedWork%0A%0ATOC"> Related Work
                  
                  </a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#Sampleimplementation%0A%0AANCHOR" name="Sampleimplementation%0A%0ATOC">Sample implementation
                  
                  </a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#BibliographyANCHOR" name="BibliographyTOC">Bibliography</a></div>
         </div>
      </div>
   </div>
</div>
<div id="mainContainerTERMS">
   <div id="mainContainerTitleTERMS" onclick="$('#mainContainerEntriesTERMS').toggle('1000')">Index of Terms</div>
   <div id="mainContainerEntriesTERMS" style="display:none;">
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">a</div>
         <div class="singletermTERMS">After</div>
         <div class="singletermTERMS">acknowledgements</div>
         <div class="singletermTERMS">appendix</div>
         <div class="singletermTERMS">article</div>
         <div class="singletermTERMS">a later section</div>
         <div class="singletermTERMS">automatic markup</div>
         <div class="singletermTERMS">Automata Studies, Princeton Univ. Press</div>
         <div class="singletermTERMS">August 3 - 6, 2010</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">b</div>
         <div class="singletermTERMS">bibliography</div>
         <div class="singletermTERMS">Balisage: The Markup Conference 2010</div>
         <div class="singletermTERMS">Blažević</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">c</div>
         <div class="singletermTERMS">chapter</div>
         <div class="singletermTERMS">colophon</div>
         <div class="singletermTERMS">context</div>
         <div class="singletermTERMS">contextually required elements</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">d</div>
         <div class="singletermTERMS">document</div>
         <div class="singletermTERMS">dedication</div>
         <div class="singletermTERMS">derivative.start-anew</div>
         <div class="singletermTERMS">derivative.start-nested</div>
         <div class="singletermTERMS">derivative.proceed-with</div>
         <div class="singletermTERMS">derivative.ensure-inside</div>
         <div class="singletermTERMS">derivative.ensure-outside</div>
         <div class="singletermTERMS">depth</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">e</div>
         <div class="singletermTERMS">example</div>
         <div class="singletermTERMS">element-name</div>
         <div class="singletermTERMS">extended syntax-directed translation schema</div>
         <div class="singletermTERMS">Electronic Publishing</div>
         <div class="singletermTERMS">Extreme Markup Languages</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">f</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">g</div>
         <div class="singletermTERMS">glossary</div>
         <div class="singletermTERMS">group</div>
         <div class="singletermTERMS">G'</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">h</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">i</div>
         <div class="singletermTERMS">Interleave</div>
         <div class="singletermTERMS">index</div>
         <div class="singletermTERMS">i.e.</div>
         <div class="singletermTERMS">interleave</div>
         <div class="singletermTERMS">integer</div>
         <div class="singletermTERMS">IRE Transactions on Information Theory 2</div>
         <div class="singletermTERMS">International Journal on Digital Libraries</div>
         <div class="singletermTERMS">International Organization for Standardization</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">j</div>
         <div class="singletermTERMS">J. ACM 11</div>
         <div class="singletermTERMS">J. ACM 15</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">k</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">l</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">m</div>
         <div class="singletermTERMS">mblazevic@stilo.com</div>
         <div class="singletermTERMS">Mario</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">n</div>
         <div class="singletermTERMS">normalization</div>
         <div class="singletermTERMS">normalizer</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">o</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">p</div>
         <div class="singletermTERMS">preface</div>
         <div class="singletermTERMS">prereq</div>
         <div class="singletermTERMS">postreq</div>
         <div class="singletermTERMS">Prentice Hall</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">q</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">r</div>
         <div class="singletermTERMS">Result</div>
         <div class="singletermTERMS">Region</div>
         <div class="singletermTERMS">result</div>
         <div class="singletermTERMS">region-identifier</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">s</div>
         <div class="singletermTERMS">steps</div>
         <div class="singletermTERMS">S'</div>
         <div class="singletermTERMS">start-tag</div>
         <div class="singletermTERMS">syntax-directed translation schema</div>
         <div class="singletermTERMS">Senior software developer</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">t</div>
         <div class="singletermTERMS">title</div>
         <div class="singletermTERMS">toc</div>
         <div class="singletermTERMS">tree transformation grammars</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">u</div>
         <div class="singletermTERMS">unique particle contribution</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">v</div>
         <div class="singletermTERMS">Validator.hs</div>
         <div class="singletermTERMS">Vasari project</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">x</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">y</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">z</div>
      </div>
   </div>
</div>
<div id="mainContainerIML"><a name="GrammardrivenMarkupGenerationANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="article e0" version="5.0-subset Balisage-1.2">
      <div class="title e1">Grammar-driven Markup Generation</div>
      <div class="info e2">
         <div class="confgroup e3">
            <div class="conftitle e4">Balisage: The Markup Conference 2010</div>
            <div class="confdates e5">August 3 - 6, 2010</div>
         </div>
         <div class="abstract e6">
            <div class="para e7">
               This paper defines the concept of grammar-driven normalization of incomplete instances,
               sketches its implementation
               for RELAX NG schema and XML documents, and presents an example of its practical use
               for automated document
               conversion.
               
            </div>
         </div>
         <div class="author e8">
            <div class="personname e9">
               <div class="firstname e10">Mario</div>
               <div class="surname e11">Blažević</div>
            </div>
            <div class="personblurb e12">
               <div class="para e13">
                  The author has a Master's degree in Computer Science from University of Novi Sad,
                  Yugoslavia. Since moving to
                  Canada in 2000, he has been working for OmniMark Technologies, later acquired by Stilo
                  International plc.,
                  mostly in the area of markup processing and on development of the OmniMark programming
                  language.
                  
               </div>
            </div>
            <div class="email e14">mblazevic@stilo.com</div>
            <div class="affiliation e15">
               <div class="jobtitle e16">Senior software developer</div>
               <div class="orgname e17">Stilo International plc.</div>
            </div>
         </div>
         <div class="legalnotice e18">
            <div class="para e19">Copyright © 2010 by the author.  Used with
               permission.
            </div>
         </div>
      </div>
      <div class="note e20">
         <div class="programlisting e21" xml:space="preserve">
            I want to thank my colleagues Jacques Légaré, Joe Gollner, Patrick Baker, and Roy
            Amodeo for their
            valuable comments, and Stilo International for providing the initial motivation for
            the work and giving me time to
            do it properly.
            
         </div>
      </div><a name="Introduction%0A%0AANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="section e22">
         <div class="title e23"> Introduction
            
            
         </div>
         <div class="para e24">A grammar is a set of rules that describes the composition of a language. Grammars
            have existed for at least two
            and half millenia, but their use was mainly didactic. The practical applications of
            grammars started with their
            mathematical formalization in the 1950s 
            <div class="citation e25" linkend="c56"></div> and the emergence of computer programming languages
            
            <div class="citation e26" linkend="b59"></div>.
         </div>
         <div class="para e27">There are three ways to apply a grammar:</div>
         <div class="variablelist e28">
            <div class="varlistentry e29">
               <div class="term e30">Validate</div>
               <div class="listitem e31">
                  <div class="para e32">a given sentence to determine if it is grammatically correct.</div>
               </div>
            </div>
            <div class="varlistentry e33">
               <div class="term e34">Generate</div>
               <div class="listitem e35">
                  <div class="para e36">a correct sentence according to the grammar.</div>
               </div>
            </div>
            <div class="varlistentry e37">
               <div class="term e38">Parse</div>
               <div class="listitem e39">
                  <div class="para e40">a given sentence to determine its structure and constituent parts.</div>
               </div>
            </div>
         </div>
         <div class="para e41">The historical motivation for development of the theory of formal languages was to
            explain the method of
            generation of valid sentences as well as their recognition and parsing. Generative
            grammars are still an active area
            of reasearch in linguistics. In computer science, however, it is parsing that is the
            primary role of grammars; their
            use for generation of valid sentences appears to be forgotten.
         </div>
         <div class="para e42">One reason for this lack of interest in grammar-driven generation is that the problem
            is poorly defined. The
            output of a generator is a grammatically valid sentence. But what is its input, other
            than the grammar? The task of a
            parser is clearer: while its output in practice can be anything, it is usually defined
            as a parse tree of some
            form.
         </div>
         <div class="para e43">While many kinds of generator inputs are possible and interesting to contemplate,
            we shall concentrate on the
            specific task of generating a grammatically valid sentence from a sequence of tokens
            (
            <div class="emphasis e44" role="ital">i.e.</div>, terminals) allowed by the grammar. Furthermore, the generator must exactly reproduce
            any
            input that is already a grammatically valid sentence. We shall use the term 
            <div class="emphasis e45" role="ital">normalization</div> to refer to this form of sentence generation, and the term 
            <div class="emphasis e46" role="ital">normalizer</div> for the generator that performs it.
         </div>
         <div class="para e47">Given a normalizer that maps a set of token sequences 
            <div class="emphasis e48" role="ital">T</div> into a set of
            cannonical, grammatically valid sequences 
            <div class="emphasis e49" role="ital">S</div>, one can define a new language 
            <div class="emphasis e50" role="ital">S'</div> as the union of the core language 
            <div class="emphasis e51" role="ital">S</div> and the non-core
            language 
            <div class="emphasis e52" role="ital">T</div>.
         </div>
         <div class="para e53">For an actual example of this kind of language definition, we need look no further
            than SGML. An SGML parser
            performs parsing, normalization, and validation at the same time. For example, given
            the following SGML DTD that
            declares the end tag of element 
            <div class="emphasis e54" role="ital">a</div> and both tags of element 
            <div class="emphasis e55" role="ital">b</div> to be omissible:
         </div>
         <div class="programlisting e56" xml:space="preserve">
            &lt;!element a - o (b)&gt;
            &lt;!element b o o (#pcdata)&gt;
         </div>
         <div class="para e57">an SGML parser with OMITTAG feature enabled will parse the instance 
            <div class="code e58">&lt;a&gt;Hello, World!</div>
            into a syntax tree corresponding to 
            <div class="code e59">&lt;a&gt;&lt;b&gt;Hello, World!&lt;/b&gt;&lt;/a&gt;</div>. Any conformant SGML parser
            with support for omissible tags will consider these two instances as equivalent, as
            long as the same DTD is used to
            parse them. If the DTD should change, however, an instance that omits element tags
            may become not only invalid but
            unparsable.
         </div>
         <div class="para e60">For this reason and others, an XML parser does not perform any normalization. A well-formed
            XML instance is
            always parsed in the same way according to a fixed grammar, regardless of what DTD
            or schema the instance happens to
            also conform to. Various types of XML schemas are used only for validation, not for
            parsing or normalization.
         </div>
         <div class="para e61">This paper will demonstrate how an XML schema (a RELAX NG schema specifically) can
            be used to generate a valid
            instance of the schema from an invalid but well-formed XML instance. In other words,
            we shall normalize a well-formed
            XML instance so it conforms to a given schema.
         </div>
         <div class="para e62">The only element tags allowed in the input are those that occur in the target schema.
            If normalization succeeds
            with no errors, the output of the normalizer will:
         </div>
         <div class="itemizedlist e63">
            <div class="listitem e64">
               <div class="para e65">be well-formed XML,</div>
            </div>
            <div class="listitem e66">
               <div class="para e67">conform to the target schema, and</div>
            </div>
            <div class="listitem e68">
               <div class="para e69">contain the entire input instance as its subsequence, interleaved with additional
                  element tags.
                  
                  <div class="popupBox e70">
                     <div class="popupLabel" onmouseover="$('#d1e132').show('1000');" onmouseout="$('#d1e132').hide('1000');">[ footnote ]</div>
                     <div id="d1e132" style="display: none;">
                        <div class="footnote" xml:id="interleave-exception">
                           <div class="para e71">There is one exception. The normalizer may reorder those parts of the input
                              content that the target schema models as interleaved. In essence, its output will
                              conform to the target schema
                              strictified by replacing its every 
                              <div class="emphasis e72" role="ital">interleave</div> pattern node by a 
                              <div class="emphasis e73" role="ital">group</div> node.
                           </div>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div>
         </div>
         <div class="para e74">The normalizer is much more forgiving than the SGML parser in what kinds of input
            it can normalize. The target
            grammar is allowed to be ambiguous, though this is not recommended for performance
            reasons. There is no 
            <div class="emphasis e75" role="ital">unique particle contribution</div> constraint 
            <div class="citation e76" linkend="w04"></div>, nor is the generation
            restricted to 
            <div class="emphasis e77" role="ital">contextually required elements</div> 
            <div class="citation e78" linkend="s86"></div>. If the input
            instance is ambiguous, 
            <div class="emphasis e79" role="ital">i.e.</div>, there is more than one way to normalize it, the
            normalization with the least amount of added markup will be chosen. This choice is
            not made at the point when the
            particle is encountered, because the subsequent content could make that choice invalid,
            but deferred until the
            enclosing element ends. The biggest constraint is that only plain element tags with
            no attributes can be
            inserted. Even this constraint could be overcome by automatically generating some
            arbitrary grammatically correct
            values for all required attributes, but we felt that this might cause more harm than
            benefit in practice.
         </div>
         <div class="para e80">The primary purpose of SGML's minimization features was making SGML easier to author.
            We do not recommend using
            the XML normalizer in this way; we feel that it is important that every XML document
            in permanent storage should
            conform to a clearly expressed schema.
         </div>
         <div class="para e81">The legitimate place for the normalization process is inside a processing pipeline,
            where it can usefully be
            applied to or produce a transient XML document instance. Normalization can thus be
            applied before another process in
            order to transform the input document into a form easier to process. The target schema
            for the normalizer may be just
            a stricter form of the input document's schema, or it may specify additional disambiguating
            markup.
         </div>
         <div class="para e82">Alternatively, a normalizer can appear at the opposite end of the processing pipeline,
            where it ensures that the
            output of the preceding process conforms to the target schema. We shall demonstrate
            this latter possibility of
            practical use in 
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e83" linkend="Results" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">a later section</div>.
         </div>
         <div class="para e84">The rest of the paper is organized as follows: the next section will present an example
            of normalizer's use, and
            afterwards its design and implementation will be explained. The section following
            after that explains the purpose and
            results of the normalizer in production, and the paper concludes with a discussion
            of related work.
         </div>
      </div><a name="Example%0AANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="section e85">
         <div class="title e86"> Example 
            
         </div>
         <div class="para e87">This section will demonstrate the capabilities of our normalizer
            through an example. Let us take the following RELAX NG schema as our target:
         </div>
         <div class="programlisting e88" xml:space="preserve">
            start = document
            block = p | ol | ul
            
            document = element document { title, block+, section* }
            section  = element section { title, block+, section* }
            title    = element title { text }
            p        = element p { text }
            ol       = element ol { li+ }
            ul       = element ul { li+ }
            li       = element li { block+ }
         </div>
         <div class="para e89">The goal is to convert our input to a valid instance of this grammar. As for the input,
            it may start as a plain
            text file like the following one:
         </div>
         <div class="programlisting e90" xml:space="preserve">
            Normalizer test input
            
            This is a short test input for the normalizer.
            
            Purpose
            
            The purpose of this document is to demonstrate the capabilities of the normalizer.
            The normalizer is schema-driven, and it tries to fit its input into the target schema.
            
            Constraints
            
            The goal of the normalizer is to produce output that conforms to the schema, while
            
            preserving complete input. It does not always succeed:
            - A piece of input that cannot be fit into the schema will be dropped.
            - The normalizer does not attempt to conjure any required attribute values nor text
            data.
            These must be present in the input.
            
         </div>
         <div class="para e91">We first need to ensure that our input is a well-fomed XML document, which can be
            achieved simply by putting the
            entire text inside the 
            <div class="code e92">&lt;document&gt;...&lt;/document&gt;</div> tags. If we then run this XML instance
            through the normalizer, it will be converted to
         </div>
         <div class="programlisting e93" xml:space="preserve">
            &lt;document&gt;
            &lt;title&gt;&lt;/title&gt;
            &lt;p&gt;
            Normalizer test input
            
            This is a short test input for the normalizer.
            
            Purpose
            
            The purpose of this document is to demonstrate the capabilities of the normalizer.
            The normalizer is schema-driven, and it tries to fit its input into the target schema.
            
            Constraints
            
            The goal of the normalizer is to produce output that conforms to the schema, while
            
            preserving complete input. It does not always succeed:
            - A piece of input that cannot be fit into the schema will be dropped.
            - The normalizer does not attempt to conjure any required attribute values nor text
            data.
            These must be present in the input.
            &lt;/p&gt;
            &lt;/document&gt;
         </div>
         <div class="para e94">As we can verify, the output indeed does conform to the target schema. The content
            model of
            
            <div class="code e95">document</div> requires a 
            <div class="code e96">title</div> element, for example, and this element has been inserted. Since it
            has no content, though, it may not be all that useful.
         </div>
         <div class="para e97">In order to produce a more appropriate instance, we need to place certain constraints
            on the solution. One way
            to do this would be make the schema stricter. We could require the title content to
            be non-empty, and the paragraph
            content to contain no line-breaks. Alternatively, we can specify the constraints by
            adding the desired markup to the
            input document. For example, we can mark up all input lines that appear to be titles:
         </div>
         <div class="programlisting e98" xml:space="preserve">
            &lt;document&gt;
            &lt;title&gt;Normalizer test input&lt;/title&gt;
            
            This is a short test input for the normalizer.
            
            &lt;title&gt;Purpose&lt;/title&gt;
            
            The purpose of this document is to demonstrate the capabilities of the normalizer.
            The normalizer is schema-driven, and it tries to fit its input into the target schema.
            
            &lt;title&gt;Constraints&lt;/title&gt;
            
            The goal of the normalizer is to produce output that conforms to the schema, while
            
            preserving complete input. It does not always succeed:
            - A piece of input that cannot be fit into the schema will be dropped.
            - The normalizer does not attempt to conjure any required attribute values nor text
            data.
            These must be present in the input.
            &lt;/document&gt;
         </div>
         <div class="para e99">Given this enriched input together with the original schema, the normalizer produces
            the following
            output:
         </div>
         <div class="programlisting e100" xml:space="preserve">
            &lt;document&gt;
            &lt;title&gt;Normalizer test input&lt;/title&gt;
            &lt;p&gt;
            
            This is a short test input for the normalizer.
            
            &lt;/p&gt;
            &lt;section&gt;
            &lt;title&gt;Purpose&lt;/title&gt;
            &lt;p&gt;
            
            The purpose of this document is to demonstrate the capabilities of the normalizer.
            The normalizer is schema-driven, and it tries to fit its input into the target schema.
            
            &lt;/p&gt;
            &lt;section&gt;
            &lt;title&gt;Constraints&lt;/title&gt;
            &lt;p&gt;
            
            The goal of the normalizer is to produce output that conforms to the schema, while
            
            preserving complete input. It does not always succeed:
            - A piece of input that cannot be fit into the schema will be dropped.
            - The normalizer does not attempt to conjure any required attribute values nor text
            data.
            These must be present in the input.
            &lt;/p&gt;
            &lt;/section&gt;
            &lt;/section&gt;
            &lt;/document&gt;
            
         </div>
         <div class="para e101">The good news is that the normalizer has not only respected and kept our 
            <div class="code e102">title</div> markup, it has
            inferred that every title but the first one has to start a new section. The bad news
            is that the second section has
            been nested within the first one. While this does conform to the target schema, the
            two sections belong at the same
            level. Furthermore, we want every line to be a separate paragraph; and there appears
            to be a list at the end of our
            document and it should be marked up as such.
         </div>
         <div class="para e103">In this simple example we could just visually determine where each section, paragraph,
            or list item starts and
            ends and mark them up with XML element tags. In practice, however, we'd rather have
            this work done automatically. A
            simple pattern-matching rule would be capable of inserting a start tag wherever there
            is a hyphen at the beginning of
            the line, but finding where it ends is much more difficult. To make this marking-up
            process easier, the normalizer
            recognizes a number of processing instructions as output constraints. Once we apply
            them, our input document might
            look like this:
         </div>
         <div class="programlisting e104" xml:space="preserve">
            &lt;document&gt;
            &lt;title&gt;Normalizer test input&lt;/title&gt;
            
            &lt;?derivative.start-anew &lt;p&gt;?&gt;This is a short test input for the normalizer.
            
            &lt;?derivative.start-anew &lt;section&gt;?&gt;&lt;title&gt;Purpose&lt;/title&gt;
            
            &lt;?derivative.start-anew &lt;p&gt;?&gt;The purpose of this document is to demonstrate 
            the capabilities of the normalizer.
            &lt;?derivative.start-anew &lt;p&gt;?&gt;The normalizer is schema-driven, and it tries 
            to fit its input into the target schema.
            
            &lt;?derivative.start-anew &lt;section&gt;?&gt;&lt;title&gt;Constraints&lt;/title&gt;
            
            &lt;?derivative.start-anew &lt;p&gt;?&gt;The goal of the normalizer is to produce output 
            that conforms to the schema, while preserving complete input. It does not always succeed:
            &lt;?derivative.proceed-with &lt;ul&gt;?&gt;&lt;?derivative.start-anew &lt;li&gt;?&gt;
            A piece of input that cannot be fit into the schema will be dropped.
            &lt;?derivative.proceed-with &lt;ul&gt;?&gt;&lt;?derivative.start-anew &lt;li&gt;?&gt;
            The normalizer does not attempt to conjure any required attribute values nor text
            data.
            &lt;?derivative.start-anew &lt;p&gt;?&gt;These must be present in the input.
            &lt;/document&gt;
            
         </div>
         <div class="para e105">The processing instructions basically act as placeholders for element start tags,
            letting the normalizer know
            which element is supposed to enclose the following content. The exact location of
            the element's end tag will be
            inferred by the normalizer. The details of the processing instructions and the inference
            algorithm will be explained in
            the next chapter. The normalizer's output, based on our last enriched input above,
            looks as follows:
         </div>
         <div class="programlisting e106" xml:space="preserve">
            &lt;document&gt;
            &lt;title&gt;Normalizer test input&lt;/title&gt;
            &lt;p&gt;This is a short test input for the normalizer.&lt;/p&gt;
            &lt;section&gt;
            &lt;title&gt;Purpose&lt;/title&gt;
            &lt;p&gt;The purpose of this document is to demonstrate the capabilities of the normalizer.&lt;/p&gt;
            &lt;p&gt;The normalizer is schema-driven, and it tries to fit its input into the target
            schema.&lt;/p&gt;
            &lt;/section&gt;
            &lt;section&gt;
            &lt;title&gt;Constraints&lt;/title&gt;
            &lt;p&gt;The goal of the normalizer is to produce output that conforms to the schema, while
            
            preserving complete input. It does not always succeed:&lt;/p&gt;
            &lt;ul&gt;
            &lt;li&gt;
            &lt;p&gt;A piece of input that cannot be fit into the schema will be dropped.&lt;/p&gt;
            &lt;/li&gt;
            &lt;li&gt;
            &lt;p&gt;The normalizer does not attempt to conjure any required attribute values nor 
            text data.&lt;/p&gt;
            &lt;p&gt;These must be present in the input.&lt;/p&gt;
            &lt;/li&gt;
            &lt;/ul&gt;
            &lt;/section&gt;
            &lt;/document&gt;
            
         </div>
      </div><a name="DesignandImplementation%0A%0AANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="section e107">
         <div class="title e108"> Design and Implementation
            
            
         </div>
         <div class="para e109">The basic idea that drove the normalizer design came after implementing the validator
            automaton 
            <div class="citation e110" linkend="c02"></div> for RELAX NG 
            <div class="citation e111" linkend="c01"></div>. This automaton uses a flexible validation algorithm based on
            Brzozowski derivatives 
            <div class="citation e112" linkend="b64"></div>. We shall now sketch the basic idea of this validation algorithm; a
            more thorough treatment can be found in the literature 
            <div class="citation e113" linkend="a72"></div>.
         </div>
         <div class="para e114">Informally, the derivative of a grammar 
            <div class="emphasis e115" role="ital">G</div> with respect to a sequence of tokens
            
            <div class="emphasis e116" role="ital">S</div> is the grammar 
            <div class="emphasis e117" role="ital">G'</div>, such that a sequence 
            <div class="emphasis e118" role="ital">S'</div> is valid according to 
            <div class="emphasis e119" role="ital">G'</div> if and only if the concatenation
            of 
            <div class="emphasis e120" role="ital">S</div> and 
            <div class="emphasis e121" role="ital">S'</div> is valid according to 
            <div class="emphasis e122" role="ital">G</div>.
         </div>
         <div class="para e123">We can think of the grammar 
            <div class="emphasis e124" role="ital">G</div> as the initial state of a validating automaton,
            and the grammar derivative calculation as its transition function. A very simple and
            generic validator algorithm can
            be built on top of this concept 
            <div class="citation e125" linkend="s05"></div>, and one such validator is the standard RELAX NG validation
            algorithm.
         </div>
         <div class="para e126">While working on the implementation of an RELAX NG validator library 
            <div class="citation e127" linkend="s09b"></div> for OmniMark
            
            <div class="citation e128" linkend="s09a"></div>, it became clear that the automaton could be relatively easily extended in two orthogonal
            ways: with additional pattern constructs, and with additional actions to perform.
            In particular, the validating
            automaton could be modified to produce arbitrary output, in the same way a deterministic
            finite automaton can be
            extended to a Moore machine 
            <div class="citation e129" linkend="m56"></div>.
         </div>
         <div class="para e130">The original RELAX NG validation algorithm 
            <div class="citation e131" linkend="c02"></div> represents the grammar as a tree data
            structure. Here is its definition in Haskell 
            <div class="citation e132" linkend="h02"></div>:
         </div>
         <div class="programlisting e133" xml:space="preserve">
            data Pattern = Empty
            | NotAllowed
            | Text
            | Choice Pattern Pattern
            | Interleave Pattern Pattern
            | Group Pattern Pattern
            | OneOrMore Pattern
            | List Pattern
            | Data Datatype ParamList
            | DataExcept Datatype ParamList Pattern
            | Value Datatype String Context
            | Attribute NameClass Pattern
            | Element NameClass Pattern
            | After Pattern Pattern
            
         </div>
         <div class="para e134">The constructors of this data type, with the exception of the last one, correspond
            to the constructs of the
            RELAX NG schema language. The last constructor, 
            <div class="code e135">After</div>, appears when a start tag of an element is
            consumed, and matches the remainder of the XML input together with the corresponding
            end tag.
         </div>
         <div class="para e136">We need two extensions to this data structure in order to enable the automaton to
            perform normalization. First,
            we need to be able to assume the presence of an omitted element tag. Secondly, we
            must be able to output the
            normalized version of our input, together with the omitted and inferred tags. So we
            add two more data
            constructors:
         </div>
         <div class="programlisting e137" xml:space="preserve">
            data Pattern = Empty
            | ...
            | Region Bool QName Pattern
            | Result [ResultDelta] Pattern
            
            data ResultDelta = StartTag ChildNode | Add ChildNode | EndTag | Inferred ResultDelta
            
         </div>
         <div class="para e138">The 
            <div class="code e139">Result</div> constructor keeps track of the output that should be emitted if the pattern it wraps
            succeeds. Whenever the current pattern (
            <div class="emphasis e140" role="ital">i.e.</div>, the state of the automaton) has a
            
            <div class="code e141">Result</div> node at its root, the accumulated chunk of output is flushed and the root node is
            replaced by its
            child pattern.
         </div>
         <div class="para e142">The 
            <div class="code e143">Region</div> constructor denotes an open element region, which may have come from the input or
            may
            have been inserted in order to normalize it. In the former role, it acts as a replacement
            for the 
            <div class="code e144">After</div>
            node. To accomodate this change in the representation of open element regions, we
            have to make another adjustment to
            the 
            <div class="code e145">Interleave</div> constructor. It needs an extra integer field to keep track of which of its patterns
            has
            consumed unmatched start tags, and how many of them.
         </div>
         <div class="para e146">As long as the input conforms to the target schema, the normalizer acts the same way
            as the RELAX NG validator,
            except it builds the 
            <div class="code e147">Result</div> nodes and flushes them at the output. When a particle that doesn't match the
            current pattern is encountered, the normalizer attempts to recover by descending into
            the content models of elements
            that are allowed at the current point. The derivative of the current pattern is then
            the sum of derivatives of all
            content models that accept the particle, with each content derivative wrapped into
            a 
            <div class="code e148">Region</div> node and a
            
            <div class="code e149">Result</div> node; these keep track of the inferred element start tag.
         </div>
         <div class="para e150">This modification of the RELAX NG validation algorithm results in the normalizer whose
            complete source code is
            listed in the paper's appendix 
            <div class="xref e151" linkend="appendix"></div>. This simple normalizer is completely correct, but far from
            perfect. It easily runs into a combinatorial explosion of the pattern tree, and it
            cannot be customized to resolve the
            ambiguity in a desired way. While the available space is too short to describe all
            of the additional features and
            optimizations, the role of the processing instruction guides is too important to leave
            out.
         </div>
         <div class="para e152">Many interesting target schemas contain a large number of elements which have nearly
            identical content models
            and which are allowed to appear in the same places. Such is the case, for example,
            with DocBook 5 elements
            
            <div class="code e153">glossary</div>, 
            <div class="code e154">bibliography</div>, 
            <div class="code e155">index</div>, 
            <div class="code e156">toc</div>, 
            <div class="code e157">dedication</div>,
            
            <div class="code e158">acknowledgements</div>, 
            <div class="code e159">preface</div>, 
            <div class="code e160">chapter</div>, 
            <div class="code e161">appendix</div>,
            
            <div class="code e162">article</div>, and 
            <div class="code e163">colophon</div>. This represents a problem for the normalizer because it must keep
            track of all the alternative elements in case of recovery. If the user can specify
            which of the elements should be
            used for recovery, this improves the output and the performance at the same time.
         </div>
         <div class="para e164">At the moment, the normalizer accepts the following processing instructions:</div>
         <div class="itemizedlist e165">
            <div class="listitem e166">
               <div class="para e167">&lt;?
                  <div class="code e168">derivative.start-anew</div> 
                  <div class="emphasis e169" role="ital">depth</div>? 
                  <div class="emphasis e170" role="ital">start-tag</div>?&gt;
               </div>
            </div>
            <div class="listitem e171">
               <div class="para e172">&lt;?
                  <div class="code e173">derivative.start-nested</div> 
                  <div class="emphasis e174" role="ital">depth</div>? 
                  <div class="emphasis e175" role="ital">start-tag</div>?&gt;
               </div>
            </div>
            <div class="listitem e176">
               <div class="para e177">&lt;?
                  <div class="code e178">derivative.proceed-with</div> 
                  <div class="emphasis e179" role="ital">depth</div>? 
                  <div class="emphasis e180" role="ital">start-tag</div>?&gt;
               </div>
            </div>
            <div class="listitem e181">
               <div class="para e182">&lt;?
                  <div class="code e183">derivative.ensure-inside</div> 
                  <div class="emphasis e184" role="ital">element-name</div>?&gt;
               </div>
            </div>
            <div class="listitem e185">
               <div class="para e186">&lt;?
                  <div class="code e187">derivative.ensure-outside</div> 
                  <div class="emphasis e188" role="ital">element-name</div>?&gt;
               </div>
            </div>
         </div>
         <div class="para e189">where 
            <div class="emphasis e190" role="ital">depth</div> has the form 
            <div class="emphasis e191" role="ital">region-identifier</div>
            <div class="code e192">:</div>
            <div class="emphasis e193" role="ital">integer</div>.
         </div>
         <div class="para e194">Processing instructions are used instead of element tags because the input document
            has to be well-formed XML,
            so it cannot contain unmatched element start tags. Using empty element tags in a special
            namespace could cause
            difficulties because the target schema may or may not allow them in that position.
            Finally, since these instructions
            target one specific tool, the normalizer, this is an appropriate use of processing
            instructions if there ever was
            one.
         </div>
         <div class="para e195">The normalizer evaluates these processing instructions as follows:</div>
         <div class="variablelist e196">
            <div class="varlistentry e197">
               <div class="term e198">start-anew</div>
               <div class="listitem e199">
                  <div class="para e200">
                     Any existing element region that was open with the same 
                     <div class="emphasis e201" role="ital">region-identifier</div> and larger
                     or equal 
                     <div class="emphasis e202" role="ital">integer</div> depth will be closed. If 
                     <div class="emphasis e203" role="ital">depth</div> is
                     not specified, any existing element region with the same element name will be closed.
                     A new element region will be
                     started as if the specified 
                     <div class="emphasis e204" role="ital">start-tag</div> appeared instead of the instruction.
                     
                     
                  </div>
               </div>
            </div>
            <div class="varlistentry e205">
               <div class="term e206">start-nested</div>
               <div class="listitem e207">
                  <div class="para e208">
                     Any existing element region that was open with the same 
                     <div class="emphasis e209" role="ital">region-identifier</div> and larger
                     
                     <div class="emphasis e210" role="ital">integer</div> depth will be closed. A new element region will be started as if the specified
                     
                     <div class="emphasis e211" role="ital">start-tag</div> appeared instead of the instruction.
                     
                     
                  </div>
               </div>
            </div>
            <div class="varlistentry e212">
               <div class="term e213">proceed-with</div>
               <div class="listitem e214">
                  <div class="para e215">
                     Any existing element region that was open with the same 
                     <div class="emphasis e216" role="ital">region-identifier</div> and larger
                     
                     <div class="emphasis e217" role="ital">integer</div> depth will be closed. If there is an existing element region with the same
                     
                     <div class="emphasis e218" role="ital">region-identifier</div> and equal integer depth, this region is kept and nothing else
                     happens. Otherwise a new element region will be started as if the specified 
                     <div class="emphasis e219" role="ital">start-tag</div>
                     appeared instead of the instruction.
                     
                     
                  </div>
               </div>
            </div>
            <div class="varlistentry e220">
               <div class="term e221">ensure-inside</div>
               <div class="listitem e222">
                  <div class="para e223">
                     The current pattern is trimmed to leave only those possibilities which assume the
                     specified 
                     <div class="emphasis e224" role="ital">element-name</div> is currently open.
                     
                     
                  </div>
               </div>
            </div>
            <div class="varlistentry e225">
               <div class="term e226">ensure-outside</div>
               <div class="listitem e227">
                  <div class="para e228">
                     The existing schema of the remainder of the document is trimmed to leave only those
                     possibilities which assume the
                     specified 
                     <div class="emphasis e229" role="ital">element-name</div> is not currently open.
                     
                     
                  </div>
               </div>
            </div>
         </div>
      </div><a name="Results%0A%0AANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="section e230" xml:id="Results">
         <div class="title e231"> Results
            
            
         </div>
         <div class="para e232">The schema-driven normalizer described above has been implemented in the OmniMark
            programming language, to serve
            as a component in various document conversion solutions. We shall now briefly describe
            this environment in order to
            illustrate the practical benefits of the approach.
         </div>
         <div class="para e233">The wider purpose is to convert documents from a legacy presentation-oriented format
            into a semantically richer
            XML format. Some examples of the source document format are FrameMaker, HTML, InDesign,
            or Quark Xpress. The target
            format of the conversion can be DITA, DocBook, or a user-specified XML format.
         </div>
         <div class="para e234">One obvious simplification when faced with converting M source formats to N target
            formats is to introduce an
            intermediate format, and thus replace M∗N direct converters by M input converters
            to the intermediate format
            plus N output converters from the intermediate to the target format. Another benefit
            of having the intermediate
            document is that it can be enriched with user annotations to guide the output converter.
         </div>
         <div class="para e235">Experience we gained in building specific output converters showed that hand-written
            implementations were
            difficult to verify and maintain, so we needed a more robust and more flexible solution.
            Some customers required
            outputs that conform to a specialization of DITA, others wanted DocBook with various
            extensions.
         </div>
         <div class="para e236">The core of the output converters is the topic of this paper: the schema-driven normalizer.
            Its draft
            implementation, given in the appendix, was coded in Haskell and tested using the QuickCheck
            library 
            <div class="citation e237" linkend="c10"></div>. After this proof of concept, the production implementation was developed in OmniMark.
            Once the
            normalizer was ready, the old hand-coded output converters for DITA and DocBook were
            replaced with new converters in a
            matter of days.
         </div>
         <div class="para e238">Compared to the hand-written output converters they replaced, the converters based
            on the schema-driven
            normalizer provide several benefits:
         </div>
         <div class="itemizedlist e239">
            <div class="listitem e240">
               <div class="para e241">Assuming the normalizer itself is correct, the output of the converter is guaranteed
                  to be conformant to the
                  target schema. The correctness of hand-written converters' output is more difficult
                  to verify.
               </div>
            </div>
            <div class="listitem e242">
               <div class="para e243">A new target format can be supported very quickly as long as we have a schema for
                  it, while before it would
                  require rewriting the entire converter. If the new target language is a strict subset
                  of an existing one, no coding is
                  required whatsoever. For a small extension of an already supported schema, only a
                  few lines of code must be
                  added.
               </div>
            </div>
            <div class="listitem e244">
               <div class="para e245">Many users have various stylistic requirements that can be supported simply by restricting
                  the target
                  schema, with no code modifications required.
               </div>
            </div>
            <div class="listitem e246">
               <div class="para e247">The new converters are capable of automatically reordering parts of the input to make
                  it conform to the
                  target schema, with no user intervention required beyond the usual annotations. One
                  example that we have often
                  encountered in practice is that of DITA task topics: the DITA 1.1 schema requires
                  the 
                  <div class="code e248">prereq</div>,
                  
                  <div class="code e249">context</div>, 
                  <div class="code e250">steps</div>, 
                  <div class="code e251">result</div>, 
                  <div class="code e252">example</div>, and 
                  <div class="code e253">postreq</div> elements
                  to be listed in this specific order. Most existing technical documentation is not
                  written this way.
                  
                  
                  <div class="popupBox e254">
                     <div class="popupLabel" onmouseover="$('#d1e554').show('1000');" onmouseout="$('#d1e554').hide('1000');">[ footnote ]</div>
                     <div id="d1e554" style="display: none;">
                        <div class="footnote">
                           <div class="para e255">Note that this reordering transformation applies only where the target content model
                              specifies that its
                              parts can appear in any order. In case of DITA task topics, this means that we have
                              to modify the target schema so it
                              accepts the elements listed above in any order. The normalizer will output them in
                              the canonical order.
                           </div>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div>
         </div>
         <div class="para e256">One downside of the new converters is their performance, especially their worst-case
            memory consumption. The
            worst case in question is generally an input document which is annotated in a way
            that makes it non-conformant with
            the target schema. The hand-coded converters would in this situation either report
            errors (which is the desired
            behaviour) or generate invalid output (which is not). The schema-driven converters
            try to recover by inserting the
            missing element tags and by rearranging the input. The recovery eventually fails and
            the normalizer produces an error
            report, but its attempt costs a lot of time and memory. We are still looking for a
            way to fix this issue.
         </div>
      </div><a name="RelatedWork%0A%0AANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="section e257">
         <div class="title e258"> Related Work
            
            
         </div>
         <div class="para e259">Automatic grammar-driven sentence normalization has been done in linguistics, for
            the automatic correction of
            grammatically incorrect English sentences 
            <div class="citation e260" linkend="v88"></div>.
         </div>
         <div class="para e261">For markup languages, particularly XML, there has been some related work in the area
            of 
            <div class="emphasis e262" role="ital">automatic markup</div> 
            <div class="citation e263" linkend="f93"></div> 
            <div class="citation e264" linkend="k97"></div> 
            <div class="citation e265" linkend="t98"></div>. The main difference with our work is that the input of an automatic markup system
            is typically plain
            text, usually produced by OCR. As a consequence, even those automatic markup systems
            whose output schema is not fixed
            require additional configuration in form of pattern-matching rules. The normaliser
            approach presented in this paper
            can be coupled with a pattern-matching engine as well, but it does not depend on one.
         </div>
         <div class="para e266"> The automatic markup system that seems nearest to ours is the 
            <div class="emphasis e267" role="ital">Vasari project</div>
            
            <div class="citation e268" linkend="a03"></div>, which is also schema-driven to some extent. The target schema must be enriched using
            a
            special pattern-matching language which determines where the required element tags
            can be inserted. It is not clear if
            the location of every tag required by the target schema must be specified this way.
         </div>
         <div class="para e269">There is a large body of work on the automatic translation between structured documents
            that conform to similar
            schemas 
            <div class="citation e270" linkend="a72"></div> 
            <div class="citation e271" linkend="m96"></div> 
            <div class="citation e272" linkend="t03"></div>. The approaches based on the
            concept of 
            <div class="emphasis e273" role="ital">syntax-directed translation schema</div> 
            <div class="citation e274" linkend="l68"></div> and its
            extensions, such as 
            <div class="emphasis e275" role="ital">extended syntax-directed translation schema</div> 
            <div class="citation e276" linkend="k95"></div> and 
            <div class="emphasis e277" role="ital">tree transformation grammars</div> 
            <div class="citation e278" linkend="l97"></div>, seem to
            be most related to our work. The syntax-directed translation is simpler and more direct
            than our approach to
            translation, but it requires both the source and target format to be well structured.
            Our problem, quite common in
            practice, is that the source format is only weakly structured. The transformation
            process presented in this paper
            proceeds in two stages: the weakly structured source document is first translated
            into another weakly structured
            document which uses the tags allowed by the target schema. This intermediate document
            is then normalized to a valid
            schema instance.
         </div>
      </div><a name="Sampleimplementation%0A%0AANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="appendix e279" xml:id="appendix">
         <div class="title e280">Sample implementation
            
            
         </div>
         <div class="para e281">This appendix contains a sample normalizer implementation in Haskell. The implementation
            depends on the sample
            code for the RELAX NG validator 
            <div class="citation e282" linkend="c02"></div>, which it expects to find in module file
            
            <div class="code e283">Validator.hs</div>.
         </div>
         <div class="programlisting e284" xml:space="preserve">
            
            module Normalizer where
            
            import Control.Monad (liftM2)
            import Control.Exception (assert)
            import Data.List (minimumBy)
            
            -- The RELAX NG validator automaton code from http://www.thaiopensource.com/relaxng/derivative.html
            import Validator (contains, datatypeAllows, datatypeEqual, strip, whitespace,
            Uri, LocalName, ParamList, Prefix, Context, Datatype,
            NameClass(..), QName(..), ChildNode(..), AttributeNode(..))
            
            data Pattern = Empty
            | NotAllowed
            | Text
            | Choice Pattern Pattern
            | Interleave Int Pattern Pattern
            | Group Pattern Pattern
            | OneOrMore Pattern
            | List Pattern
            | Data Datatype ParamList
            | DataExcept Datatype ParamList Pattern
            | Value Datatype String Context
            | Attribute NameClass Pattern
            | Element NameClass Pattern
            | Region Bool QName Pattern
            | Result [ResultDelta] Pattern
            deriving (Eq, Show)
            
            data ResultDelta = StartTag ChildNode | Add ChildNode | EndTag | Inferred ResultDelta
            deriving (Eq, Show)
            
            nullable:: Pattern -&gt; Bool
            nullable (Group p1 p2) = nullable p1 &amp;&amp; nullable p2
            nullable (Interleave balance p1 p2) = balance == 0 &amp;&amp; nullable p1 &amp;&amp; nullable p2
            nullable (Choice p1 p2) = nullable p1 || nullable p2
            nullable (OneOrMore p) = nullable p
            nullable (Element _ _) = False
            nullable (Attribute _ _) = False
            nullable (List _) = False
            nullable (Value _ _ _) = False
            nullable (Data _ _) = False
            nullable (DataExcept _ _ _) = False
            nullable NotAllowed = False
            nullable Empty = True
            nullable Text = True
            nullable (Region False _ _) = False
            nullable (Region True _ p) = nullable p
            nullable (Result _ p) = nullable p
            
            inferred :: ResultDelta -&gt; Bool
            inferred (Inferred _) = True
            inferred _ = False
            
            nullableResults:: Pattern -&gt; [[ResultDelta]]
            nullableResults (Group p1 p2) = case nullableResults p2 of [] -&gt; []
            l -&gt; assert (all null l) (nullableResults p1)
            nullableResults (Interleave 0 p1 p2) = liftM2 (++) (nullableResults p1) (nullableResults
            p2)
            nullableResults Interleave{} = []
            nullableResults (Choice p1 p2) = nullableResults p1 ++ nullableResults p2
            nullableResults (OneOrMore p) = nullableResults p
            nullableResults (Element _ _) = []
            nullableResults (Attribute _ _) = []
            nullableResults (List _) = []
            nullableResults (Value _ _ _) = []
            nullableResults (Data _ _) = []
            nullableResults (DataExcept _ _ _) = []
            nullableResults NotAllowed = []
            nullableResults (Region False _ _) = []
            nullableResults (Region True q p) = map (++ [Inferred EndTag]) (nullableResults p)
            nullableResults Empty = [[]]
            nullableResults Text = [[]]
            nullableResults (Result r p) = map (r ++) (nullableResults p)
            
            bestNullableResult :: Pattern -&gt; [ResultDelta]
            bestNullableResult p = if nullableResults p == []
            then error ("bestNullableResult: " ++ show p)
            else minimumBy innermostLength (nullableResults p)
            where innermostLength r1 r2 = compare (length r1) (length r2)
            
            childDeriv :: Context -&gt; Pattern -&gt; ChildNode -&gt; Pattern
            childDeriv cx p (TextNode s) = textDeriv cx False p s
            childDeriv _ p (ElementNode qn cx atts children) =
            let p1 = startTagOpenDeriv p (ElementNode qn cx atts [])
            p2 = attsDeriv cx p1 atts
            p3 = startTagCloseDeriv p2
            p4 = childrenDeriv cx p3 children
            in endTagDeriv p4
            
            textDeriv :: Context -&gt; Bool -&gt; Pattern -&gt; String -&gt; Pattern
            textDeriv cx inf (Choice p1 p2) s = choice (textDeriv cx inf p1 s) (textDeriv cx inf
            p2 s)
            textDeriv cx False (Interleave 0 p1 p2) s =
            choice (interleave 0 (textDeriv cx False p1 s) p2)
            (interleave 0 p1 (textDeriv cx False p2 s))
            textDeriv cx False (Interleave balance p1 p2) s = if balance &lt; 0
            then interleave balance (textDeriv cx False p1 s) p2
            else interleave balance p1 (textDeriv cx False p2 s)
            textDeriv cx True (Interleave 0 p1 p2) s = choice
            (interleave 0 (textDeriv cx True p1 s) p2)
            (interleave 0 p1 (textDeriv cx True p2 s))
            textDeriv cx True (Interleave balance p1 p2) s = if balance &lt; 0
            then interleave balance (textDeriv cx True p1 s) p2
            else interleave balance p1 (textDeriv cx True p2 s)
            textDeriv cx inf (Group p1 p2) s = let p = group (textDeriv cx inf p1 s) p2
            in if nullable p1
            then choice p (result (bestNullableResult p1) (textDeriv cx inf p2 s))
            else p
            textDeriv cx inf (OneOrMore p) s = group (textDeriv cx inf p s) (choice (OneOrMore
            p) Empty)
            textDeriv cx inf Text s = result [(if inf then Inferred else id) (Add (TextNode s))]
            Text
            textDeriv cx1 inf (Value dt value cx2) s = if datatypeEqual dt value cx2 s cx1
            then result [(if inf then Inferred else id) (Add (TextNode s))] Empty
            else NotAllowed
            textDeriv cx inf (Data dt params) s = if datatypeAllows dt params s cx
            then result [(if inf then Inferred else id) (Add (TextNode s))] Empty
            else NotAllowed
            textDeriv cx inf (DataExcept dt params p) s =
            if datatypeAllows dt params s cx &amp;&amp; not (nullable (textDeriv cx inf p s))
            then result [(if inf then Inferred else id) (Add (TextNode s))] Empty
            else NotAllowed
            textDeriv cx inf (List p) s = if nullable (listDeriv cx p (words s))
            then result [(if inf then Inferred else id) (Add (TextNode s))] Empty
            else NotAllowed
            textDeriv cx inf (Element (Name uri local) p) s =
            let qn = QName uri local
            in region True qn (textDeriv cx inf (startRecovery qn cx p) s)
            textDeriv cx inf (Element (NameClassChoice n1 n2) p) s =
            choice (textDeriv cx inf (Element n1 p) s) (textDeriv cx inf (Element n2 p) s)
            textDeriv cx inf (Element _ _) s = NotAllowed
            textDeriv cx inf (Region inferred qn p) s = region inferred qn (textDeriv cx inf p
            s)
            textDeriv cx inf (Result r p) s = result r (textDeriv cx inf p s)
            textDeriv _ _ _ _ = NotAllowed
            
            listDeriv :: Context -&gt; Pattern -&gt; [String] -&gt; Pattern
            listDeriv _ p [] = p
            listDeriv cx p (h:t) = listDeriv cx (textDeriv cx False p h) t
            
            startRecovery :: QName -&gt; Context -&gt; Pattern -&gt; Pattern
            startRecovery qn cx p = result [Inferred (StartTag (ElementNode qn cx [] []))] (startTagCloseDeriv
            p)
            
            region :: Bool -&gt; QName -&gt; Pattern -&gt; Pattern
            region inferred qname NotAllowed = NotAllowed
            region inferred qname p = Region inferred qname p
            
            result :: [ResultDelta] -&gt; Pattern -&gt; Pattern
            result _ NotAllowed = NotAllowed
            result r (Choice p1 p2) = Choice (result r p1) (result r p2)
            result r1 (Result r2 p) = Result (r1 ++ r2) p
            result [] p = p
            result r p = Result r p
            
            addResult :: Pattern -&gt; [ResultDelta] -&gt; Pattern
            addResult NotAllowed _ = NotAllowed
            addResult (Choice p1 p2) r = Choice (addResult p1 r) (addResult p2 r)
            addResult (Group p1 p2) r = group (addResult p1 r) p2
            addResult p@(Interleave balance p1 p2) r = interleave balance (addResult p1 r) p2
            addResult (Result r1 p) r2 = result r1 (addResult p r2)
            addResult (Region inferred qn p) r = Region inferred qn (addResult p r)
            addResult p r = Result r p
            
            choice :: Pattern -&gt; Pattern -&gt; Pattern
            choice p NotAllowed = p
            choice NotAllowed p = p
            choice Empty Text = Text
            choice Text Empty = Text
            choice p1 p2 | p1 == p2 = p1
            choice p1 p2 = Choice p1 p2
            
            group :: Pattern -&gt; Pattern -&gt; Pattern
            group p NotAllowed = NotAllowed
            group NotAllowed p = NotAllowed
            group p Empty = p
            group Empty p = p
            group Text Text = Text
            group _ (Result _ _) = error "Can't have Result on the RHS of Group."
            group (Result r p1) p2 = result r (group p1 p2)
            group p1 p2 = Group p1 p2
            
            interleave :: Int -&gt; Pattern -&gt; Pattern -&gt; Pattern
            interleave _ p NotAllowed = NotAllowed
            interleave _ NotAllowed p = NotAllowed
            interleave _ p Empty = p
            interleave _ Empty p = p
            interleave _ Text Text = Text
            interleave balance p1 p2 = Interleave balance p1 p2
            
            startTagOpenDeriv :: Pattern -&gt; ChildNode -&gt; Pattern
            startTagOpenDeriv (Choice p1 p2) node = choice (startTagOpenDeriv p1 node) (startTagOpenDeriv
            p2 node)
            startTagOpenDeriv (Element (NameClassChoice n1 n2) p) node =
            choice (startTagOpenDeriv (Element n1 p) node) (startTagOpenDeriv (Element n2 p) node)
            startTagOpenDeriv (Element nc@(Name uri local) p) node@(ElementNode qn cx _ _) =
            if contains nc qn
            then Region False qn (result [StartTag node] p)
            else let qn = QName uri local
            in region True qn (startTagOpenDeriv (startRecovery qn cx p) node)
            startTagOpenDeriv (Element nc p) node@(ElementNode qn cx _ _) =
            if contains nc qn then Region False qn (result [StartTag node] p) else NotAllowed
            startTagOpenDeriv (Interleave 0 p1 p2) node =
            choice
            (interleave (-1) (startTagOpenDeriv p1 node) p2)
            (interleave 1 p1 (startTagOpenDeriv p2 node))
            startTagOpenDeriv (Interleave balance p1 p2) node =
            if balance &lt; 0
            then interleave (balance-1) (startTagOpenDeriv p1 node) p2
            else interleave (balance+1) p1 (startTagOpenDeriv p2 node)
            startTagOpenDeriv (OneOrMore p) node = group (startTagOpenDeriv p node) (choice (OneOrMore
            p) Empty)
            startTagOpenDeriv (Group p1 p2) node =
            let x = group (startTagOpenDeriv p1 node) p2
            in if nullable p1
            then choice x (result (bestNullableResult p1) (startTagOpenDeriv p2 node))
            else x
            startTagOpenDeriv (Region inferred qn p) node = region inferred qn (startTagOpenDeriv
            p node)
            startTagOpenDeriv (Result r p) node = result r (startTagOpenDeriv p node)
            startTagOpenDeriv _ _ = NotAllowed
            
            attsDeriv :: Context -&gt; Pattern -&gt; [AttributeNode] -&gt; Pattern
            attsDeriv cx p [] = p
            attsDeriv cx p ((AttributeNode qn s):t) = attsDeriv cx (attDeriv cx p (AttributeNode
            qn s)) t
            
            attDeriv :: Context -&gt; Pattern -&gt; AttributeNode -&gt; Pattern
            attDeriv cx (Choice p1 p2) att = choice (attDeriv cx p1 att) (attDeriv cx p2 att)
            attDeriv cx (Group p1 p2) att = choice (group (attDeriv cx p1 att) p2) (group p1 (attDeriv
            cx p2 att))
            attDeriv cx (Interleave balance p1 p2) att =
            choice (interleave balance (attDeriv cx p1 att) p2) (interleave balance p1 (attDeriv
            cx p2 att))
            attDeriv cx (OneOrMore p) att = group (attDeriv cx p att) (choice (OneOrMore p) Empty)
            attDeriv cx (Attribute nc p) (AttributeNode qn s) = if contains nc qn &amp;&amp; valueMatch
            cx p s 
            then Empty else NotAllowed
            attDeriv cx (Region inferred qn p) att = Region inferred qn (attDeriv cx p att)
            attDeriv cx (Result r p) att = result r (attDeriv cx p att)
            attDeriv _ _ _ = NotAllowed
            
            valueMatch :: Context -&gt; Pattern -&gt; String -&gt; Bool
            valueMatch cx p s = (nullable p &amp;&amp; whitespace s) || nullable (textDeriv cx False p
            s)
            
            startTagCloseDeriv :: Pattern -&gt; Pattern
            startTagCloseDeriv (Choice p1 p2) = choice (startTagCloseDeriv p1) (startTagCloseDeriv
            p2)
            startTagCloseDeriv (Group p1 p2) = group (startTagCloseDeriv p1) (startTagCloseDeriv
            p2)
            startTagCloseDeriv (Interleave balance p1 p2) = interleave balance (startTagCloseDeriv
            p1) (startTagCloseDeriv p2)
            startTagCloseDeriv (OneOrMore p) = oneOrMore (startTagCloseDeriv p)
            startTagCloseDeriv (Attribute _ _) = NotAllowed
            startTagCloseDeriv (Region inferred qn p) = Region inferred qn (startTagCloseDeriv
            p)
            startTagCloseDeriv (Result r p) = result r (startTagCloseDeriv p)
            startTagCloseDeriv p = p
            
            oneOrMore :: Pattern -&gt; Pattern
            oneOrMore NotAllowed = NotAllowed
            oneOrMore Empty = Empty
            oneOrMore Text = Text
            oneOrMore p@OneOrMore{} = p
            oneOrMore (Choice p Empty) = Choice (oneOrMore p) Empty
            oneOrMore (Choice Empty p) = Choice Empty (oneOrMore p)
            oneOrMore (Result r p) = result r (oneOrMore p)
            oneOrMore p = OneOrMore p
            
            childrenDeriv :: Context -&gt; Pattern -&gt; [ChildNode] -&gt; Pattern
            childrenDeriv _ NotAllowed _ = NotAllowed
            childrenDeriv cx p [] = let p1 = textDeriv cx True p ""
            in choice (addResult p [Inferred (Add (TextNode ""))]) p1
            childrenDeriv cx p [(TextNode s)] = let p1 = childDeriv cx p (TextNode s)
            in if whitespace s 
            then choice (addResult p [Add (TextNode s)]) p1 
            else p1
            childrenDeriv cx p children = stripChildrenDeriv cx p children
            
            stripChildrenDeriv :: Context -&gt; Pattern -&gt; [ChildNode] -&gt; Pattern
            stripChildrenDeriv _ p [] = p
            stripChildrenDeriv cx p (h:t) = stripChildrenDeriv cx (if strip h 
            then (addResult p [Add h]) 
            else childDeriv cx p h) t
            
            endTagDeriv :: Pattern -&gt; Pattern
            endTagDeriv (Choice p1 p2) = choice (endTagDeriv p1) (endTagDeriv p2)
            endTagDeriv (Region False qn p) = if nullable p
            then result (bestNullableResult p ++ [EndTag]) Empty
            else region False qn (endTagDeriv p)
            endTagDeriv (Region True qn p) = region True qn (endTagDeriv p)
            endTagDeriv (Result r p) = result r (endTagDeriv p)
            endTagDeriv (Group p1 p2) = group (endTagDeriv p1) p2
            endTagDeriv (Interleave balance p1 p2) | balance &lt; 0 = interleave (balance+1) (endTagDeriv
            p1) p2
            | balance == 0 = NotAllowed
            | balance &gt; 0 = interleave (balance-1) p1 (endTagDeriv p2)
            endTagDeriv _ = NotAllowed
            
            
         </div>
      </div><a name="BibliographyANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="bibliography e285">
         <div class="title e286">Bibliography</div>
         <div class="bibliomixed e287" xml:id="a72">
            AV Aho, JD Ullman, 1972.
            The Theory of Parsing, Translation, and Compiling.
            
            <div class="emphasis e288" role="ital">Prentice Hall</div>
            
         </div>
         <div class="bibliomixed e289" xml:id="a03">
            Mohammad Abolhassani, Norbert Fuhr and Norbert Gövert,
            Information extraction and automatic markup for XML documents,
            In Blanken et al, 2003, 159--174,
            Springer. doi: 
            <div class="biblioid doi e290">10.1007/978-3-540-45194-5_11</div>
            
         </div>
         <div class="bibliomixed e291" xml:id="b59">
            Backus, J.W.,
            The Syntax and Semantics of the Proposed International Algebraic Language of Zürich
            ACM-GAMM Conference,
            
            <div class="emphasis e292" role="ital">Proceedings of the International Conference on Information Processing, UNESCO</div>,
            1959, pp.125-132.
            
         </div>
         <div class="bibliomixed e293" xml:id="b64">
            Brzozowski, J. A. 1964. Derivatives of Regular Expressions. 
            <div class="emphasis e294" role="ital">J. ACM 11</div>,
            4 (Oct. 1964), 481-494.
            doi: 
            <div class="biblioid doi e295">10.1145/321239.321249</div>
            
         </div>
         <div class="bibliomixed e296" xml:id="c56">
            Chomsky, Noam (1956). "Three models for the description of language".
            
            <div class="emphasis e297" role="ital">IRE Transactions on Information Theory 2</div>: 113–124.
            doi: 
            <div class="biblioid doi e298">10.1109/TIT.1956.1056813</div>
            
         </div>
         <div class="bibliomixed e299" xml:id="c01">
            James Clark and Makoto Murata. RELAX NG Specification.
            
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e300" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">http://relaxng.org/spec-20011203.html</div>, 2001. ISO/IEC 19757-2:2003.
            
         </div>
         <div class="bibliomixed e301" xml:id="c02">
            James Clark. An algorithm for RELAX NG validation
            
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e302" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">http://www.thaiopensource.com/relaxng/derivative.html</div>
            
         </div>
         <div class="bibliomixed e303" xml:id="c10">
            QuickCheck: Automatic testing of Haskell programs
            
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e304" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">http://hackage.haskell.org/package/QuickCheck-2.1.0.3</div>
            
         </div>
         <div class="bibliomixed e305" xml:id="f93">
            Peter Fankhauser and Yi Xu,
            MarkItUp! - An incremental approach to document structure recognition,
            
            <div class="emphasis e306" role="ital">Electronic Publishing</div>, 1993, pages 447-456
            
         </div>
         <div class="bibliomixed e307" xml:id="k95">
            Eila Kuikka and Martti Penttonen,
            Transformation of Structured Documents,
            
            <div class="emphasis e308" role="ital">Electronic Publishing Origination, Dissemination and Design</div>, 8(4), 1995.
            
         </div>
         <div class="bibliomixed e309" xml:id="k97">
            Bertin Klein and Peter Fankhauser,
            Error tolerant Document Structure Analysis,
            
            <div class="emphasis e310" role="ital">International Journal on Digital Libraries</div>,
            1997, volume 1, pages 344-357.
            doi: 
            <div class="biblioid doi e311">10.1007/s007990050028</div> 
            
         </div>
         <div class="bibliomixed e312" xml:id="l68">
            Lewis, P. M. and Stearns, R. E. 1968. Syntax-Directed Transduction.
            
            <div class="emphasis e313" role="ital">J. ACM 15</div>, 3 (Jul. 1968), 465-488.
            doi: 
            <div class="biblioid doi e314">10.1145/321466.321477</div>
            
         </div>
         <div class="bibliomixed e315" xml:id="l97">
            Greger Lindén,
            Structured Document Transformations,
            1997
            
         </div>
         <div class="bibliomixed e316" xml:id="m56">
            Moore, E. F., [1956]. Gedanken experiments on sequential machines,
            
            <div class="emphasis e317" role="ital">Automata Studies, Princeton Univ. Press</div>,
            Princeton, New Jersey, pp. 129-153.
            
         </div>
         <div class="bibliomixed e318" xml:id="m96">
            Makoto Murata,
            Transformation of Documents and Schemas by Patterns and Contextual Conditions,
            
            <div class="emphasis e319" role="ital">Proceedings of the Third International Workshop on Principles of Document Processing
               (PODP 96)
            </div>,
            1997, pages 153-169, Springer-Verlag. doi: 
            <div class="biblioid doi e320">10.1007/3-540-63620-X_61</div>
            
         </div>
         <div class="bibliomixed e321" xml:id="s05">
            Sperberg-McQueen, C. M. Applications of Brzozowski derivatives to XML schema processing.
            In 
            <div class="emphasis e322" role="ital">Extreme Markup Languages</div> 2005, page 26, Internet, 2005. IDEAlliance.
            
         </div>
         <div class="bibliomixed e323" xml:id="t98">
            Kazem Taghva, Allen Condit, and Julie Borsack,
            Autotag: A tool for creating structured document collections from printed materials,
            
            <div class="emphasis e324" role="ital">Electronic Publishing, Artistic Imaging, and Digital Typography, Proc. of the EP ’98
               and RIDT
               ’98 Conferences
            </div>, 1998, pages 420-431,
            Springer-Verlag
            
         </div>
         <div class="bibliomixed e325" xml:id="t03">
            Tang, X. 2003 A High-Level Specification Language for Structured Document Transformation.
            Doctoral Thesis.
            UMI Order Number: AAINQ84932., University of Waterloo.
            
         </div>
         <div class="bibliomixed e326" xml:id="v88">
            Dénes Vargha,
            Schema method: a framework for correcting grammatically ill-formed input
            
            <div class="emphasis e327" role="ital">Proceedings of the 12th conference on Computational linguistics</div> - Volume 1
            Computer and Automation Institute, Hungarian Academy of Sciences
            Pages 341 - 347
            Association for Computational Linguistics Morristown, NJ, USA ©1988
            ISBN: 9638431563. doi: 
            <div class="biblioid doi e328">10.3115/991635.991705</div>
            
         </div>
         <div class="bibliomixed e329" xml:id="h02">
            Haskell 98 Language and Libraries, the Revised Report. December 2002.
            
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e330" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">http://haskell.org/onlinereport/</div>
            
         </div>
         <div class="bibliomixed e331" xml:id="s86">
            Standard Generalized Markup Language (SGML)
            
            <div class="emphasis e332" role="ital">International Organization for Standardization</div> ISO 8879:1986
            
         </div>
         <div class="bibliomixed e333" xml:id="s09a">
            OmniMark language documentation
            
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e334" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">http://developers.omnimark.com/docs-extract/html/index.htm</div>
            
         </div>
         <div class="bibliomixed e335" xml:id="s09b">
            OmniMark RELAX NG (OMRELAXNG) library documentation
            
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e336" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">http://developers.omnimark.com/docs-extract/html/library/125.htm</div>
            
         </div>
         <div class="bibliomixed e337" xml:id="w04">
            XML Schema Part 1: Structures Second Edition, Analysis of the Unique Particle Attribution
            Constraint
            W3C Recommendation 28 October 2004
            
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e338" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">http://www.w3.org/TR/xmlschema-1/#non-ambig</div>
            
         </div>
      </div>
   </div>
</div>