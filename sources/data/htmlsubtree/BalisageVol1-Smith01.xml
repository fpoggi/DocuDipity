<div id="mainContainerTOC">
   <div id="mainContainerTitleTOC" onclick="$('#mainContainerEntriesTOC').toggle('1000');">Table of Content</div>
   <div id="mainContainerEntriesTOC" style="display:none;">
      <div class="headedContainerTOC">
         <div class="headedContainerTitleTOC"><a href="#ParserPossibilities:WhyWriteAMarkupParserANCHOR" name="ParserPossibilities:WhyWriteAMarkupParserTOC">Parser Possibilities: Why Write A Markup Parser</a></div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#IntroductionANCHOR" name="IntroductionTOC">Introduction</a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#What'sAMarkupParserANCHOR" name="What'sAMarkupParserTOC">What's A Markup Parser</a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#WhyWriteAParser?ANCHOR" name="WhyWriteAParser?TOC">Why Write A Parser?</a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#TheRoadTomlParserANCHOR" name="TheRoadTomlParserTOC">The Road To mlParser</a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#MixingSGMLAndXMLANCHOR" name="MixingSGMLAndXMLTOC">Mixing SGML And XML</a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#mlParserANCHOR" name="mlParserTOC">mlParser</a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#mlParserTodayANCHOR" name="mlParserTodayTOC">mlParser Today</a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#SummaryANCHOR" name="SummaryTOC">Summary</a></div>
         </div>
         <div class="headedContainerTOC">
            <div class="headedContainerTitleTOC"><a href="#BibliographyANCHOR" name="BibliographyTOC">Bibliography</a></div>
         </div>
      </div>
   </div>
</div>
<div id="mainContainerTERMS">
   <div id="mainContainerTitleTERMS" onclick="$('#mainContainerEntriesTERMS').toggle('1000')">Index of Terms</div>
   <div id="mainContainerEntriesTERMS" style="display:none;">
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">a</div>
         <div class="singletermTERMS">Attributes</div>
         <div class="singletermTERMS">August 12 - 15, 2008</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">b</div>
         <div class="singletermTERMS">Balisage: The Markup Conference 2008</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">c</div>
         <div class="singletermTERMS">cload</div>
         <div class="singletermTERMS">collect</div>
         <div class="singletermTERMS">content.</div>
         <div class="singletermTERMS">content</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">d</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">e</div>
         <div class="singletermTERMS">element</div>
         <div class="singletermTERMS">Earl</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">f</div>
         <div class="singletermTERMS">Filtered HTML</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">g</div>
         <div class="singletermTERMS">get_XML_field()</div>
         <div class="singletermTERMS">get_next_XML_field()</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">h</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">i</div>
         <div class="singletermTERMS">Input Interface.</div>
         <div class="singletermTERMS">if</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">j</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">k</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">l</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">m</div>
         <div class="singletermTERMS">markup.</div>
         <div class="singletermTERMS">Markup Language Definition,</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">n</div>
         <div class="singletermTERMS">Not tied to existing APIs.</div>
         <div class="singletermTERMS">Nsgmls Output Format,</div>
         <div class="singletermTERMS">Norman</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">o</div>
         <div class="singletermTERMS">Output Call-Backs.</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">p</div>
         <div class="singletermTERMS">Practical Guide To SGML And XML Filters.</div>
         <div class="singletermTERMS">Practical Guide To SGML/XML Filters</div>
         <div class="singletermTERMS">Parsing Engine.</div>
         <div class="singletermTERMS">Practical Guide to SGML/XML Filters,</div>
         <div class="singletermTERMS">parser</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">q</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">r</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">s</div>
         <div class="singletermTERMS">See</div>
         <div class="singletermTERMS">special</div>
         <div class="singletermTERMS">SGML Definition,</div>
         <div class="singletermTERMS">smithno@saic.com</div>
         <div class="singletermTERMS">SGML</div>
         <div class="singletermTERMS">Smith</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">t</div>
         <div class="singletermTERMS">The learning experience.</div>
         <div class="singletermTERMS">test.xml</div>
         <div class="singletermTERMS">Thinlet Home Page,</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">u</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">v</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">x</div>
         <div class="singletermTERMS">XML</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">y</div>
         <div class="singletermTERMS">You have complete control.</div>
         <div class="singletermTERMS">You can mix and match markup languages.</div>
         <div class="singletermTERMS">You need to create documents with "live" content.</div>
      </div>
      <div class="letterContainerTERMS">
         <div class="letterlableTERMS">z</div>
      </div>
   </div>
</div>
<div id="mainContainerIML"><a name="ParserPossibilities:WhyWriteAMarkupParserANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="article e0" version="5.0-subset Balisage-1.2" xml:id="HR-23632987-8973">
      <div class="title e1">Parser Possibilities: Why Write A Markup Parser</div>
      <div class="info e2">
         <div class="confgroup e3">
            <div class="conftitle e4">Balisage: The Markup Conference 2008</div>
            <div class="confdates e5">August 12 - 15, 2008</div>
         </div>
         <div class="abstract e6">
            <div class="para e7">
               In the early days of XML, there seemed to be a new XML parser just about
               every week. This was in stark contrast to SGML where there might be half a
               dozen working parsers ever written. As XML matured and SAX became the first defacto
               XML
               parser API, the new parser stream pretty much slowed to a trickle.
               Once robust XML parsers, such as Expat,
               became widely available, there seemed little reason left to write you own parser.
               Expat is robust, fast, and still provides the XML under pinnings for many programming
               languages.
               
            </div>
            <div class="para e8">I believe there remain many valid reasons for writing your own markup
               	 language parser. This paper identifies reasons you might want to write a custom
               	 parser and examines the choices I made writing mlParser.
               
            </div>
         </div>
         <div class="author e9">
            <div class="personname e10">
               <div class="firstname e11">Norman</div>
               <div class="othername e12">Earl</div>
               <div class="surname e13">Smith</div>
            </div>
            <div class="personblurb e14">
               <div class="para e15">Mr. Smith has been a software developer for 30+ years and involved with
                  markup applications starting with SGML in 1990. He has worked for SAIC for 26
                  years on a variety of projects ranging from automated document creation to
                  robotics to web applications. He has authored 12 books including two on
                  SGML/XML. Mr. Smith was selected as an SAIC Technical Fellow in 2004.
               </div>
            </div>
            <div class="affiliation e16">
               <div class="jobtitle e17">SAIC Technical Fellow and Assistant VP of Technology</div>
               <div class="orgname e18">Science Applications International Corp.</div>
            </div>
            <div class="email e19">smithno@saic.com</div>
         </div>
         <div class="legalnotice e20">
            <div class="para e21">Copyright, Science Applications International Corporation. All rights reserved.  Unpublished
               rights reserved under copyright laws of the United States.
            </div>
         </div>
         <div class="keywordset e22" role="author">
            <div class="keyword e23">parser</div>
            <div class="keyword e24">XML</div>
            <div class="keyword e25">SGML</div>
         </div>
      </div><a name="IntroductionANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="section e26">
         <div class="title e27">Introduction</div>
         <div class="para e28">XML and SGML parsers are available that are mature, robust,
            		and widely used. It's not like the early days of XML when it seemed that every new
            		week brought a new parser. Soon, the first SAX-based XML parsers appeared,
            		followed by DOM (Document Object Model) parsers with standard APIs. Once
            		high-quality validating parsers, such as Expat and AElfred, became widely available,
            		the community seemed to lose interest in writing new parsers. Many of
            		the early XML parsers were non-validating because they were considerably easier
            to write
            		than validating parsers.
         </div>
         <div class="para e29">SAX was originally patterned after the ESIS (Element Structure Information Set)
            output from the SGMLS and NSGMLS
            		SGML parsers. (
            <div class="emphasis e30" role="ital">See</div> 
            <div class="xref e31" linkend="ClarkJ"></div>)
            		DOM implementations usually use an underlying SAX parser to feed the
            		content to the DOM objects. SAX-based applications are generally faster and
            		require less memory than a DOM-based application. My experience is that an
            		event-based parsing model, like SAX, can easily handle 80% to 90% of XML applications.
            		Either are appropriate for the next 5% to 10% of applications, and the last 5%
            		of applications really need DOM or something similar.
         </div>
         <div class="para e32">Even with numerous XML parser options, I have never been completely
            		satisfied with the available XML parsers because I still deal with SGML and other
            		markup languages. The remainder of this paper looks at reasons for
            		writing a parser. Questions that you should ask yourself before starting to write
            		a custom parser and the road to writing my own mlParser are also examined.
         </div>
      </div><a name="What'sAMarkupParserANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="section e33">
         <div class="title e34">What's A Markup Parser</div>
         <div class="para e35">A markup language, such as XML, is a language for writing application-level
            markup languages. HTML and DocBook are examples of application-level
            		markup languages. The dual use of the term "markup language" is especially
            		confusing to non-technical people. Wikipedia's definition of SGML
            (
            <div class="emphasis e36" role="ital">See</div> 
            <div class="xref e37" linkend="WikipediaSGML"></div>) describes it
            		as "a metalanguage in which one can define markup languages" and I believe the
            		term metalanguage is appropriate. Wikipedia further defines markup language as "a
            		set of annotations to text that describe how it is to be structured, laid out,
            		or formatted."
         </div>
         <div class="para e38">Both SGML and XML use "&lt;" and "&gt;" to delimit markup.  Common usage
            		has evolved to the point that just about any markup that uses "&lt;" and "&gt;"
            		is called XML. Notice that I have been using the term "markup language parser" instead
            		of "XML parser" for the most part so far. This is done on purpose. 
         </div>
         <div class="para e39">There are four types of markup language
            		in use that I know of:
         </div>
         <div class="orderedlist e40" startingnumber="1">
            <div class="listitem e41">
               <div class="para e42">SGML</div>
            </div>
            <div class="listitem e43">
               <div class="para e44">XML</div>
            </div>
            <div class="listitem e45">
               <div class="para e46">WordML</div>
            </div>
            <div class="listitem e47">
               <div class="para e48">*SP</div>
            </div>
         </div>
         <div class="para e49">HTML and DocBook are not included in the list because they are
            	 XML/SGML application-level markup languages, not markup meta languages.
            	 WordML and *SP are not meta-markup lanugages. However, their syntax
            	 sufficiently differs from XML and SGML such that normal parsers don't handle
            	 them either. They are included to show markup that might require a
            	 custom parser to process, and because mlParser can handle both.
            	 
         </div>
         <div class="para e50">SGML, or Standard Generalized Markup Language, is an ISO standard. Its
            		heritage is in the publishing industry and it has an IBM General Markup Language
            		(GML) lineage. Computers in the early days had limited processing power for the
            		individual, which translated to no SGML editor that performed real-time validation
            		and formatting. Therefore, SGML contained many features to minimize the
            		keystrokes required to enter content. For example, end tags could be declared optional.
            		The structure of an SGML document is defined by a Document Type Definition (DTD).
            		SGML is a markup metalanguage. My general belief is that SGML is still best for
            		defining publishing markup languages.
         </div>
         <div class="para e51">XML, or eXtensible Markup Language, has its roots in the database
            		world. It is a direct result of Tim Bray's work at OpenText for handing
            		structured data that may or may not be SGML compliant. XML is also a markup
            		metalanguage. Element structure may be defined thru a variety of "languages"
            		including DTDs, Schemas, and RelaxNG. It is an SGML subset with just enough
            		syntax differences to prevent processing markup files with each other's tools.
            		I know because I tried for years to treat markup as SGML for some tools and the
            		same markup as XML with other tools with limited success. 
         </div>
         <div class="para e52">XML also introduced the concept of valid versus well-formed XML documents. A
            		valid document is one that has been validated successfully against its DTD or Schema
            with a
            		validating parser. A well-formed document is one that has matching start and
            		end tags and follows the other rules of XML markup syntax. A well-formed
            		document may or may not be valid. For that matter, it may or may not have a DTD
            		or Schema.
         </div>
         <div class="para e53">There is no concept of well-formed documents in SGML, only
            		valid or not valid. Most SGML tools validate the document every time it is
            		used. A common real-world view is that a document only needs to be validated in
            		specific cases:
         </div>
         <div class="itemizedlist e54">
            <div class="listitem e55">
               <div class="para e56">The document is edited by a human.</div>
            </div>
            <div class="listitem e57">
               <div class="para e58">During program development, until you are sure that valid markup is
                  			 generated.
               </div>
            </div>
            <div class="listitem e59">
               <div class="para e60">When data is supplied from an external source, markup may or may not
                  			 need to be validated on every data exchange depending on
                  			 circumstances.
               </div>
            </div>
         </div>
         <div class="para e61">WordML is my name for the output from saving a Microsoft Word document
            		as Filtered HTML. The markup appears to follow some XML syntax rules, some SGML
            		syntax rules, and some of its own, unique syntax rules.
            		
            		Much
            		Word-specific data is stored in comments. I have even run across a few WordML
            		documents that were not well formed! Few XML parsers can handle WordML.
         </div>
         <div class="para e62">*SP represents the various Serve Page markup languages such as ASP and
            		JSP. It is not often that a Java developer attempts to run Java Server Pages
            		thru an external parser. The JSP compiler normally takes care of the parsing.
            		There are times when it can be very revealing. The output of the JSP compiler
            		is a Java program that generates an HTML page. Normally, the embedded Java code
            		generates dynamic values on the page. XML parsers do not normally handle
            		*SP files.
         </div>
         <div class="para e63">Finally, the answer to the question "What's a markup parser?" A markup parser
            		basically reads data that contains application-level markup, extracts tags and
            		attributes from the markup, and generates some output. Validating parsers also
            		read the structure definition in the form of a DTD, Schema, or other format.
            		The output may range from structural error messages to ESIS output or anything
            		in between. Some parsers, like OmniMark have built-in programming languages.
            		Others provide SAX or DOM programming language interfaces. The possibilities
            		are limited only by the requirements of the application and imagination of the
            		developer. A markup parser may handle multiple types of
            		markup, not just XML or SGML, from the point of view presented here.
         </div>
         <div class="para e64">ESIS is the primary output for
            		the SGMLS and NSGMLS parsers. It is a record-oriented format where the first
            		character on each line represents the markup event and the rest of the line is
            		data. For example, a start tag event is represented by an '(' event type and
            		the rest of the line is data. The tag name is the data in this case.
            		'(mytag' is the ESIS output generated for &lt;MYTAG&gt; in the input document.
         </div>
         <div class="para e65">ESIS is very significant from a historical prospective. Back in prime
            		SGML days of the early 1990s, SGMLS was just about the only widely available
            		free SGML parser. Commercial SGML tools were all expensive because of the cost
            		of either writing or licensing an SGML parser to include in the tools. Taking
            		advantage of the SGMLS ESIS output was the only way to test-drive SGML without
            		spending a lot of money. ESIS format is easy to process and a good programmer
            		could do amazing things with ESIS output and a Perl script or two.
            		ESIS also contains the idea behind SAX. The call-back events in programs
            		logically work on an ESIS stream. 
         </div>
      </div><a name="WhyWriteAParser?ANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="section e66">
         <div class="title e67">Why Write A Parser?</div>
         <div class="para e68">With the parser background out of the way, let's take a look at reasons both to
            		write your own parser and reasons not to write your own parser. First, there are
            		good reasons for not writing a custom parser:
         </div>
         <div class="itemizedlist e69">
            <div class="listitem e70">
               <div class="para e71">Writing a basic parser is a lot of work</div>
            </div>
            <div class="listitem e72">
               <div class="para e73">Writing a validating parser is a lot more work</div>
            </div>
            <div class="listitem e74">
               <div class="para e75">Implementing XSL/XSLT/X-Path/XQuery, etc., support is not practical for most
                  			individual developers
               </div>
            </div>
            <div class="listitem e76">
               <div class="para e77">Writing a parser, even a non-validating parser that implements SAX
                  		        and/or DOM, is a huge effort
                  			 
               </div>
            </div>
            <div class="listitem e78">
               <div class="para e79">There are multiple, structure definition languages, such as DTD,
                  		  	   Schema, RelaxNG, etc., needed for validation that are complex
               </div>
            </div>
         </div>
         <div class="para e80">Writing any markup parser is hard work. The additional complexity and
            	        effort required to write a validating parser instead of a
            	        non-validating/well-formed parser is significant. For many cases,
            	        it exceeds the point of diminishing returns . Writing a validating parser
            	        requires writing the
            		validating part, plus the code to parse a DTD or schema, and implement the code
            		to actually validate the element structure at each change-in-tag state.
            Are the benefits worth the effort?
         </div>
         <div class="para e81">The "X" add-ons are also complex. They require a very sharp staff to
            		implement the standards. The resources to properly implement
            		XSL/XSLT/X-Path/XQuery is substantial. These are usually beyond the
            		average individual developer for short-term projects.
            		Complexity and the associated learning curve are the main
            		impediments.
         </div>
         <div class="para e82">
            		Both the SAX and DOM API's are large and fairly complex, which means the
            		average developer won't implement them
            completely, if at all. I know from experience; I didn't
            		bother implementing either.
            A validating parser also requires the code to load allowable element
            		structure in order to be able to validate a document, with another increase in
            		code complexity and size.
         </div>
         <div class="para e83">
            	    All of these items represent increased implementation effort that just
            		might not be worth the trouble if an existing parser meets most of your
            		requirements. You have to carefully gauge the value proposition for
            		each increase in effort that the next step brings. It may or may not be worth
            		the effort.
            	
         </div>
         <div class="para e84">On the other hand, there are still many reasons for writing your own
            		markup parser. The rest of this section takes a look as some of those reasons.
            		They include:
         </div>
         <div class="itemizedlist e85">
            <div class="listitem e86">
               <div class="para e87">The learning experience.</div>
            </div>
            <div class="listitem e88">
               <div class="para e89">No existing parser meets your specific requirements.</div>
            </div>
            <div class="listitem e90">
               <div class="para e91">You have complete control.</div>
            </div>
            <div class="listitem e92">
               <div class="para e93">You can mix and match markup languages, i.e., SGML, XML,
                  			 etc.
               </div>
            </div>
            <div class="listitem e94">
               <div class="para e95">Not tied to existing APIs.</div>
            </div>
            <div class="listitem e96">
               <div class="para e97">You need to create documents with "live" content. </div>
            </div>
         </div>
         <div class="para e98">The following paragraphs expand these points. </div>
         <div class="para e99">
            <div class="emphasis e100" role="ital">The learning experience.</div> Writing a markup parser, even a
            		"simple" non-validating parser, is always a learning experience. There are a
            		number of learning experience possibilities, such as:
         </div>
         <div class="itemizedlist e101">
            <div class="listitem e102">
               <div class="para e103">Learning about markup languages. Writing a parser will teach you
                  			 about markup language rules. Having to account for every possible condition
                  			 in the markup will quickly enlighten you!
               </div>
            </div>
            <div class="listitem e104">
               <div class="para e105">Learning about software state machines. I have used the state
                  			 machine technique for writing a parser more than once. It is a straight-forward
                  			 way to work thru the program. An in depth knowledge of the rules of the markup
                  			 language is required. There is a basic state machine for parsing SGML published
                  			 in the 
                  <div class="emphasis e106" role="ital">Practical Guide To SGML And XML Filters.</div>
                  			 (
                  <div class="emphasis e107" role="ital">See</div> 
                  <div class="xref e108" linkend="SmithN"></div>)
                  			 If you don't know
                  what a State Transition Diagram is, you will learn a lot of new things
                  			 writing a markup parser.
               </div>
            </div>
            <div class="listitem e109">
               <div class="para e110">Providing a vehicle to learn a new language. I wrote the first implementation
                  			 of mlParser because I needed to write a non-trivial program to learn
                  			 Java and I already understood the ins and outs of SGML.
                  			 This allowed me to concentrate
                  			 on learning the programming language and not the application.
               </div>
            </div>
         </div>
         <div class="para e111">As you can see, there are many things that can be learned from the
            		experience of writing a parser.
         </div>
         <div class="para e112">
            <div class="emphasis e113" role="ital">No existing parser meets your specific requirements.</div> This is
            		not an unusual occurrence, especially if your application is a little
            		non-standard. Reasons include:
         </div>
         <div class="itemizedlist e114">
            <div class="listitem e115">
               <div class="para e116">Need a light-weight parser</div>
            </div>
            <div class="listitem e117">
               <div class="para e118">Need to parse multiple markup meta languages</div>
            </div>
            <div class="listitem e119">
               <div class="para e120">The programming language for an application is incompatible with
                  		  existing parsers
               </div>
            </div>
         </div>
         <div class="para e121">Robert Bajzat (
            <div class="emphasis e122" role="ital">See</div> 
            <div class="xref e123" linkend="Bajzat"></div>)
            needed a light-weight XML parser for his Thinlet package,
            		which is a small (39k) Java windowing framework aimed at cell phones. The
            		on-screen widgets for a Thinlet-based application are in simple XML. The Thinlet
            		XML parser handles its slightly restricted XML syntax. Comments
            		not spanning a line is an example restrictions.
            		The Thinlet parser also is closely tied to the application
            		and knows how to handle just the widget markup. The Thinlet parser is an
            		integral part of the framework, and the short cuts in syntax make it tiny! 
         </div>
         <div class="para e124">Incompatibility with existing parsers usually means the markup data
            		buries information within comments, does not follow the syntax rules, or mixes
            		and matches syntax rules from different markup meta languages. WordML is a good
            		example of this. WordML is what I call the result of saving a Word document as
            		"Filtered HTML." It appears to follow some SGML rules, some XML rules, invents
            		a few rules, and puts a great deal of information into comments. Few parsers
            		can handle this markup.
         </div>
         <div class="para e125">
            <div class="emphasis e126" role="ital">You have complete control.</div>
            	        This is the real reason most people write their
            		own version of an application. Tailoring a program to meet your system
            		requirements has a strong draw for many people. I would rather write a
            		hand-tuned set of Java classes to represent markup data, for example,
            		than use one of the
            		canned frameworks that seems to create hundreds of classes/methods when three
            		or four well-designed classes are easier to understand and more efficient.
            
         </div>
         <div class="para e127">
            		Control extends to which markup features are supported. The parser may not
            		need to handle attributes at all if the data does not
            		contain attributes and is record-oriented. The
            		parser may do simple transforms as the input stream goes by that will
            		significantly simplify downstream code. The parser
            		doesn't always have to stop on
            		errors. 
         </div>
         <div class="para e128">
            <div class="emphasis e129" role="ital">You can mix and match markup languages.</div> I started out using
            		SGML around 1990. I have been thru the start of XML and the rise of Server Page
            		languages such as JSP and ASP. There have been plenty of times when I wanted
            		to mix and match SGML and XML files, in particular. Writing your own parser
            		makes this practical. 
         </div>
         <div class="para e130">
            <div class="emphasis e131" role="ital">Not tied to existing APIs.</div> The existing SAX and DOM APIs are
            		large and complex. If you go back and examine ESIS closely, basic markup
            		processing can be done with a much simpler subset API. But once you make the
            		leap that you don't have to implement existing APIs, you are free to build what
            		meets your application requirements. That said, I firmly believe that this is
            		the least acceptable reason in my list for writing a parser.
         </div>
         <div class="para e132">
            <div class="emphasis e133" role="ital">You need to create documents with "live" content.</div> A favorite
            		application technique of mine is creating a live document. By live, I mean that
            		some portion of the content is dynamically generated. Executing an external
            		script, nesting the output of another parse, running an SQL query, or retrieving
            		a URN are some of the many things that can be incorporated transparently with a
            		custom parser. The data just shows up in the data to the downstream processing
            		programs. A great deal of extra functionality can be transparently dropped into
            		a markup-based application by including the ability to execute arbitrary
            		programs/code on a parsing event.
         </div>
      </div><a name="TheRoadTomlParserANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="section e134">
         <div class="title e135">The Road To mlParser</div>
         <div class="para e136">I initially wrote my markup language parser, mlParser, in 2002. The
            		journey from being thrown into the SGML ocean in 1990 to the birth of mlParser
            		and its subsequent evolution into a multi, meta-markup language parser was a
            		long road. In the early SGML days, SGML tools were expensive. My customer wanted
            to
            		use SGML as the exchange format for bibliographic data and could not justify
            		the expense of purchasing SGML tools without being sure of success. We
            		developed small-scale applications around SGMLS using
            		Perl scripts to process ESIS output. It worked well, and I
            		learned a lot about processing an ESIS stream. 
         </div>
         <div class="para e137">The following markup file is used as input for sample code for the examples
            	       that follow:
         </div>
         <div class="programlisting e138" xml:space="preserve">
            &lt;RECORDS&gt;
            &lt;RECORD&gt;
            &lt;NAME&gt;John Doe&lt;/NAME&gt;
            &lt;PHONE&gt;555-123-4567&lt;/PHONE&gt;
            &lt;EMAIL&gt;JDoe@anymail.com&lt;/EMAIL&gt;
            &lt;STATE&gt;Confusion&lt;/STATE&gt;
            &lt;/RECORD&gt;
            &lt;RECORD&gt;
            &lt;NAME&gt;Jane Smith&lt;/NAME&gt;
            &lt;PHONE&gt;555-345-9876&lt;/PHONE&gt;
            &lt;EMAIL&gt;smithj@anymail.com&lt;/EMAIL&gt;
            &lt;STATE&gt;Nirvana&lt;/STATE&gt;
            &lt;/RECORD&gt;
            &lt;/RECORDS&gt;
            
         </div>
         <div class="para e139">The ESIS output from mlParser for the above markup is:</div>
         <div class="programlisting e140" xml:space="preserve">
            # mlParser (c) Science Applications International Corporation, 2002, 2006, 2007.
            All rights reserved.
            (records
            -\n
            (record
            -\n
            (name
            -John Doe
            )name
            -\n
            (phone
            -555-123-4567
            )phone
            -\n
            (email
            -JDoe@anymail.com
            )email
            -\n
            (state
            -Confusion
            )state
            -\n
            )record
            -\n
            (record
            -\n
            (name
            -Jane Smith
            )name
            -\n
            (phone
            -555-345-9876
            )phone
            -\n
            (email
            -smithj@anymail.com
            )email
            -\n
            (state
            -Nirvana
            )state
            -\n
            )record
            )records
            C
            Done
            
         </div>
         <div class="para e141">The code described in the following paragraphs produces this output:
            		
         </div>
         <div class="programlisting e142" xml:space="preserve">
            Name: John Doe   Email: JDoe@anymail.com
            Name: Jane Smith   Email: smithj@anymail.com
            
         </div>
         <div class="para e143">Over the years, I wrote two other parsers. The first was part of a Forth
            (
            <div class="emphasis e144" role="ital">See</div> 
            <div class="xref e145" linkend="Forth"></div>)
            	interpreter. The only restriction on Forth function names is that the name
            	cannot contain white space. Therefore, a function name can be a tag name. So,
            	&lt;RECORD&gt; is both a tag and a function. A function
            	definition begins with ':' and ends
            	with ';'. Forth is a stack-oriented language that has a Reverse Polish syntax,
            	which means that parameters come before the function name and no parens are
            	necessary. A function is called by simply referencing its name.
         </div>
         <div class="para e146">The application implementation approach was:</div>
         <div class="itemizedlist e147">
            <div class="listitem e148">
               <div class="para e149">Define a function for each tag</div>
            </div>
            <div class="listitem e150">
               <div class="para e151">Each function must consume characters up to the
                  		next tag/end tag
               </div>
            </div>
            <div class="listitem e152">
               <div class="para e153">A document processed itself when fed to the
                  		  Forth interpreter
               </div>
            </div>
         </div>
         <div class="para e154">The document effectively executed itself. It was an interesting idea
            		that never got past the toy stage. The following is a snippet of
            		Forth code used to
            		process the markup file described above:
         </div>
         <div class="programlisting e155" xml:space="preserve">
            String content
            : &lt;NAME&gt;
            " Name:" print
            content collect ;  \ Read the content for &lt;name&gt;
            : &lt;/NAME&gt;
            content print ;
            : &lt;EMAIL&gt;
            " E-Mail: " print
            content collect ;
            : &lt;/EMAIL&gt;
            content print
            " \n" print ;
            " test.xml" cload
            
         </div>
         <div class="para e156">The 
            <div class="emphasis e157" role="bold">cload</div> function loads and interprets the filename
            		
            <div class="emphasis e158" role="bold">test.xml</div>.
            	the 
            <div class="emphasis e159" role="bold">collect</div> function consumes
            	the charcters up to the next '&lt;' and store it in
            	
            <div class="emphasis e160" role="bold">content.</div>
            	The document executes itself generating the
            		output. The parser was implemented as a state machine.
            	 
         </div>
         <div class="para e161">My next parser was a Perl library, which was based completely on regular
            		expressions. The primary functions were:
         </div>
         <div class="programlisting e162" xml:space="preserve">
            $content = &amp;get_XML_field($string,"tag");
            @results = &amp;get_next_XML_field($string,"tag");
            
         </div>
         <div class="para e163">
            
            <div class="emphasis e164" role="bold">get_XML_field()</div> returns the contents
            of &lt;TAG&gt; from the string of markup. It is useful when processing
            record oriented markup one record at a time.
            
            <div class="emphasis e165" role="bold">get_next_XML_field()</div> extracts a
            repeating tag from the markup string, returning a status, the tag
            contents, and the remainder of the markup string. Typically, the whole
            file is read into a string and 
            <div class="emphasis e166" role="bold">get_next_XML_field()</div>
            extracts the next record to operate on. Then calls to
            
            <div class="emphasis e167" role="bold">get_XML_field()</div> pull out the fields
            individually for processing.
            
         </div>
         <div class="para e168">The approach for using this parser was:</div>
         <div class="itemizedlist e169">
            <div class="listitem e170">
               <div class="para e171">Read data into a string</div>
            </div>
            <div class="listitem e172">
               <div class="para e173">Extract a "wrapper" element into another string</div>
            </div>
            <div class="listitem e174">
               <div class="para e175">Extract individual fields from the wrapper string</div>
            </div>
            <div class="listitem e176">
               <div class="para e177">Do whatever processing is needed</div>
            </div>
         </div>
         <div class="para e178">The following Perl code snippet generates the example output:</div>
         <div class="programlisting e179" xml:space="preserve">
            require "xml.pl";
            
            my $file;
            my $record;
            my $name;
            my $email;
            my $template ="Name: \$name   Email: \$email\n";
            
            $/ = "&lt;/RECORD&gt;";
            
            while(&lt;STDIN&gt;){   # Read a record
            $record = $_;
            $name   = &amp;get_XML_field($record,"NAME");
            $email  = &amp;get_XML_field($record,"EMAIL");
            eval("print \"$template\"");
            }
            exit;
            
         </div>
         <div class="para e180">This Perl parsing library has been used successfully in several production
            		applications. The constraints are that the markup does not contain attributes
            		and that huge records have to fit in memory. 
         </div>
         <div class="para e181">Both of these solutions worked for a small subset of applications with
            		simplified markup. They handle start tags, content, and end tags and that's
            		about it. Neither ever grew into a robust, general purpose parser.
            		The Perl library has found its way into several production
            		applications though.
            
         </div>
         <div class="para e182">The following code snippet is part of the mlParser program to
            process the sample input file. It has the call-backs for the parser
            output events. The simple nature of the input markup, makes for an
            extremely simple Java example. 
         </div>
         <div class="programlisting e183" xml:space="preserve">
            ...
            HashMap element = new HashMap();
            String  content = "";
            ...
            public void writeStartTag(String sTag)
            {
            String tag     = sTag.toLowerCase();
            
            if(tag.equals("record"){
            element.clear();    // Wipe the hash for each record.
            }
            }
            ...
            public void writeEndTag(String eTag)
            	{
            	    String tag     = eTag.toLowerCase();
            if(tag.equals("record")){
            system.out.print("Name: "    + element.get("name")  +
            "  Email: " + element.get("email") + "\n";
            }else{
            element.put(tag, content);  // Collect all element content in a Hash
            }
            	}
            
         </div>
         <div class="para e184">Assume that the content callback happens and leaves the
            content in the 
            <div class="emphasis e185" role="ital">content</div> global variable.
            The only processing needed in the 
            <div class="emphasis e186" role="bold">writeStartTag()</div>
            method clears the 
            <div class="emphasis e187" role="ital">element</div> hash. All of
            the other processing occurs in 
            <div class="emphasis e188" role="bold">writeEndTag().</div> When
            the end tag is &lt;/RECORD&gt;, we know that all of the fields in the
            record have been collected. Simply putting the content in a hash with
            the tag as the key is a convenient way to collect the data without
            testing for each tag as it passes by. 
         </div>
      </div><a name="MixingSGMLAndXMLANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="section e189">
         <div class="title e190">Mixing SGML And XML</div>
         <div class="para e191">I am an old-time SGMLer who was as skeptical as the next person about XML
            		when it first came out of the closet at the 1996 SGML Conference. The false
            		promise that got a lot of the SGML community on the XML train was that "XML is
            		just SGML without DTDs" and XML is a subset of SGML. I had often wished to
            		process SGML files without a DTD. The implication I misread into the original
            		XML discussions was being able to process SGML markup with XML tools. 
         </div>
         <div class="para e192">Not being able to do much without a DTD was always an SGML issue for two
            		reasons. First, I never saw the need to validate an SGML file every time it
            		was touched. An SGML file only needs to be validated when modified. Second, I
            		received SGML files from external sources without a DTD with enough regularity
            		that having to reverse engineer a DTD in order to be able to use SGML tools
            		became a real annoyance. Most of the time, only a handful of tags were
            		processed. Writing what was essentially a throw-away DTD always rubbed me the
            		wrong way. 
         </div>
         <div class="para e193">An XML well-formed document versus a valid document was the leap that was
            		supposed to enable the "SGML without DTDs" concept. Well, that didn't quite
            		happen. By the time XML hit the streets, minor syntax changes and the fact that
            		non-validating parsers threw errors when processing virtually every SGML file made
            		feeding an SGML file to a non-validating XML parser a waste of CPU cycles.
            		Error examples include:
         </div>
         <div class="itemizedlist e194">
            <div class="listitem e195">
               <div class="para e196">The first line of the file had to be the XML declaration
                  		(&lt;?xml version="1.0" encoding="UTF-8"?&gt;),
                  		which is a processing instruction in SGML.
               </div>
            </div>
            <div class="listitem e197">
               <div class="para e198">The SGML empty tag representation causes
                  the document not to be well-formed and
                  therefore causes parsing problems.
               </div>
            </div>
            <div class="listitem e199">
               <div class="para e200">Any entity reference not in the default XML set (&lt;, &gt;, and
                  		  &amp;) threw errors. 
               </div>
            </div>
         </div>
         <div class="para e201">I eventually found xmln, which seemed to be the answer
            		for a while. The C source was available and it generated an ESIS-like output
            		stream, which meant it could be utilized by programs
            		such as the Perl scripts I had already written
            		to use the
            		ESIS output from SGMLS. I thought I could modify xmln to handle SGML files as
            		well but could never track down one of the C header files, which forced an end
            		to my customization attempts.
         </div>
         <div class="para e202">I attempted to use markup interchangeably as SGML and XML for a couple
            		of years. I finally threw in the towel when a couple of developers started using
            		Java XML tools on a project. Since then, I consider SGML and XML
            		cousins at best. XML is not
            		a subset of SGML as originally advertised!
         </div>
         <div class="para e203">
            		I work with some systems that started life as SGML applications. Eventually,
            		the data and code will be migrated to XML data and tools. In the meantime,
            		wouldn't it be convenient to mix SGML data and XML data transparently rather
            		than have to do a conversion? I believe this is still a valid requirement for
            		mixing XML and SGML interchangeably and a good reason to write a custom
            		parser.
            	 
         </div>
         <div class="para e204">This section discusses my frustration mixing SGML and XML and
            	        the road to writing my own parser. mlParser
            		did not happen directly as a result, rather the knowledge gained along the way
            		was applied to its initial implementation and eventual evolution.
         </div>
      </div><a name="mlParserANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="section e205">
         <div class="title e206">mlParser</div>
         <div class="para e207">In 2002, my next project required that I be fluent in Java. I had done
            		light Java maintenance up to that point. The project seemed pretty important, so
            		I needed to be productive on day one! I knew several programming
            		languages at that point - getting up to speed did not seem impossible. The
            		obvious approach was writing a non-trivial Java program. 
         </div>
         <div class="para e208">I decided to implement the parser described by the software finite state
            		machine from
            		
            <div class="emphasis e209" role="ital">Practical Guide To SGML/XML Filters</div>.
            		 (
            <div class="emphasis e210" role="ital">See</div> 
            <div class="xref e211" linkend="SmithN"></div>) Having experimented
            		with both state machines and simple parsers in the past, I knew the technique
            		and subject area. This allowed me to concentrate on the learning Java aspect in
            		writing the parser. 
         </div>
         <div class="para e212">The initial implementation started as a simple, pretty-much exact
            		implementation from the book. The parser generated an ESIS output stream. I
            		verified the output by comparing the mlParser ESIS output
            		with the NSGMLS output. The
            		first implementation was much easier than I had expected. 
         </div>
         <div class="para e213">The second version implemented a few of the XML syntax differences, such
            		as the 
            <div class="emphasis e214" role="ital">&lt;TAG/&gt;</div> empty tag. By the time I
            got the parser digesting basic SGML
            		and XML, I began to see the potential for my own parser! 
         </div>
         <div class="para e215">The third iteration was a restructuring of the code with interfaces for
            		input processing, the parsing engine, and the output call-back class. My
            		thinking was: 
         </div>
         <div class="itemizedlist e216">
            <div class="listitem e217">
               <div class="para e218">
                  <div class="emphasis e219" role="ital">Input Interface.</div> The assumption was
                  a developer could supply
                  			 a markup stream from any source, not just a file. The default input interface
                  			 class handles the file as a stream, which was a good choice because of the
                  			 large number of input types that can be mapped into a stream. There has been no
                  			 need to implement another input class, but I still see the
                  			 potential for custom
                  			 input classes.
               </div>
            </div>
            <div class="listitem e220">
               <div class="para e221">
                  <div class="emphasis e222" role="ital">Parsing Engine.</div> The interface makes it possible to replace
                  			 the default state machine with some other parsing engine. The state machine is
                  the
                  			 heart of mlParser and its ability to parse multiple meta-markup languages is
                  			 an important capability for me, so I don't see replacing current the state machine.
                  			 However, it is possible.
               </div>
            </div>
            <div class="listitem e223">
               <div class="para e224">
                  <div class="emphasis e225" role="ital">Output Call-Backs.</div> Each markup event triggers a call-back
                  			 to an interface-defined method. The interface is organized around ESIS events
                  			 plus a couple, such as document start and end. The interface is reminiscent of
                  			 SAX, only a great deal simpler. This interface is the hook to embed mlParser into
                  			 applications.
               </div>
            </div>
         </div>
         <div class="para e226">Two additional implementation cycles added a couple of significant
            		capabilities, parsing WordML and *SP files. Not long after SGML and XML parsing
            		were stable, I saved a Microsoft Word document
            as 
            <div class="emphasis e227" role="ital">Filtered HTML</div> and
            		fed it to mlParser. mlParser did not get very far. I was disappointed, but not
            		surprised. There was no immediate requirement to parse Word output. I wanted
            		mlParser to handle all common markup types transparently by this time. 
         </div>
         <div class="para e228">Examination of a WordML file reveals that it follows some SGML rules,
            		some XML rules, and invents a few of its own. Additionally, a great deal of
            		formatting data is stored in comments. I wrote a program to convert WordML to a
            		very generic HTML as an excuse to keep tweaking the parser. Successfully
            		parsing WordML became an obsession and mlParser was a time-consuming hobby
            		at this point. 
         </div>
         <div class="para e229">I volunteered to convert Word documents to HTML many times over the next
            		couple of years. Each document seemed to present some unaccounted-for nuance
            		that required a code tweak to the state machine class. The mlParser and WordML
            		converter program now handles most Word documents, although the generated HTML
            		is often ugly. The HTML is usually good enough to pass a validating parser with
            		no significant validation errors.
         </div>
         <div class="para e230">I put some thought into what additional features would be necessary to
            		make mlParser useful in a production application. The obvious items
            		included:
         </div>
         <div class="itemizedlist e231">
            <div class="listitem e232">
               <div class="para e233">Identifying empty tags without a DTD or Schema</div>
            </div>
            <div class="listitem e234">
               <div class="para e235">Simple entity resolution</div>
            </div>
            <div class="listitem e236">
               <div class="para e237">Setting most options via the command line</div>
            </div>
            <div class="listitem e238">
               <div class="para e239">The option to stop on errors or continue processing a file</div>
            </div>
            <div class="listitem e240">
               <div class="para e241">Implementing additional input data sources such as strings and
                  		  URNs
               </div>
            </div>
            <div class="listitem e242">
               <div class="para e243">Allowing nested parsing</div>
            </div>
         </div>
         <div class="para e244">SGML and XML have different markup syntax for empty elements.
            XML uses the form &lt;Tag/&gt; and SGML just uses a start tag
            and no end tag. The XML form enables recognizing an empty element
            without a DTD or Schema. The SGML requires that empty tags be
            explicitly identified. The mlParser approach is simply a file
            that identifies empty elements that get loaded into a hash at
            startup. It's simple and effective. When a missing end tag is
            detected, a check of the hash determines whether or not it is an
            empty element, and the processing handles the
            condition correctly. This approach allows
            SGML files that contain empty elements to work properly. 
         </div>
         <div class="para e245">
            	       Simple entity substitution is a similar problem to empty
            elements; how do you represent entity values without a DTD
            or Schema?  The mlParser solution is a simple Java properties
            file with the entity string as the name and the substitution
            value as the value. The default entity translation file looks
            like this:
         </div>
         <div class="programlisting e246" xml:space="preserve"> &amp;amp;=&amp;
            &amp;lt;=&lt;
            &amp;gt;=&gt;
            
         </div>
         <div class="para e247">If no entity property file is specified, a default set is used. Entities not
            		found in the property file are passed thru unchanged
            		instead of generating an error. 
         </div>
         <div class="para e248">Some applications, such as a browser or building a document,
            may require that a markup parser continue even when errors occur.
            Other applications may need to stop on each error so they can be
            corrected. mlParser can do either and allows the user to specify
            the behavior as a command-line option. Applications that embed
            mlParser can set the option via a setter method.
         </div>
         <div class="para e249">A definite requirement for using mlParser in several of my
            applications is the ability to launch nested parses. Instantiating
            another parser object is straightforward and adds almost no complication
            to application code.
         </div>
         <div class="para e250">The Java JSP compiler is pretty forgiving, and as long as it can parse the
            		Java code out of "&lt;%" and "%&gt;" delimiters, it is happy. What happens when
            		the JSP compiler is successful and there is a missing angle bracket or two
            		in the HTML markup? The result is usually
            		unexplained "stuff" on the generated HTML page. What do you do? You
            		use mlParser, which can handle the server page
            		syntax, and parse the problem JSP file. Even if the parser only checks that the
            		file is well formed, you may find problems. This actually happened on one project.
            		mlParser showed the JSP file to not be well formed. When the markup was fixed in
            		the JSP file, the unexplained "stuff" went away.
         </div>
         <div class="para e251">At this point, mlParser is mature with the capabilities identified above
            		and is used in multiple production applications on multiple projects.
         </div>
         <div class="para e252">The remainder of this section gives a brief overview of the Software
            		Finite State Machine that is the mlParser parsing engine. I first ran across
            		state machines about 20 years ago in a presentation about navigation in an
            		Adventure game where the current state represented room or location on the adventure
            		map. The direction selection by the user caused the state to transition to a
            		new location. State machines have fascinated me ever since and I have managed to
            use
            		them a few times over the years. Markup parsers are close to an ideal
            		state machine application. 
         </div>
         <div class="para e253">The following State Transition Diagram shows the states for a simple
            		SGML parser:
         </div>
         <div class="figure e254" floatstyle="1" xml:id="StateDiagram" xreflabel="SGML State Transistion Diagram">
            <div class="mediaobject e255">
               <div class="imageobject e256">
                  <div class="metaBox e257"><img src="resources/manbluflag.jpg" class="metaImage" onclick="$('#d1e472').toggle('1000');" alt="Marker: click here for details..." title="Marker: click here for details..."><div id="d1e472" class="metaSource" style="display:none;">                
                        &lt;imagedata<span class="metaAttribute">class='e257'
                           </span><span class="metaAttribute">fileref='../../../vol1/graphics/Smith01/Smith01-001.jpg'
                           </span><span class="metaAttribute">format='jpg'
                           </span><span class="metaAttribute">width='100%'
                           </span>
                        &gt;
                        
                     </div>
                  </div>
               </div>
               <div class="caption e258">
                  <div class="para e259">Simple SGML State Transition Diagram</div>
               </div>
            </div>
         </div>
         <div class="para e260">The state machine has to handle every character in the input stream. The
            		initial state is TEXT. State changes often correspond to parsing events, although
            		the State Transition Diagram does not show the call-back points. All parsing
            		states eventually return to the TEXT state.
         </div>
         <div class="para e261">Two characters are significant in the TEXT state - the Start Tag Open
            		(STAGO), which is '&lt;' and Entity Reference Open (ERO), which is '&amp;'.
            		STAGO fires a call-back to the Content method and changes the state to TAG. 
         </div>
         <div class="para e262">ERO changes to the ENTITY state to handle collection and substitution of
            		the entity. A ';' or white-space character triggers transition back into the TEXT
            		state. All other characters do not cause the state machine to exit the ENTITY
            		state and are accumulated to form the entity name.
         </div>
         <div class="para e263">The TAG state is entered from the TEXT state via the '&lt;' character. A
            	        white-space
            		character triggers transition into ATTRIBUTE Name state. The Tag Close (TAGC)
            		character '&gt;' exits TAG state back to TEXT state and fires a call-back to
            		the start tag method. Call-backs to the attribute method fire at the end of
            		each attribute. This is one difference between mlParser and SAX. mlParser fires
            		a call-back for each attribute and SAX returns the attributes in an
            		
            <div class="emphasis e264" role="ital">Attributes</div> object. Attributes are available when the start tag method
            		call-back executes in both.
         </div>
         <div class="para e265">There are two sub-states for collecting attributes: Attribute Name and
            		Attribute Value. The top level state is ATTRIBUTE. The need for sub-states may
            		not be obvious, but works well. The attribute name ends with either an '='
            		character or a '&gt;' character. In either case, a state change is triggered.
            		The Attribute Value sub-state is a little complicated because the value may be
            		enclosed in quotes or simply terminated by white space. The end of Attribute
            		Value sub-state also signals the end of ATTRIBUTE. The current state changes
            		back to TAG because the TAGC character will eventually be found.
            		In practice, there are sub-states for several states. A global
            		variable keeps track of the current state. 
         </div>
         <div class="para e266">The ability to look ahead one
            		character simplifies the state machine code significantly. Reading the next
            		character needs to be a method and not just a read loop around the state cases.
            		The sub-states certainly contribute to needing to be able to read characters at
            		any point, and I believe a read character method is the right approach for this
            		type of state machine application.
         </div>
         <div class="para e267">The state transition diagram certainly helps to think thru a state
            		machine implementation at its start. I usually draw
            		these diagrams during design. I then prepare
            		a State Transition Table by the time I start coding. It speeds up the coding
            		process significantly. The following State Transition Table corresponds to the
            		State Transition diagram above:
         </div>
         <div class="table e268" border="1" cellpadding="2" cellspacing="0">
            <div class="caption e269">
               <div class="para e270">State Transition Table</div>
            </div>
            <div class="thead e271">
               <div class="tr e272">
                  <div class="th e273">Current State</div>
                  <div class="th e274" colspan="7">Character</div>
               </div>
            </div>
            <div class="tbody e275">
               <div class="tr e276">
                  <div class="td e277"></div>
                  <div class="td e278">STAGO (&lt;)</div>
                  <div class="td e279">Whitespace</div>
                  <div class="td e280">TAGC (&gt;)</div>
                  <div class="td e281"> = </div>
                  <div class="td e282">ERO(&amp;)</div>
                  <div class="td e283">ERC(;)</div>
                  <div class="td e284">Other</div>
               </div>
               <div class="tr e285">
                  <div class="td e286">Text</div>
                  <div class="td e287">Tag</div>
                  <div class="td e288">Text</div>
                  <div class="td e289">Text</div>
                  <div class="td e290">Text</div>
                  <div class="td e291">Entity</div>
                  <div class="td e292"></div>
                  <div class="td e293">Text</div>
               </div>
               <div class="tr e294">
                  <div class="td e295">Tag</div>
                  <div class="td e296"></div>
                  <div class="td e297">Attribute</div>
                  <div class="td e298">Text</div>
                  <div class="td e299"></div>
                  <div class="td e300"></div>
                  <div class="td e301"></div>
                  <div class="td e302">Tag</div>
               </div>
               <div class="tr e303">
                  <div class="td e304">Attribute</div>
                  <div class="td e305"></div>
                  <div class="td e306"></div>
                  <div class="td e307">Tag</div>
                  <div class="td e308">Switch sub-states</div>
                  <div class="td e309"></div>
                  <div class="td e310"></div>
                  <div class="td e311">Attribute</div>
               </div>
               <div class="tr e312">
                  <div class="td e313">Entity</div>
                  <div class="td e314"></div>
                  <div class="td e315">Text</div>
                  <div class="td e316"></div>
                  <div class="td e317"></div>
                  <div class="td e318"></div>
                  <div class="td e319">Text</div>
                  <div class="td e320">Entity</div>
               </div>
            </div>
         </div>
         <div class="para e321">The table contains more details than the diagram. The table also points
            		out potential error conditions. Any cell without an entry
            usually represents an error
            		condition that should be examined closely before
            deciding if it is truly an error condition
            		or if it can be ignored. For example, the cell at TEXT state and TAGC was blank
            		in the initial version. The cell should have had TEXT because a lone '&gt;' is
            		just another text character. The
            empty cell at TAG state and STAGO
            		is definitely an error and must be handled.
         </div>
         <div class="para e322">A software finite state machine is the ideal implementation technique
            		for a markup parser. There are a relatively small number of states, a limited
            		number of state change conditions, and the implementation is not overly
            		complex. The current State Machine class in mlParser is about 1800 lines of
            		heavily commented Java. The whole parser is about 3000
            lines and the compiled mlParser JAR file is only 22K.
         </div>
      </div><a name="mlParserTodayANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="section e323">
         <div class="title e324">mlParser Today</div>
         <div class="para e325">This section covers mlParser in its present form. Design choices I made
            		and implemented features are discussed. mlParser has grown and
            		evolved a great deal since that first Java implementation. It is a
            		robust markup parsing tool that is at the heart of several internal
            		applications and is being used on multiple projects. The most significant
            		mlParser use is as the core for an integrated software documentation tool where
            		it has displaced OmniMark applications.
         </div>
         <div class="para e326">Early sections of this paper identified reasons for writing a parser and
            		design choices to make before you get too far into the effort. My initial
            		reason for writing mlParser was learning Java. My reasons for continuing
            		development evolved almost as much as the code itself. My current list
            		is:
         </div>
         <div class="itemizedlist e327">
            <div class="listitem e328">
               <div class="para e329">Mixing different markup meta-languages</div>
            </div>
            <div class="listitem e330">
               <div class="para e331">An application development framework</div>
            </div>
            <div class="listitem e332">
               <div class="para e333">An easily customizable parsing package when XML-type markup just
                  			 won't work
               </div>
            </div>
            <div class="listitem e334">
               <div class="para e335">Fullfilling the "SGML without DTDs" vision</div>
            </div>
            <div class="listitem e336">
               <div class="para e337">Replacing all my OmniMark code</div>
            </div>
         </div>
         <div class="para e338">The integrated software documentation tool has been in use for several
            		years; there are thousands of SGML files across many projects. The software
            		will eventually migrate completely to XML;
            		however, the legacy SGML files will never be converted
            		to XML. There will be a period where
            documents will be built from some SGML files and
            		some XML files. The system must handle the legacy SGML on demand for the
            		foreseeable future. mlParser enables this mixed markup environment. 
         </div>
         <div class="para e339">An application development framework has grown up with mlparser. The
            		output call-back interface forms the basis for mlParser application
            		development. A new application can often be implemented with just two classes.
            		One class is the main program that collects command line arguments, registers
            		the output call-back class, and launches the parsing engine. Starting the
            		parsing process is done by simply invoking the state machine class. Simple
            		applications usually do not require additional classes. Applications that
            		handle multiple document types will need to invoke multiple parser objects with
            		associated, output call-back classes. Each document type should have its own
            		parsing object.
         </div>
         <div class="para e340">My intimate knowledge of the internals, especially the state machine,
            		allows me to customize the parser for specific applications. For example, there
            		is an application that uses an HTML subset plus a handful of extra tags. I want
            		to use generic, out-of-the-box OpenOffice as the editor so the user never
            		sees a tag. We tried processing instructions in
            		place of the extra tags without success. For OpenOffice to work as the editor
            		for this application, editing must be done in normal WYSIWYG mode. Our solution
            		was to include the extra three or four tags in the document with '{' and '}' as
            tag
            		delimiters instead the normal '&lt;' and '&gt;'. It turned out to be a simple
            		solution from both the developer's and user's points of view. The developer was
            		happy because no extra code was required to be able to use OpenOffice, and the
            		user was happy because he didn't have to deal with tags
            for the most part. OpenOffice happily
            		passes around the 
            <div class="emphasis e341" role="ital">special</div>
            tags unmodified, and the application code sees
            		them as normal tags. Tweaking mlParser was straightforward and the result was
            		a major editing improvement from the user's perspective without
            affecting application code.
         </div>
         <div class="para e342">The "XML is just SGML without DTDs" sales pitch from the XML faction at
            		the 1996 SGML Conference convinced me and the SGML community at large that
            		XML was worth pursuing. I envisioned XML as a true SGML subset where I could
            		transparently use the expensive SGML tools that I fought so hard to purchase
            		over the years. New XML
            		tools would certainly be less expensive and compatible. By the time that the
            		XML 1.0 standard hit the streets, that fantasy was crushed. I never gave up the
            		dream of transparent markup though. I wanted to be able to treat markup as SGML
            		to use SGML tools and XML to use XML tools transparently. mlParser essentially
            		allows me to treat both XML and SGML as just 
            <div class="emphasis e343" role="ital">markup.</div> The mlParser
            		parsing engine recognizes the syntax differences between the two, and therefore
            		fulfills the "XML is just SGML without DTDs" as "XML and SGML are just markup,"
            		which is even better!
         </div>
         <div class="para e344">mlParser is built around the following design/features:</div>
         <div class="itemizedlist e345">
            <div class="listitem e346">
               <div class="para e347">Runs either from the command line or embedded in an
                  			 application
               </div>
            </div>
            <div class="listitem e348">
               <div class="para e349">Generates an ESIS output stream by default</div>
            </div>
            <div class="listitem e350">
               <div class="para e351">Handles simple entity character substitution</div>
            </div>
            <div class="listitem e352">
               <div class="para e353">Non-validating parser</div>
            </div>
            <div class="listitem e354">
               <div class="para e355">Handles both SGML and XML empty elements</div>
            </div>
            <div class="listitem e356">
               <div class="para e357">Allows nested parsing</div>
            </div>
            <div class="listitem e358">
               <div class="para e359">Sets most parsing options from the command line</div>
            </div>
            <div class="listitem e360">
               <div class="para e361">Handles multiple types of markup transparently (XML, SGML,
                  			 WordML)
               </div>
            </div>
            <div class="listitem e362">
               <div class="para e363">Can include or exclude comments from the output stream</div>
            </div>
            <div class="listitem e364">
               <div class="para e365">Handles CDATA</div>
            </div>
            <div class="listitem e366">
               <div class="para e367">Does not implement marked sections</div>
            </div>
            <div class="listitem e368">
               <div class="para e369">Includes the option to stop on parsing errors or continue when
                  			 possible
               </div>
            </div>
            <div class="listitem e370">
               <div class="para e371">Built around ESIS events</div>
            </div>
            <div class="listitem e372">
               <div class="para e373">Based on a relatively simple software state machine</div>
            </div>
            <div class="listitem e374">
               <div class="para e375">Includes a sample output call-back class that implements a jump
                  			 table for "document" applications
               </div>
            </div>
            <div class="listitem e376">
               <div class="para e377">Supports multiple input sources</div>
            </div>
         </div>
         <div class="para e378">The same Java JAR file is used for both the stand-alone program and when
            		embedded in an application. Simple entity substitution is driven via a
            		Java properties file. If no entity property file
            		is specified, a default set is used. Entities not
            		found in the property file are passed thru unchanged. A full-blown entity
            		implementation seemed to be almost as much effort as the rest of the parser; and
            		for me, simple entity substitution is sufficient.
         </div>
         <div class="para e379">Several of my applications require nested parsing with different DTDs.
            		An application simply invokes another parser object, handles the output from
            		the nested parser object, and picks up where it left off in the original input
            		stream.
         </div>
         <div class="para e380">The need to stop on a parsing error or continue transparently is
            		application specific. Stopping on an error is the default behavior for
            		stand-alone parser operation. An application
            		processing a document may want to simply
            		unwind the element stack, fire end tag call-backs and keep going. This works
            		reasonably well for missing end tags, but can create a mess with a missing
            		start tag. mlParser provides the option to stop or continue when errors
            		are detected.
            		
         </div>
         <div class="para e381">Multiple input sources is a useful feature. Markup traditionally comes
            		from files and must be complete. mlParser accepts files, strings, or URNs.
            		Parsing a string implies well-formed markup, but no &lt;!DOCTYPE and no XML
            		declaration. Transparently handling URNs allows an application to
            		parse markup directly from the web or some external source such as a
            		Subversion repository. Building a multi-file document directly from a
            		Subversion repository ensures that the output document contains the latest
            		checked-in files without a process to manually extract and process them.
         </div>
         <div class="para e382">The default output call-back interface for handling documents is
            		constructed around two jump tables and Java Reflection. There is one jump table
            		for start tags and one for end tags. The jump tables are constructed as
            		HashMaps with the tag as the key, and the value is the Java method via
            		Reflection. This approach creates a level of indirection between the tags and
            		the code that processes them:
         </div>
         <div class="itemizedlist e383">
            <div class="listitem e384">
               <div class="para e385">One method can handle multiple tags. For example, the same method
                  			 can be used for dropping a tag and its contents or for passing the tag
                  			 unchanged.
               </div>
            </div>
            <div class="listitem e386">
               <div class="para e387">Only tags of interest have to be accounted for; all others can be
                  			 automatically ignored. An unexpected tag will not cause an exception to be
                  			 thrown or the program to bomb.
               </div>
            </div>
            <div class="listitem e388">
               <div class="para e389">The source code does not contain page-after-page of nested
                  			 
                  <div class="emphasis e390" role="ital">if</div> statements to determine which method to call to process a specific
                  			 tag. 
               </div>
            </div>
         </div>
         <div class="para e391">The following start tag call-back method uses the jump table approach:</div>
         <div class="programlisting e392" xml:space="preserve">
            	public void writeStartTag(String sTag)
            	{
            String key     = sTag.toLowerCase();
            try{
            myMethod = (Method)sTagAction.get(key);
            myMethod.invoke(this,new Object[] {});
            }
            catch(Exception e){
            performDefaultStart();
            }
            	}
            
         </div>
         <div class="para e393">
            		Handling a new tag requires no code change here. Instead, a new entry
            		is simply added to the Start Tag Action hash.  I find the jump table approach
            		clean, flexible, and elegant. The jump
            		table approach can be used with any SAX-based parser, not just mlParser.
            		
         </div>
         <div class="para e394">mlParser has evolved over the years from a learning exercise with
            		potential to a major part of my markup applications. The thought of
            		implementing the current
            		mlParser from scratch is a daunting one. Starting small and adding capabilities
            		as needed is a doable job. 
         </div>
      </div><a name="SummaryANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="section e395">
         <div class="title e396">Summary</div>
         <div class="para e397">
            		This paper discusses reasons to write your own markup parser and
            		documents my journey to writing my own parser. mlParser
            		started with very modest beginnings and has evolved into a
            		primary tool in my markup application toolkit. I use it to generate ESIS
            		streams that are processed by Perl scripts, for the core of
            		an integrated software documentation tool, and for
            		markup conversion applications.
            	 
         </div>
         <div class="para e398">
            		I don't believe that I would have tackled writing a parser with
            		all of the features and capabilities that are currently in
            		mlParser. Starting with a small, simple, and flexible base
            		allowed me to evolve a useful and capable parsing tool!
            	 
         </div>
         <div class="para e399">I found out along the way that while XML is king for record-oriented
            		markup, I still prefer SGML for documents. SGML's inclusions,
            		exclusions, and default attribute values make a developer's life
            		much less stressful for document-centric applications. 
         </div>
         <div class="para e400">
            		The experience has shown that there are still many valid reasons
            		to write a markup parser. This paper has identified and explored
            		many of these reasons. Not finding a parser that meets your needs
            		is what most of the reasons boil down to. Don't be afraid to
            		follow the path to your own parser!
            	
         </div>
      </div><a name="BibliographyANCHOR" href="#mainContainerTitleTOC" class="anchor">toc</a><div class="bibliography e401">
         <div class="title e402">Bibliography</div>
         <div class="bibliomixed e403" xml:id="Bajzat" xreflabel="Bajzat">Bajzat, Robert,
            		   
            <div class="emphasis e404" role="ital">Thinlet Home Page,</div>
            
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e405" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">http://www.thinlet.com/index.html</div>.
            		
         </div>
         <div class="bibliomixed e406" xml:id="ClarkJ" xreflabel="ClarkJ">Clark, James,
            		   
            <div class="emphasis e407" role="ital">Nsgmls Output Format,</div>
            
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e408" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">http://www.jclark.com/sp/</div>.
            		
         </div>
         <div class="bibliomixed e409" xml:id="SmithN" xreflabel="Smith1998">Smith, Norman E.,
            		   
            <div class="emphasis e410" role="ital">Practical Guide to SGML/XML Filters,</div>
            Wordware Publishing, Inc., ISBN 1-55622-587-3,  July 1998.
            
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e411" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">http://www.wordware.com</div>.
            		
         </div>
         <div class="bibliomixed e412" xml:id="Forth" xreflabel="Smith1997">Smith, Norman E.,
            		   
            <div class="emphasis e413" role="ital">Write Your Own Programming Language Using C++, 2nd Edition,</div>
            Wordware Publishing, Inc., ISBN 1-55622-492-3,  1997.
            
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e414" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">http://www.wordware.com</div>.
            		
         </div>
         <div class="bibliomixed e415" xml:id="WikipediaMU" xreflabel="WikipediaMU">Wikipedia,
            		   
            <div class="emphasis e416" role="ital">Markup Language Definition,</div>
            
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e417" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">http://en.wikipedia.org/wiki/Markup_language</div>.
            		
         </div>
         <div class="bibliomixed e418" xml:id="WikipediaSGML" xreflabel="WikipediaSGML">Wikipedia,
            		   
            <div class="emphasis e419" role="ital">SGML Definition,</div>
            
            <div xmlns:xlink="http://www.w3.org/1999/xlink" class="link e420" xlink:actuate="onRequest" xlink:show="new" xlink:type="simple">http://en.wikipedia.org/wiki/SGML</div>.
            		
         </div>
      </div>
   </div>
</div>